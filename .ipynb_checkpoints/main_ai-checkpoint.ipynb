{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b374a97",
   "metadata": {},
   "source": [
    "# Node Classification with Graph Neural Networks\n",
    "\n",
    "In this project, I will be implementing a GNN model to classify nodes in the Amazon Computers dataset. The Amazon Computers dataset was first introduced in [Shchur et al., 2019](https://arxiv.org/abs/1811.05868) titled <i>Pitfalls of Graph Neural Network Evaluation</i>. The dataset is a segment of the Amazon co-purchase graph [McAuley et al., 2015](https://cseweb.ucsd.edu/~jmcauley/pdfs/sigir15.pdf), where nodes represent goods, edges indicate that two goods are frequently bought together, node features are bag-of-words encoded product reviews, and class labels are given by the product category.\n",
    "\n",
    "First, I try a simple MLP model with 3 Linear Layers, which uses only feature embeddings to predict class labels. The model continues to train until around 150 epochs where it begins overfitting. At this point, the ROC AUC is roughly 0.55. Then I try a GNN model with 3 GCNConv Layers. The model continues to train until around 1,500 epochs before it tarts overfitting and achieves a ROC AUC of around 0.76. The difference in model performance shows that the model was able to take advantage of the available information in the edge features, which allowed it to train for longer without overfitting and achieve much better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0919afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df93e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Amazon(root='data/Amazon',name='computers', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39606b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: AmazonComputers()\n",
      "===========\n",
      "Number of graphs: 1\n",
      "Number of features: 767\n",
      "Number of classes: 10\n",
      "\n",
      "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752], train_mask=[13752], test_mask=[13752])\n",
      "===========\n",
      "Number of nodes: 13752\n",
      "Number of edges: 491722\n",
      "Average node degree: 35.76\n",
      "Number of training nodes: 2712\n",
      "Training node label rate: 0.20\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}')\n",
    "print('===========')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset.data\n",
    "# this dataset is not split into a training and a test set, so I randomly split the dataset into 20% train and 80% test\n",
    "# setting the random seed so that the train and test set are always the same\n",
    "random.seed(0)\n",
    "data.train_mask = torch.tensor([False if random.random() < 0.8 else True for num in range(data.num_nodes)])\n",
    "data.test_mask = torch.tensor([False if num == True else True for num in data.train_mask])\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========')\n",
    "\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0524af",
   "metadata": {},
   "source": [
    "Above, I can see that there are 13,752 nodes and 491,722 edges which results in an average node degree of 35.8. The graph is undirected and isolated nodes do exist. I split my data into a 20% training set and an 80% test set.\n",
    "\n",
    "Also, I made use of data transformations via transform=NormalizeFeatures(). This resulted in row-normalizing the input feature vectors. In other words, the features in each row sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02b8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False,  ...,  True, False,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the training mask is boolean True/False\n",
    "data.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be82da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\tcount\n",
      "0\t81\n",
      "1\t433\n",
      "2\t278\n",
      "3\t102\n",
      "4\t1030\n",
      "5\t67\n",
      "6\t97\n",
      "7\t140\n",
      "8\t416\n",
      "9\t68\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(data.y[data.train_mask].numpy(), return_counts=True)\n",
    "print(\"value\\tcount\")\n",
    "for val, count in zip(values, counts):\n",
    "    print(f\"{val}\\t{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a1cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of label '4' in the full dataset: 0.38\n",
      "Percentage of top 3 most common labels in the full dataset: 0.69\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of label '4' in the full dataset: {round(counts[4]/sum(counts),2)}\")\n",
    "print(f\"Percentage of top 3 most common labels in the full dataset: {round((counts[1]+counts[4]+counts[8])/sum(counts),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88711e5d",
   "metadata": {},
   "source": [
    "Here I can see that the most common value by far is 4, consisting of 38% of the dataset. This is an unbalanced classification task, so I'm going to use a different metric to evaluate performance other than accuracy. I'm going to use the AUC ROC metric. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. The higher the AUC, the better the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5433e6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(height=counts, x=values)\n",
    "plt.title(\"Frequency of Labels\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151fad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4d1a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move data to gpu for gpu acceleration\n",
    "data = data.to(device)\n",
    "data.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdb0a7",
   "metadata": {},
   "source": [
    "## Training a Multi-layer Perceptron Network (MLP)\n",
    "Here, I am going to try to infer the category of each node based solely on its feature vector, without taking any relational information into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d874cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (lin1): Linear(in_features=767, out_features=16, bias=True)\n",
      "  (lin2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (lin3): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(dataset.num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, dataset.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP(hidden_channels=16)\n",
    "# add device to gpu for gpu acceleration\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e46a792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 2.2937\n",
      "Epoch: 002, Loss: 2.2732\n",
      "Epoch: 003, Loss: 2.2505\n",
      "Epoch: 004, Loss: 2.2311\n",
      "Epoch: 005, Loss: 2.2087\n",
      "Epoch: 006, Loss: 2.1847\n",
      "Epoch: 007, Loss: 2.1676\n",
      "Epoch: 008, Loss: 2.1417\n",
      "Epoch: 009, Loss: 2.1216\n",
      "Epoch: 010, Loss: 2.0906\n",
      "Epoch: 011, Loss: 2.0613\n",
      "Epoch: 012, Loss: 2.0482\n",
      "Epoch: 013, Loss: 2.0075\n",
      "Epoch: 014, Loss: 1.9818\n",
      "Epoch: 015, Loss: 1.9735\n",
      "Epoch: 016, Loss: 1.9602\n",
      "Epoch: 017, Loss: 1.9584\n",
      "Epoch: 018, Loss: 1.9461\n",
      "Epoch: 019, Loss: 1.9529\n",
      "Epoch: 020, Loss: 1.9523\n",
      "Epoch: 021, Loss: 1.9362\n",
      "Epoch: 022, Loss: 1.9256\n",
      "Epoch: 023, Loss: 1.9188\n",
      "Epoch: 024, Loss: 1.9165\n",
      "Epoch: 025, Loss: 1.9034\n",
      "Epoch: 026, Loss: 1.8955\n",
      "Epoch: 027, Loss: 1.8983\n",
      "Epoch: 028, Loss: 1.9116\n",
      "Epoch: 029, Loss: 1.8997\n",
      "Epoch: 030, Loss: 1.8977\n",
      "Epoch: 031, Loss: 1.8921\n",
      "Epoch: 032, Loss: 1.8899\n",
      "Epoch: 033, Loss: 1.8827\n",
      "Epoch: 034, Loss: 1.8829\n",
      "Epoch: 035, Loss: 1.8737\n",
      "Epoch: 036, Loss: 1.8747\n",
      "Epoch: 037, Loss: 1.8660\n",
      "Epoch: 038, Loss: 1.8620\n",
      "Epoch: 039, Loss: 1.8636\n",
      "Epoch: 040, Loss: 1.8668\n",
      "Epoch: 041, Loss: 1.8619\n",
      "Epoch: 042, Loss: 1.8618\n",
      "Epoch: 043, Loss: 1.8615\n",
      "Epoch: 044, Loss: 1.8476\n",
      "Epoch: 045, Loss: 1.8490\n",
      "Epoch: 046, Loss: 1.8423\n",
      "Epoch: 047, Loss: 1.8379\n",
      "Epoch: 048, Loss: 1.8373\n",
      "Epoch: 049, Loss: 1.8321\n",
      "Epoch: 050, Loss: 1.8242\n",
      "Epoch: 051, Loss: 1.8256\n",
      "Epoch: 052, Loss: 1.8264\n",
      "Epoch: 053, Loss: 1.8100\n",
      "Epoch: 054, Loss: 1.8044\n",
      "Epoch: 055, Loss: 1.7988\n",
      "Epoch: 056, Loss: 1.7997\n",
      "Epoch: 057, Loss: 1.7881\n",
      "Epoch: 058, Loss: 1.7839\n",
      "Epoch: 059, Loss: 1.7825\n",
      "Epoch: 060, Loss: 1.7678\n",
      "Epoch: 061, Loss: 1.7690\n",
      "Epoch: 062, Loss: 1.7596\n",
      "Epoch: 063, Loss: 1.7431\n",
      "Epoch: 064, Loss: 1.7393\n",
      "Epoch: 065, Loss: 1.7358\n",
      "Epoch: 066, Loss: 1.7229\n",
      "Epoch: 067, Loss: 1.7107\n",
      "Epoch: 068, Loss: 1.6995\n",
      "Epoch: 069, Loss: 1.7070\n",
      "Epoch: 070, Loss: 1.6913\n",
      "Epoch: 071, Loss: 1.6807\n",
      "Epoch: 072, Loss: 1.6744\n",
      "Epoch: 073, Loss: 1.6577\n",
      "Epoch: 074, Loss: 1.6526\n",
      "Epoch: 075, Loss: 1.6510\n",
      "Epoch: 076, Loss: 1.6481\n",
      "Epoch: 077, Loss: 1.6366\n",
      "Epoch: 078, Loss: 1.6279\n",
      "Epoch: 079, Loss: 1.6293\n",
      "Epoch: 080, Loss: 1.6199\n",
      "Epoch: 081, Loss: 1.6174\n",
      "Epoch: 082, Loss: 1.6098\n",
      "Epoch: 083, Loss: 1.6010\n",
      "Epoch: 084, Loss: 1.5984\n",
      "Epoch: 085, Loss: 1.6002\n",
      "Epoch: 086, Loss: 1.5926\n",
      "Epoch: 087, Loss: 1.5856\n",
      "Epoch: 088, Loss: 1.5786\n",
      "Epoch: 089, Loss: 1.5811\n",
      "Epoch: 090, Loss: 1.5763\n",
      "Epoch: 091, Loss: 1.5633\n",
      "Epoch: 092, Loss: 1.5644\n",
      "Epoch: 093, Loss: 1.5582\n",
      "Epoch: 094, Loss: 1.5592\n",
      "Epoch: 095, Loss: 1.5495\n",
      "Epoch: 096, Loss: 1.5487\n",
      "Epoch: 097, Loss: 1.5437\n",
      "Epoch: 098, Loss: 1.5425\n",
      "Epoch: 099, Loss: 1.5356\n",
      "Epoch: 100, Loss: 1.5399\n",
      "Epoch: 101, Loss: 1.5394\n",
      "Epoch: 102, Loss: 1.5344\n",
      "Epoch: 103, Loss: 1.5315\n",
      "Epoch: 104, Loss: 1.5222\n",
      "Epoch: 105, Loss: 1.5173\n",
      "Epoch: 106, Loss: 1.5249\n",
      "Epoch: 107, Loss: 1.5189\n",
      "Epoch: 108, Loss: 1.5192\n",
      "Epoch: 109, Loss: 1.5046\n",
      "Epoch: 110, Loss: 1.4988\n",
      "Epoch: 111, Loss: 1.5006\n",
      "Epoch: 112, Loss: 1.5034\n",
      "Epoch: 113, Loss: 1.5083\n",
      "Epoch: 114, Loss: 1.4948\n",
      "Epoch: 115, Loss: 1.4979\n",
      "Epoch: 116, Loss: 1.4898\n",
      "Epoch: 117, Loss: 1.4852\n",
      "Epoch: 118, Loss: 1.4889\n",
      "Epoch: 119, Loss: 1.4919\n",
      "Epoch: 120, Loss: 1.4768\n",
      "Epoch: 121, Loss: 1.4637\n",
      "Epoch: 122, Loss: 1.4757\n",
      "Epoch: 123, Loss: 1.4640\n",
      "Epoch: 124, Loss: 1.4661\n",
      "Epoch: 125, Loss: 1.4715\n",
      "Epoch: 126, Loss: 1.4750\n",
      "Epoch: 127, Loss: 1.4593\n",
      "Epoch: 128, Loss: 1.4594\n",
      "Epoch: 129, Loss: 1.4601\n",
      "Epoch: 130, Loss: 1.4537\n",
      "Epoch: 131, Loss: 1.4588\n",
      "Epoch: 132, Loss: 1.4564\n",
      "Epoch: 133, Loss: 1.4424\n",
      "Epoch: 134, Loss: 1.4466\n",
      "Epoch: 135, Loss: 1.4453\n",
      "Epoch: 136, Loss: 1.4557\n",
      "Epoch: 137, Loss: 1.4430\n",
      "Epoch: 138, Loss: 1.4402\n",
      "Epoch: 139, Loss: 1.4443\n",
      "Epoch: 140, Loss: 1.4318\n",
      "Epoch: 141, Loss: 1.4436\n",
      "Epoch: 142, Loss: 1.4303\n",
      "Epoch: 143, Loss: 1.4298\n",
      "Epoch: 144, Loss: 1.4211\n",
      "Epoch: 145, Loss: 1.4291\n",
      "Epoch: 146, Loss: 1.4339\n",
      "Epoch: 147, Loss: 1.4375\n",
      "Epoch: 148, Loss: 1.4255\n",
      "Epoch: 149, Loss: 1.4224\n",
      "Epoch: 150, Loss: 1.4223\n",
      "Epoch: 151, Loss: 1.4184\n",
      "Epoch: 152, Loss: 1.4141\n",
      "Epoch: 153, Loss: 1.4156\n",
      "Epoch: 154, Loss: 1.4170\n",
      "Epoch: 155, Loss: 1.4240\n",
      "Epoch: 156, Loss: 1.4134\n",
      "Epoch: 157, Loss: 1.4093\n",
      "Epoch: 158, Loss: 1.4099\n",
      "Epoch: 159, Loss: 1.4128\n",
      "Epoch: 160, Loss: 1.4050\n",
      "Epoch: 161, Loss: 1.4012\n",
      "Epoch: 162, Loss: 1.4079\n",
      "Epoch: 163, Loss: 1.4074\n",
      "Epoch: 164, Loss: 1.4035\n",
      "Epoch: 165, Loss: 1.3994\n",
      "Epoch: 166, Loss: 1.4077\n",
      "Epoch: 167, Loss: 1.4122\n",
      "Epoch: 168, Loss: 1.3971\n",
      "Epoch: 169, Loss: 1.4110\n",
      "Epoch: 170, Loss: 1.4034\n",
      "Epoch: 171, Loss: 1.4020\n",
      "Epoch: 172, Loss: 1.3969\n",
      "Epoch: 173, Loss: 1.3921\n",
      "Epoch: 174, Loss: 1.3982\n",
      "Epoch: 175, Loss: 1.3996\n",
      "Epoch: 176, Loss: 1.3879\n",
      "Epoch: 177, Loss: 1.3889\n",
      "Epoch: 178, Loss: 1.3880\n",
      "Epoch: 179, Loss: 1.3804\n",
      "Epoch: 180, Loss: 1.3893\n",
      "Epoch: 181, Loss: 1.3886\n",
      "Epoch: 182, Loss: 1.3884\n",
      "Epoch: 183, Loss: 1.3880\n",
      "Epoch: 184, Loss: 1.3870\n",
      "Epoch: 185, Loss: 1.3762\n",
      "Epoch: 186, Loss: 1.3717\n",
      "Epoch: 187, Loss: 1.3773\n",
      "Epoch: 188, Loss: 1.3816\n",
      "Epoch: 189, Loss: 1.3821\n",
      "Epoch: 190, Loss: 1.3761\n",
      "Epoch: 191, Loss: 1.3768\n",
      "Epoch: 192, Loss: 1.3766\n",
      "Epoch: 193, Loss: 1.3713\n",
      "Epoch: 194, Loss: 1.3769\n",
      "Epoch: 195, Loss: 1.3676\n",
      "Epoch: 196, Loss: 1.3753\n",
      "Epoch: 197, Loss: 1.3697\n",
      "Epoch: 198, Loss: 1.3705\n",
      "Epoch: 199, Loss: 1.3599\n",
      "Epoch: 200, Loss: 1.3619\n",
      "Epoch: 201, Loss: 1.3768\n",
      "Epoch: 202, Loss: 1.3750\n",
      "Epoch: 203, Loss: 1.3560\n",
      "Epoch: 204, Loss: 1.3710\n",
      "Epoch: 205, Loss: 1.3570\n",
      "Epoch: 206, Loss: 1.3615\n",
      "Epoch: 207, Loss: 1.3724\n",
      "Epoch: 208, Loss: 1.3551\n",
      "Epoch: 209, Loss: 1.3671\n",
      "Epoch: 210, Loss: 1.3617\n",
      "Epoch: 211, Loss: 1.3562\n",
      "Epoch: 212, Loss: 1.3634\n",
      "Epoch: 213, Loss: 1.3605\n",
      "Epoch: 214, Loss: 1.3644\n",
      "Epoch: 215, Loss: 1.3541\n",
      "Epoch: 216, Loss: 1.3609\n",
      "Epoch: 217, Loss: 1.3580\n",
      "Epoch: 218, Loss: 1.3556\n",
      "Epoch: 219, Loss: 1.3517\n",
      "Epoch: 220, Loss: 1.3582\n",
      "Epoch: 221, Loss: 1.3568\n",
      "Epoch: 222, Loss: 1.3625\n",
      "Epoch: 223, Loss: 1.3536\n",
      "Epoch: 224, Loss: 1.3548\n",
      "Epoch: 225, Loss: 1.3709\n",
      "Epoch: 226, Loss: 1.3528\n",
      "Epoch: 227, Loss: 1.3644\n",
      "Epoch: 228, Loss: 1.3768\n",
      "Epoch: 229, Loss: 1.3587\n",
      "Epoch: 230, Loss: 1.3610\n",
      "Epoch: 231, Loss: 1.3464\n",
      "Epoch: 232, Loss: 1.3585\n",
      "Epoch: 233, Loss: 1.3503\n",
      "Epoch: 234, Loss: 1.3451\n",
      "Epoch: 235, Loss: 1.3398\n",
      "Epoch: 236, Loss: 1.3475\n",
      "Epoch: 237, Loss: 1.3450\n",
      "Epoch: 238, Loss: 1.3390\n",
      "Epoch: 239, Loss: 1.3427\n",
      "Epoch: 240, Loss: 1.3488\n",
      "Epoch: 241, Loss: 1.3456\n",
      "Epoch: 242, Loss: 1.3485\n",
      "Epoch: 243, Loss: 1.3336\n",
      "Epoch: 244, Loss: 1.3303\n",
      "Epoch: 245, Loss: 1.3380\n",
      "Epoch: 246, Loss: 1.3381\n",
      "Epoch: 247, Loss: 1.3339\n",
      "Epoch: 248, Loss: 1.3333\n",
      "Epoch: 249, Loss: 1.3314\n",
      "Epoch: 250, Loss: 1.3249\n",
      "Epoch: 251, Loss: 1.3403\n",
      "Epoch: 252, Loss: 1.3314\n",
      "Epoch: 253, Loss: 1.3312\n",
      "Epoch: 254, Loss: 1.3305\n",
      "Epoch: 255, Loss: 1.3330\n",
      "Epoch: 256, Loss: 1.3358\n",
      "Epoch: 257, Loss: 1.3310\n",
      "Epoch: 258, Loss: 1.3201\n",
      "Epoch: 259, Loss: 1.3304\n",
      "Epoch: 260, Loss: 1.3194\n",
      "Epoch: 261, Loss: 1.3198\n",
      "Epoch: 262, Loss: 1.3226\n",
      "Epoch: 263, Loss: 1.3311\n",
      "Epoch: 264, Loss: 1.3203\n",
      "Epoch: 265, Loss: 1.3311\n",
      "Epoch: 266, Loss: 1.3180\n",
      "Epoch: 267, Loss: 1.3319\n",
      "Epoch: 268, Loss: 1.3291\n",
      "Epoch: 269, Loss: 1.3348\n",
      "Epoch: 270, Loss: 1.3272\n",
      "Epoch: 271, Loss: 1.3211\n",
      "Epoch: 272, Loss: 1.3155\n",
      "Epoch: 273, Loss: 1.3159\n",
      "Epoch: 274, Loss: 1.3173\n",
      "Epoch: 275, Loss: 1.3221\n",
      "Epoch: 276, Loss: 1.3272\n",
      "Epoch: 277, Loss: 1.3246\n",
      "Epoch: 278, Loss: 1.3166\n",
      "Epoch: 279, Loss: 1.3210\n",
      "Epoch: 280, Loss: 1.3170\n",
      "Epoch: 281, Loss: 1.3240\n",
      "Epoch: 282, Loss: 1.3218\n",
      "Epoch: 283, Loss: 1.3165\n",
      "Epoch: 284, Loss: 1.3195\n",
      "Epoch: 285, Loss: 1.3141\n",
      "Epoch: 286, Loss: 1.3266\n",
      "Epoch: 287, Loss: 1.3114\n",
      "Epoch: 288, Loss: 1.3147\n",
      "Epoch: 289, Loss: 1.3193\n",
      "Epoch: 290, Loss: 1.3188\n",
      "Epoch: 291, Loss: 1.3180\n",
      "Epoch: 292, Loss: 1.3184\n",
      "Epoch: 293, Loss: 1.3098\n",
      "Epoch: 294, Loss: 1.3161\n",
      "Epoch: 295, Loss: 1.3296\n",
      "Epoch: 296, Loss: 1.3107\n",
      "Epoch: 297, Loss: 1.3054\n",
      "Epoch: 298, Loss: 1.3078\n",
      "Epoch: 299, Loss: 1.3167\n",
      "Epoch: 300, Loss: 1.3201\n",
      "Epoch: 301, Loss: 1.3273\n",
      "Epoch: 302, Loss: 1.3210\n",
      "Epoch: 303, Loss: 1.3210\n",
      "Epoch: 304, Loss: 1.3096\n",
      "Epoch: 305, Loss: 1.3195\n",
      "Epoch: 306, Loss: 1.3224\n",
      "Epoch: 307, Loss: 1.3172\n",
      "Epoch: 308, Loss: 1.3121\n",
      "Epoch: 309, Loss: 1.3219\n",
      "Epoch: 310, Loss: 1.3103\n",
      "Epoch: 311, Loss: 1.3092\n",
      "Epoch: 312, Loss: 1.3123\n",
      "Epoch: 313, Loss: 1.3124\n",
      "Epoch: 314, Loss: 1.3028\n",
      "Epoch: 315, Loss: 1.3087\n",
      "Epoch: 316, Loss: 1.3280\n",
      "Epoch: 317, Loss: 1.3059\n",
      "Epoch: 318, Loss: 1.3062\n",
      "Epoch: 319, Loss: 1.3175\n",
      "Epoch: 320, Loss: 1.3082\n",
      "Epoch: 321, Loss: 1.3075\n",
      "Epoch: 322, Loss: 1.3018\n",
      "Epoch: 323, Loss: 1.3015\n",
      "Epoch: 324, Loss: 1.3068\n",
      "Epoch: 325, Loss: 1.3056\n",
      "Epoch: 326, Loss: 1.3022\n",
      "Epoch: 327, Loss: 1.3059\n",
      "Epoch: 328, Loss: 1.3183\n",
      "Epoch: 329, Loss: 1.3185\n",
      "Epoch: 330, Loss: 1.2968\n",
      "Epoch: 331, Loss: 1.2994\n",
      "Epoch: 332, Loss: 1.3053\n",
      "Epoch: 333, Loss: 1.2999\n",
      "Epoch: 334, Loss: 1.3144\n",
      "Epoch: 335, Loss: 1.3135\n",
      "Epoch: 336, Loss: 1.3121\n",
      "Epoch: 337, Loss: 1.3070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 338, Loss: 1.3112\n",
      "Epoch: 339, Loss: 1.2995\n",
      "Epoch: 340, Loss: 1.3011\n",
      "Epoch: 341, Loss: 1.3138\n",
      "Epoch: 342, Loss: 1.3035\n",
      "Epoch: 343, Loss: 1.3005\n",
      "Epoch: 344, Loss: 1.3092\n",
      "Epoch: 345, Loss: 1.3008\n",
      "Epoch: 346, Loss: 1.2987\n",
      "Epoch: 347, Loss: 1.2989\n",
      "Epoch: 348, Loss: 1.2943\n",
      "Epoch: 349, Loss: 1.2994\n",
      "Epoch: 350, Loss: 1.3007\n",
      "Epoch: 351, Loss: 1.3041\n",
      "Epoch: 352, Loss: 1.2914\n",
      "Epoch: 353, Loss: 1.2858\n",
      "Epoch: 354, Loss: 1.2916\n",
      "Epoch: 355, Loss: 1.3055\n",
      "Epoch: 356, Loss: 1.3024\n",
      "Epoch: 357, Loss: 1.3025\n",
      "Epoch: 358, Loss: 1.2976\n",
      "Epoch: 359, Loss: 1.2997\n",
      "Epoch: 360, Loss: 1.2971\n",
      "Epoch: 361, Loss: 1.2953\n",
      "Epoch: 362, Loss: 1.2953\n",
      "Epoch: 363, Loss: 1.2927\n",
      "Epoch: 364, Loss: 1.2989\n",
      "Epoch: 365, Loss: 1.2902\n",
      "Epoch: 366, Loss: 1.3008\n",
      "Epoch: 367, Loss: 1.2976\n",
      "Epoch: 368, Loss: 1.2887\n",
      "Epoch: 369, Loss: 1.2950\n",
      "Epoch: 370, Loss: 1.3017\n",
      "Epoch: 371, Loss: 1.2969\n",
      "Epoch: 372, Loss: 1.2847\n",
      "Epoch: 373, Loss: 1.2936\n",
      "Epoch: 374, Loss: 1.2921\n",
      "Epoch: 375, Loss: 1.2992\n",
      "Epoch: 376, Loss: 1.2894\n",
      "Epoch: 377, Loss: 1.2992\n",
      "Epoch: 378, Loss: 1.2935\n",
      "Epoch: 379, Loss: 1.2831\n",
      "Epoch: 380, Loss: 1.2874\n",
      "Epoch: 381, Loss: 1.2906\n",
      "Epoch: 382, Loss: 1.2931\n",
      "Epoch: 383, Loss: 1.2887\n",
      "Epoch: 384, Loss: 1.2909\n",
      "Epoch: 385, Loss: 1.2860\n",
      "Epoch: 386, Loss: 1.2856\n",
      "Epoch: 387, Loss: 1.2852\n",
      "Epoch: 388, Loss: 1.2813\n",
      "Epoch: 389, Loss: 1.2905\n",
      "Epoch: 390, Loss: 1.2898\n",
      "Epoch: 391, Loss: 1.2898\n",
      "Epoch: 392, Loss: 1.2890\n",
      "Epoch: 393, Loss: 1.2926\n",
      "Epoch: 394, Loss: 1.2860\n",
      "Epoch: 395, Loss: 1.3003\n",
      "Epoch: 396, Loss: 1.2860\n",
      "Epoch: 397, Loss: 1.2881\n",
      "Epoch: 398, Loss: 1.2956\n",
      "Epoch: 399, Loss: 1.2905\n",
      "Epoch: 400, Loss: 1.2953\n",
      "Epoch: 401, Loss: 1.2817\n",
      "Epoch: 402, Loss: 1.2773\n",
      "Epoch: 403, Loss: 1.2844\n",
      "Epoch: 404, Loss: 1.2836\n",
      "Epoch: 405, Loss: 1.2788\n",
      "Epoch: 406, Loss: 1.2978\n",
      "Epoch: 407, Loss: 1.2913\n",
      "Epoch: 408, Loss: 1.2776\n",
      "Epoch: 409, Loss: 1.2761\n",
      "Epoch: 410, Loss: 1.2870\n",
      "Epoch: 411, Loss: 1.2714\n",
      "Epoch: 412, Loss: 1.2870\n",
      "Epoch: 413, Loss: 1.2678\n",
      "Epoch: 414, Loss: 1.2851\n",
      "Epoch: 415, Loss: 1.2834\n",
      "Epoch: 416, Loss: 1.2779\n",
      "Epoch: 417, Loss: 1.2860\n",
      "Epoch: 418, Loss: 1.2794\n",
      "Epoch: 419, Loss: 1.2666\n",
      "Epoch: 420, Loss: 1.2786\n",
      "Epoch: 421, Loss: 1.2679\n",
      "Epoch: 422, Loss: 1.2878\n",
      "Epoch: 423, Loss: 1.2685\n",
      "Epoch: 424, Loss: 1.2802\n",
      "Epoch: 425, Loss: 1.2858\n",
      "Epoch: 426, Loss: 1.2741\n",
      "Epoch: 427, Loss: 1.2650\n",
      "Epoch: 428, Loss: 1.2782\n",
      "Epoch: 429, Loss: 1.2746\n",
      "Epoch: 430, Loss: 1.2787\n",
      "Epoch: 431, Loss: 1.2783\n",
      "Epoch: 432, Loss: 1.2690\n",
      "Epoch: 433, Loss: 1.2798\n",
      "Epoch: 434, Loss: 1.2715\n",
      "Epoch: 435, Loss: 1.2544\n",
      "Epoch: 436, Loss: 1.2768\n",
      "Epoch: 437, Loss: 1.2754\n",
      "Epoch: 438, Loss: 1.2646\n",
      "Epoch: 439, Loss: 1.2635\n",
      "Epoch: 440, Loss: 1.2670\n",
      "Epoch: 441, Loss: 1.2716\n",
      "Epoch: 442, Loss: 1.2619\n",
      "Epoch: 443, Loss: 1.2721\n",
      "Epoch: 444, Loss: 1.2663\n",
      "Epoch: 445, Loss: 1.2803\n",
      "Epoch: 446, Loss: 1.2680\n",
      "Epoch: 447, Loss: 1.2624\n",
      "Epoch: 448, Loss: 1.2643\n",
      "Epoch: 449, Loss: 1.2763\n",
      "Epoch: 450, Loss: 1.2654\n",
      "Epoch: 451, Loss: 1.2697\n",
      "Epoch: 452, Loss: 1.2732\n",
      "Epoch: 453, Loss: 1.2765\n",
      "Epoch: 454, Loss: 1.2591\n",
      "Epoch: 455, Loss: 1.2633\n",
      "Epoch: 456, Loss: 1.2663\n",
      "Epoch: 457, Loss: 1.2729\n",
      "Epoch: 458, Loss: 1.2602\n",
      "Epoch: 459, Loss: 1.2638\n",
      "Epoch: 460, Loss: 1.2678\n",
      "Epoch: 461, Loss: 1.2558\n",
      "Epoch: 462, Loss: 1.2542\n",
      "Epoch: 463, Loss: 1.2684\n",
      "Epoch: 464, Loss: 1.2692\n",
      "Epoch: 465, Loss: 1.2715\n",
      "Epoch: 466, Loss: 1.2745\n",
      "Epoch: 467, Loss: 1.2585\n",
      "Epoch: 468, Loss: 1.2622\n",
      "Epoch: 469, Loss: 1.2686\n",
      "Epoch: 470, Loss: 1.2530\n",
      "Epoch: 471, Loss: 1.2588\n",
      "Epoch: 472, Loss: 1.2715\n",
      "Epoch: 473, Loss: 1.2539\n",
      "Epoch: 474, Loss: 1.2654\n",
      "Epoch: 475, Loss: 1.2491\n",
      "Epoch: 476, Loss: 1.2547\n",
      "Epoch: 477, Loss: 1.2489\n",
      "Epoch: 478, Loss: 1.2636\n",
      "Epoch: 479, Loss: 1.2478\n",
      "Epoch: 480, Loss: 1.2571\n",
      "Epoch: 481, Loss: 1.2570\n",
      "Epoch: 482, Loss: 1.2529\n",
      "Epoch: 483, Loss: 1.2619\n",
      "Epoch: 484, Loss: 1.2613\n",
      "Epoch: 485, Loss: 1.2475\n",
      "Epoch: 486, Loss: 1.2569\n",
      "Epoch: 487, Loss: 1.2573\n",
      "Epoch: 488, Loss: 1.2468\n",
      "Epoch: 489, Loss: 1.2595\n",
      "Epoch: 490, Loss: 1.2664\n",
      "Epoch: 491, Loss: 1.2506\n",
      "Epoch: 492, Loss: 1.2520\n",
      "Epoch: 493, Loss: 1.2326\n",
      "Epoch: 494, Loss: 1.2612\n",
      "Epoch: 495, Loss: 1.2594\n",
      "Epoch: 496, Loss: 1.2509\n",
      "Epoch: 497, Loss: 1.2463\n",
      "Epoch: 498, Loss: 1.2509\n",
      "Epoch: 499, Loss: 1.2294\n",
      "Epoch: 500, Loss: 1.2444\n",
      "Epoch: 501, Loss: 1.2487\n",
      "Epoch: 502, Loss: 1.2473\n",
      "Epoch: 503, Loss: 1.2413\n",
      "Epoch: 504, Loss: 1.2510\n",
      "Epoch: 505, Loss: 1.2446\n",
      "Epoch: 506, Loss: 1.2310\n",
      "Epoch: 507, Loss: 1.2418\n",
      "Epoch: 508, Loss: 1.2505\n",
      "Epoch: 509, Loss: 1.2379\n",
      "Epoch: 510, Loss: 1.2315\n",
      "Epoch: 511, Loss: 1.2502\n",
      "Epoch: 512, Loss: 1.2299\n",
      "Epoch: 513, Loss: 1.2344\n",
      "Epoch: 514, Loss: 1.2401\n",
      "Epoch: 515, Loss: 1.2435\n",
      "Epoch: 516, Loss: 1.2310\n",
      "Epoch: 517, Loss: 1.2386\n",
      "Epoch: 518, Loss: 1.2548\n",
      "Epoch: 519, Loss: 1.2373\n",
      "Epoch: 520, Loss: 1.2410\n",
      "Epoch: 521, Loss: 1.2254\n",
      "Epoch: 522, Loss: 1.2374\n",
      "Epoch: 523, Loss: 1.2271\n",
      "Epoch: 524, Loss: 1.2267\n",
      "Epoch: 525, Loss: 1.2365\n",
      "Epoch: 526, Loss: 1.2293\n",
      "Epoch: 527, Loss: 1.2196\n",
      "Epoch: 528, Loss: 1.2292\n",
      "Epoch: 529, Loss: 1.2320\n",
      "Epoch: 530, Loss: 1.2170\n",
      "Epoch: 531, Loss: 1.2440\n",
      "Epoch: 532, Loss: 1.2288\n",
      "Epoch: 533, Loss: 1.2330\n",
      "Epoch: 534, Loss: 1.2301\n",
      "Epoch: 535, Loss: 1.2205\n",
      "Epoch: 536, Loss: 1.2211\n",
      "Epoch: 537, Loss: 1.2169\n",
      "Epoch: 538, Loss: 1.2234\n",
      "Epoch: 539, Loss: 1.2107\n",
      "Epoch: 540, Loss: 1.2344\n",
      "Epoch: 541, Loss: 1.2223\n",
      "Epoch: 542, Loss: 1.2319\n",
      "Epoch: 543, Loss: 1.2191\n",
      "Epoch: 544, Loss: 1.2149\n",
      "Epoch: 545, Loss: 1.2232\n",
      "Epoch: 546, Loss: 1.2214\n",
      "Epoch: 547, Loss: 1.2276\n",
      "Epoch: 548, Loss: 1.2177\n",
      "Epoch: 549, Loss: 1.2170\n",
      "Epoch: 550, Loss: 1.2216\n",
      "Epoch: 551, Loss: 1.2187\n",
      "Epoch: 552, Loss: 1.2291\n",
      "Epoch: 553, Loss: 1.2187\n",
      "Epoch: 554, Loss: 1.2078\n",
      "Epoch: 555, Loss: 1.2017\n",
      "Epoch: 556, Loss: 1.2079\n",
      "Epoch: 557, Loss: 1.2179\n",
      "Epoch: 558, Loss: 1.2161\n",
      "Epoch: 559, Loss: 1.2167\n",
      "Epoch: 560, Loss: 1.2020\n",
      "Epoch: 561, Loss: 1.2262\n",
      "Epoch: 562, Loss: 1.2161\n",
      "Epoch: 563, Loss: 1.2117\n",
      "Epoch: 564, Loss: 1.2256\n",
      "Epoch: 565, Loss: 1.2107\n",
      "Epoch: 566, Loss: 1.2071\n",
      "Epoch: 567, Loss: 1.2155\n",
      "Epoch: 568, Loss: 1.1980\n",
      "Epoch: 569, Loss: 1.1949\n",
      "Epoch: 570, Loss: 1.2125\n",
      "Epoch: 571, Loss: 1.1850\n",
      "Epoch: 572, Loss: 1.2006\n",
      "Epoch: 573, Loss: 1.2072\n",
      "Epoch: 574, Loss: 1.1879\n",
      "Epoch: 575, Loss: 1.2048\n",
      "Epoch: 576, Loss: 1.1988\n",
      "Epoch: 577, Loss: 1.2022\n",
      "Epoch: 578, Loss: 1.1988\n",
      "Epoch: 579, Loss: 1.2050\n",
      "Epoch: 580, Loss: 1.2120\n",
      "Epoch: 581, Loss: 1.2014\n",
      "Epoch: 582, Loss: 1.1959\n",
      "Epoch: 583, Loss: 1.1985\n",
      "Epoch: 584, Loss: 1.2161\n",
      "Epoch: 585, Loss: 1.1922\n",
      "Epoch: 586, Loss: 1.1996\n",
      "Epoch: 587, Loss: 1.1962\n",
      "Epoch: 588, Loss: 1.2127\n",
      "Epoch: 589, Loss: 1.1922\n",
      "Epoch: 590, Loss: 1.1944\n",
      "Epoch: 591, Loss: 1.2063\n",
      "Epoch: 592, Loss: 1.2088\n",
      "Epoch: 593, Loss: 1.1917\n",
      "Epoch: 594, Loss: 1.1843\n",
      "Epoch: 595, Loss: 1.1973\n",
      "Epoch: 596, Loss: 1.1977\n",
      "Epoch: 597, Loss: 1.1843\n",
      "Epoch: 598, Loss: 1.1836\n",
      "Epoch: 599, Loss: 1.1924\n",
      "Epoch: 600, Loss: 1.1912\n",
      "Epoch: 601, Loss: 1.1908\n",
      "Epoch: 602, Loss: 1.1964\n",
      "Epoch: 603, Loss: 1.1943\n",
      "Epoch: 604, Loss: 1.1880\n",
      "Epoch: 605, Loss: 1.2019\n",
      "Epoch: 606, Loss: 1.1800\n",
      "Epoch: 607, Loss: 1.1980\n",
      "Epoch: 608, Loss: 1.2032\n",
      "Epoch: 609, Loss: 1.1985\n",
      "Epoch: 610, Loss: 1.1760\n",
      "Epoch: 611, Loss: 1.1865\n",
      "Epoch: 612, Loss: 1.1907\n",
      "Epoch: 613, Loss: 1.1886\n",
      "Epoch: 614, Loss: 1.1694\n",
      "Epoch: 615, Loss: 1.1724\n",
      "Epoch: 616, Loss: 1.1704\n",
      "Epoch: 617, Loss: 1.1682\n",
      "Epoch: 618, Loss: 1.1728\n",
      "Epoch: 619, Loss: 1.1859\n",
      "Epoch: 620, Loss: 1.1580\n",
      "Epoch: 621, Loss: 1.1713\n",
      "Epoch: 622, Loss: 1.1697\n",
      "Epoch: 623, Loss: 1.1835\n",
      "Epoch: 624, Loss: 1.1676\n",
      "Epoch: 625, Loss: 1.1775\n",
      "Epoch: 626, Loss: 1.1730\n",
      "Epoch: 627, Loss: 1.1697\n",
      "Epoch: 628, Loss: 1.1752\n",
      "Epoch: 629, Loss: 1.1727\n",
      "Epoch: 630, Loss: 1.1691\n",
      "Epoch: 631, Loss: 1.1811\n",
      "Epoch: 632, Loss: 1.1703\n",
      "Epoch: 633, Loss: 1.1614\n",
      "Epoch: 634, Loss: 1.1622\n",
      "Epoch: 635, Loss: 1.1624\n",
      "Epoch: 636, Loss: 1.1650\n",
      "Epoch: 637, Loss: 1.1731\n",
      "Epoch: 638, Loss: 1.1829\n",
      "Epoch: 639, Loss: 1.1615\n",
      "Epoch: 640, Loss: 1.1673\n",
      "Epoch: 641, Loss: 1.1746\n",
      "Epoch: 642, Loss: 1.1717\n",
      "Epoch: 643, Loss: 1.1559\n",
      "Epoch: 644, Loss: 1.1703\n",
      "Epoch: 645, Loss: 1.1647\n",
      "Epoch: 646, Loss: 1.1585\n",
      "Epoch: 647, Loss: 1.1766\n",
      "Epoch: 648, Loss: 1.1568\n",
      "Epoch: 649, Loss: 1.1511\n",
      "Epoch: 650, Loss: 1.1662\n",
      "Epoch: 651, Loss: 1.1644\n",
      "Epoch: 652, Loss: 1.1658\n",
      "Epoch: 653, Loss: 1.1562\n",
      "Epoch: 654, Loss: 1.1610\n",
      "Epoch: 655, Loss: 1.1676\n",
      "Epoch: 656, Loss: 1.1546\n",
      "Epoch: 657, Loss: 1.1606\n",
      "Epoch: 658, Loss: 1.1561\n",
      "Epoch: 659, Loss: 1.1491\n",
      "Epoch: 660, Loss: 1.1420\n",
      "Epoch: 661, Loss: 1.1610\n",
      "Epoch: 662, Loss: 1.1545\n",
      "Epoch: 663, Loss: 1.1761\n",
      "Epoch: 664, Loss: 1.1526\n",
      "Epoch: 665, Loss: 1.1478\n",
      "Epoch: 666, Loss: 1.1425\n",
      "Epoch: 667, Loss: 1.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 668, Loss: 1.1417\n",
      "Epoch: 669, Loss: 1.1569\n",
      "Epoch: 670, Loss: 1.1449\n",
      "Epoch: 671, Loss: 1.1450\n",
      "Epoch: 672, Loss: 1.1596\n",
      "Epoch: 673, Loss: 1.1646\n",
      "Epoch: 674, Loss: 1.1468\n",
      "Epoch: 675, Loss: 1.1467\n",
      "Epoch: 676, Loss: 1.1479\n",
      "Epoch: 677, Loss: 1.1461\n",
      "Epoch: 678, Loss: 1.1527\n",
      "Epoch: 679, Loss: 1.1525\n",
      "Epoch: 680, Loss: 1.1438\n",
      "Epoch: 681, Loss: 1.1514\n",
      "Epoch: 682, Loss: 1.1596\n",
      "Epoch: 683, Loss: 1.1453\n",
      "Epoch: 684, Loss: 1.1548\n",
      "Epoch: 685, Loss: 1.1322\n",
      "Epoch: 686, Loss: 1.1485\n",
      "Epoch: 687, Loss: 1.1315\n",
      "Epoch: 688, Loss: 1.1553\n",
      "Epoch: 689, Loss: 1.1577\n",
      "Epoch: 690, Loss: 1.1419\n",
      "Epoch: 691, Loss: 1.1559\n",
      "Epoch: 692, Loss: 1.1389\n",
      "Epoch: 693, Loss: 1.1493\n",
      "Epoch: 694, Loss: 1.1498\n",
      "Epoch: 695, Loss: 1.1543\n",
      "Epoch: 696, Loss: 1.1337\n",
      "Epoch: 697, Loss: 1.1533\n",
      "Epoch: 698, Loss: 1.1395\n",
      "Epoch: 699, Loss: 1.1420\n",
      "Epoch: 700, Loss: 1.1526\n",
      "Epoch: 701, Loss: 1.1561\n",
      "Epoch: 702, Loss: 1.1399\n",
      "Epoch: 703, Loss: 1.1346\n",
      "Epoch: 704, Loss: 1.1343\n",
      "Epoch: 705, Loss: 1.1494\n",
      "Epoch: 706, Loss: 1.1372\n",
      "Epoch: 707, Loss: 1.1574\n",
      "Epoch: 708, Loss: 1.1320\n",
      "Epoch: 709, Loss: 1.1383\n",
      "Epoch: 710, Loss: 1.1465\n",
      "Epoch: 711, Loss: 1.1397\n",
      "Epoch: 712, Loss: 1.1493\n",
      "Epoch: 713, Loss: 1.1358\n",
      "Epoch: 714, Loss: 1.1311\n",
      "Epoch: 715, Loss: 1.1351\n",
      "Epoch: 716, Loss: 1.1331\n",
      "Epoch: 717, Loss: 1.1518\n",
      "Epoch: 718, Loss: 1.1434\n",
      "Epoch: 719, Loss: 1.1368\n",
      "Epoch: 720, Loss: 1.1467\n",
      "Epoch: 721, Loss: 1.1468\n",
      "Epoch: 722, Loss: 1.1408\n",
      "Epoch: 723, Loss: 1.1426\n",
      "Epoch: 724, Loss: 1.1294\n",
      "Epoch: 725, Loss: 1.1361\n",
      "Epoch: 726, Loss: 1.1345\n",
      "Epoch: 727, Loss: 1.1361\n",
      "Epoch: 728, Loss: 1.1323\n",
      "Epoch: 729, Loss: 1.1281\n",
      "Epoch: 730, Loss: 1.1376\n",
      "Epoch: 731, Loss: 1.1415\n",
      "Epoch: 732, Loss: 1.1177\n",
      "Epoch: 733, Loss: 1.1402\n",
      "Epoch: 734, Loss: 1.1299\n",
      "Epoch: 735, Loss: 1.1299\n",
      "Epoch: 736, Loss: 1.1304\n",
      "Epoch: 737, Loss: 1.1412\n",
      "Epoch: 738, Loss: 1.1431\n",
      "Epoch: 739, Loss: 1.1403\n",
      "Epoch: 740, Loss: 1.1450\n",
      "Epoch: 741, Loss: 1.1335\n",
      "Epoch: 742, Loss: 1.1224\n",
      "Epoch: 743, Loss: 1.1299\n",
      "Epoch: 744, Loss: 1.1437\n",
      "Epoch: 745, Loss: 1.1275\n",
      "Epoch: 746, Loss: 1.1492\n",
      "Epoch: 747, Loss: 1.1369\n",
      "Epoch: 748, Loss: 1.1273\n",
      "Epoch: 749, Loss: 1.1278\n",
      "Epoch: 750, Loss: 1.1333\n",
      "Epoch: 751, Loss: 1.1253\n",
      "Epoch: 752, Loss: 1.1267\n",
      "Epoch: 753, Loss: 1.1476\n",
      "Epoch: 754, Loss: 1.1205\n",
      "Epoch: 755, Loss: 1.1536\n",
      "Epoch: 756, Loss: 1.1339\n",
      "Epoch: 757, Loss: 1.1123\n",
      "Epoch: 758, Loss: 1.1241\n",
      "Epoch: 759, Loss: 1.1400\n",
      "Epoch: 760, Loss: 1.1260\n",
      "Epoch: 761, Loss: 1.1355\n",
      "Epoch: 762, Loss: 1.1231\n",
      "Epoch: 763, Loss: 1.1342\n",
      "Epoch: 764, Loss: 1.1315\n",
      "Epoch: 765, Loss: 1.1183\n",
      "Epoch: 766, Loss: 1.1313\n",
      "Epoch: 767, Loss: 1.1287\n",
      "Epoch: 768, Loss: 1.1337\n",
      "Epoch: 769, Loss: 1.1308\n",
      "Epoch: 770, Loss: 1.1315\n",
      "Epoch: 771, Loss: 1.1411\n",
      "Epoch: 772, Loss: 1.1182\n",
      "Epoch: 773, Loss: 1.1278\n",
      "Epoch: 774, Loss: 1.1360\n",
      "Epoch: 775, Loss: 1.1276\n",
      "Epoch: 776, Loss: 1.1151\n",
      "Epoch: 777, Loss: 1.1196\n",
      "Epoch: 778, Loss: 1.1304\n",
      "Epoch: 779, Loss: 1.1438\n",
      "Epoch: 780, Loss: 1.1321\n",
      "Epoch: 781, Loss: 1.1415\n",
      "Epoch: 782, Loss: 1.1225\n",
      "Epoch: 783, Loss: 1.1319\n",
      "Epoch: 784, Loss: 1.1203\n",
      "Epoch: 785, Loss: 1.1272\n",
      "Epoch: 786, Loss: 1.1168\n",
      "Epoch: 787, Loss: 1.1328\n",
      "Epoch: 788, Loss: 1.1435\n",
      "Epoch: 789, Loss: 1.1238\n",
      "Epoch: 790, Loss: 1.1311\n",
      "Epoch: 791, Loss: 1.1326\n",
      "Epoch: 792, Loss: 1.1293\n",
      "Epoch: 793, Loss: 1.1343\n",
      "Epoch: 794, Loss: 1.1316\n",
      "Epoch: 795, Loss: 1.1182\n",
      "Epoch: 796, Loss: 1.1228\n",
      "Epoch: 797, Loss: 1.1320\n",
      "Epoch: 798, Loss: 1.1360\n",
      "Epoch: 799, Loss: 1.1341\n",
      "Epoch: 800, Loss: 1.1204\n",
      "Epoch: 801, Loss: 1.1369\n",
      "Epoch: 802, Loss: 1.1258\n",
      "Epoch: 803, Loss: 1.1282\n",
      "Epoch: 804, Loss: 1.1176\n",
      "Epoch: 805, Loss: 1.1391\n",
      "Epoch: 806, Loss: 1.1219\n",
      "Epoch: 807, Loss: 1.1192\n",
      "Epoch: 808, Loss: 1.1153\n",
      "Epoch: 809, Loss: 1.1215\n",
      "Epoch: 810, Loss: 1.1428\n",
      "Epoch: 811, Loss: 1.1190\n",
      "Epoch: 812, Loss: 1.1231\n",
      "Epoch: 813, Loss: 1.1308\n",
      "Epoch: 814, Loss: 1.1182\n",
      "Epoch: 815, Loss: 1.1354\n",
      "Epoch: 816, Loss: 1.1199\n",
      "Epoch: 817, Loss: 1.1235\n",
      "Epoch: 818, Loss: 1.1344\n",
      "Epoch: 819, Loss: 1.1347\n",
      "Epoch: 820, Loss: 1.1249\n",
      "Epoch: 821, Loss: 1.1257\n",
      "Epoch: 822, Loss: 1.1288\n",
      "Epoch: 823, Loss: 1.1248\n",
      "Epoch: 824, Loss: 1.1220\n",
      "Epoch: 825, Loss: 1.1307\n",
      "Epoch: 826, Loss: 1.1199\n",
      "Epoch: 827, Loss: 1.1118\n",
      "Epoch: 828, Loss: 1.1182\n",
      "Epoch: 829, Loss: 1.1390\n",
      "Epoch: 830, Loss: 1.1229\n",
      "Epoch: 831, Loss: 1.1200\n",
      "Epoch: 832, Loss: 1.1210\n",
      "Epoch: 833, Loss: 1.1189\n",
      "Epoch: 834, Loss: 1.1261\n",
      "Epoch: 835, Loss: 1.1237\n",
      "Epoch: 836, Loss: 1.1054\n",
      "Epoch: 837, Loss: 1.1269\n",
      "Epoch: 838, Loss: 1.1085\n",
      "Epoch: 839, Loss: 1.1207\n",
      "Epoch: 840, Loss: 1.1226\n",
      "Epoch: 841, Loss: 1.1170\n",
      "Epoch: 842, Loss: 1.1291\n",
      "Epoch: 843, Loss: 1.1142\n",
      "Epoch: 844, Loss: 1.1237\n",
      "Epoch: 845, Loss: 1.1273\n",
      "Epoch: 846, Loss: 1.1193\n",
      "Epoch: 847, Loss: 1.1291\n",
      "Epoch: 848, Loss: 1.1151\n",
      "Epoch: 849, Loss: 1.1404\n",
      "Epoch: 850, Loss: 1.1255\n",
      "Epoch: 851, Loss: 1.1290\n",
      "Epoch: 852, Loss: 1.1288\n",
      "Epoch: 853, Loss: 1.1418\n",
      "Epoch: 854, Loss: 1.1122\n",
      "Epoch: 855, Loss: 1.1333\n",
      "Epoch: 856, Loss: 1.1268\n",
      "Epoch: 857, Loss: 1.1151\n",
      "Epoch: 858, Loss: 1.1096\n",
      "Epoch: 859, Loss: 1.1149\n",
      "Epoch: 860, Loss: 1.1212\n",
      "Epoch: 861, Loss: 1.1294\n",
      "Epoch: 862, Loss: 1.1136\n",
      "Epoch: 863, Loss: 1.1162\n",
      "Epoch: 864, Loss: 1.1129\n",
      "Epoch: 865, Loss: 1.1181\n",
      "Epoch: 866, Loss: 1.1273\n",
      "Epoch: 867, Loss: 1.1363\n",
      "Epoch: 868, Loss: 1.1153\n",
      "Epoch: 869, Loss: 1.1134\n",
      "Epoch: 870, Loss: 1.1164\n",
      "Epoch: 871, Loss: 1.1341\n",
      "Epoch: 872, Loss: 1.1151\n",
      "Epoch: 873, Loss: 1.1055\n",
      "Epoch: 874, Loss: 1.1166\n",
      "Epoch: 875, Loss: 1.1125\n",
      "Epoch: 876, Loss: 1.1352\n",
      "Epoch: 877, Loss: 1.1185\n",
      "Epoch: 878, Loss: 1.1254\n",
      "Epoch: 879, Loss: 1.1282\n",
      "Epoch: 880, Loss: 1.1263\n",
      "Epoch: 881, Loss: 1.1179\n",
      "Epoch: 882, Loss: 1.1126\n",
      "Epoch: 883, Loss: 1.1227\n",
      "Epoch: 884, Loss: 1.1243\n",
      "Epoch: 885, Loss: 1.1034\n",
      "Epoch: 886, Loss: 1.1210\n",
      "Epoch: 887, Loss: 1.1159\n",
      "Epoch: 888, Loss: 1.1314\n",
      "Epoch: 889, Loss: 1.1292\n",
      "Epoch: 890, Loss: 1.1197\n",
      "Epoch: 891, Loss: 1.1403\n",
      "Epoch: 892, Loss: 1.1324\n",
      "Epoch: 893, Loss: 1.1215\n",
      "Epoch: 894, Loss: 1.1276\n",
      "Epoch: 895, Loss: 1.1255\n",
      "Epoch: 896, Loss: 1.1242\n",
      "Epoch: 897, Loss: 1.1380\n",
      "Epoch: 898, Loss: 1.1169\n",
      "Epoch: 899, Loss: 1.1323\n",
      "Epoch: 900, Loss: 1.1424\n",
      "Epoch: 901, Loss: 1.1350\n",
      "Epoch: 902, Loss: 1.1296\n",
      "Epoch: 903, Loss: 1.1122\n",
      "Epoch: 904, Loss: 1.1221\n",
      "Epoch: 905, Loss: 1.1234\n",
      "Epoch: 906, Loss: 1.1089\n",
      "Epoch: 907, Loss: 1.1212\n",
      "Epoch: 908, Loss: 1.1268\n",
      "Epoch: 909, Loss: 1.1223\n",
      "Epoch: 910, Loss: 1.1108\n",
      "Epoch: 911, Loss: 1.1176\n",
      "Epoch: 912, Loss: 1.1210\n",
      "Epoch: 913, Loss: 1.1241\n",
      "Epoch: 914, Loss: 1.1183\n",
      "Epoch: 915, Loss: 1.1060\n",
      "Epoch: 916, Loss: 1.1104\n",
      "Epoch: 917, Loss: 1.1151\n",
      "Epoch: 918, Loss: 1.1044\n",
      "Epoch: 919, Loss: 1.1289\n",
      "Epoch: 920, Loss: 1.1212\n",
      "Epoch: 921, Loss: 1.1171\n",
      "Epoch: 922, Loss: 1.1219\n",
      "Epoch: 923, Loss: 1.1162\n",
      "Epoch: 924, Loss: 1.1057\n",
      "Epoch: 925, Loss: 1.1072\n",
      "Epoch: 926, Loss: 1.1199\n",
      "Epoch: 927, Loss: 1.1068\n",
      "Epoch: 928, Loss: 1.1264\n",
      "Epoch: 929, Loss: 1.1133\n",
      "Epoch: 930, Loss: 1.1150\n",
      "Epoch: 931, Loss: 1.1125\n",
      "Epoch: 932, Loss: 1.1167\n",
      "Epoch: 933, Loss: 1.1156\n",
      "Epoch: 934, Loss: 1.1047\n",
      "Epoch: 935, Loss: 1.1044\n",
      "Epoch: 936, Loss: 1.1266\n",
      "Epoch: 937, Loss: 1.1189\n",
      "Epoch: 938, Loss: 1.1084\n",
      "Epoch: 939, Loss: 1.1226\n",
      "Epoch: 940, Loss: 1.1093\n",
      "Epoch: 941, Loss: 1.1215\n",
      "Epoch: 942, Loss: 1.1137\n",
      "Epoch: 943, Loss: 1.1103\n",
      "Epoch: 944, Loss: 1.1045\n",
      "Epoch: 945, Loss: 1.1058\n",
      "Epoch: 946, Loss: 1.1101\n",
      "Epoch: 947, Loss: 1.1133\n",
      "Epoch: 948, Loss: 1.1226\n",
      "Epoch: 949, Loss: 1.1201\n",
      "Epoch: 950, Loss: 1.1215\n",
      "Epoch: 951, Loss: 1.1180\n",
      "Epoch: 952, Loss: 1.1038\n",
      "Epoch: 953, Loss: 1.1240\n",
      "Epoch: 954, Loss: 1.1179\n",
      "Epoch: 955, Loss: 1.1054\n",
      "Epoch: 956, Loss: 1.1209\n",
      "Epoch: 957, Loss: 1.1127\n",
      "Epoch: 958, Loss: 1.1164\n",
      "Epoch: 959, Loss: 1.1280\n",
      "Epoch: 960, Loss: 1.0964\n",
      "Epoch: 961, Loss: 1.1227\n",
      "Epoch: 962, Loss: 1.0993\n",
      "Epoch: 963, Loss: 1.1037\n",
      "Epoch: 964, Loss: 1.1082\n",
      "Epoch: 965, Loss: 1.1138\n",
      "Epoch: 966, Loss: 1.1063\n",
      "Epoch: 967, Loss: 1.1003\n",
      "Epoch: 968, Loss: 1.1004\n",
      "Epoch: 969, Loss: 1.1045\n",
      "Epoch: 970, Loss: 1.0943\n",
      "Epoch: 971, Loss: 1.1025\n",
      "Epoch: 972, Loss: 1.0992\n",
      "Epoch: 973, Loss: 1.1078\n",
      "Epoch: 974, Loss: 1.0994\n",
      "Epoch: 975, Loss: 1.1163\n",
      "Epoch: 976, Loss: 1.0811\n",
      "Epoch: 977, Loss: 1.1011\n",
      "Epoch: 978, Loss: 1.1202\n",
      "Epoch: 979, Loss: 1.1004\n",
      "Epoch: 980, Loss: 1.1154\n",
      "Epoch: 981, Loss: 1.1165\n",
      "Epoch: 982, Loss: 1.1103\n",
      "Epoch: 983, Loss: 1.1181\n",
      "Epoch: 984, Loss: 1.1105\n",
      "Epoch: 985, Loss: 1.1008\n",
      "Epoch: 986, Loss: 1.1190\n",
      "Epoch: 987, Loss: 1.0930\n",
      "Epoch: 988, Loss: 1.1155\n",
      "Epoch: 989, Loss: 1.1263\n",
      "Epoch: 990, Loss: 1.1094\n",
      "Epoch: 991, Loss: 1.1219\n",
      "Epoch: 992, Loss: 1.1149\n",
      "Epoch: 993, Loss: 1.1168\n",
      "Epoch: 994, Loss: 1.1171\n",
      "Epoch: 995, Loss: 1.1010\n",
      "Epoch: 996, Loss: 1.1156\n",
      "Epoch: 997, Loss: 1.1095\n",
      "Epoch: 998, Loss: 1.1235\n",
      "Epoch: 999, Loss: 1.1027\n",
      "Epoch: 1000, Loss: 1.1124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001, Loss: 1.0959\n",
      "Epoch: 1002, Loss: 1.1239\n",
      "Epoch: 1003, Loss: 1.1049\n",
      "Epoch: 1004, Loss: 1.1127\n",
      "Epoch: 1005, Loss: 1.1145\n",
      "Epoch: 1006, Loss: 1.1111\n",
      "Epoch: 1007, Loss: 1.1051\n",
      "Epoch: 1008, Loss: 1.1122\n",
      "Epoch: 1009, Loss: 1.1137\n",
      "Epoch: 1010, Loss: 1.1150\n",
      "Epoch: 1011, Loss: 1.1027\n",
      "Epoch: 1012, Loss: 1.1145\n",
      "Epoch: 1013, Loss: 1.1108\n",
      "Epoch: 1014, Loss: 1.1091\n",
      "Epoch: 1015, Loss: 1.0986\n",
      "Epoch: 1016, Loss: 1.1234\n",
      "Epoch: 1017, Loss: 1.1147\n",
      "Epoch: 1018, Loss: 1.0899\n",
      "Epoch: 1019, Loss: 1.1181\n",
      "Epoch: 1020, Loss: 1.1133\n",
      "Epoch: 1021, Loss: 1.1087\n",
      "Epoch: 1022, Loss: 1.1190\n",
      "Epoch: 1023, Loss: 1.1079\n",
      "Epoch: 1024, Loss: 1.1033\n",
      "Epoch: 1025, Loss: 1.1144\n",
      "Epoch: 1026, Loss: 1.1153\n",
      "Epoch: 1027, Loss: 1.0951\n",
      "Epoch: 1028, Loss: 1.1192\n",
      "Epoch: 1029, Loss: 1.0995\n",
      "Epoch: 1030, Loss: 1.1054\n",
      "Epoch: 1031, Loss: 1.1123\n",
      "Epoch: 1032, Loss: 1.1105\n",
      "Epoch: 1033, Loss: 1.1099\n",
      "Epoch: 1034, Loss: 1.0991\n",
      "Epoch: 1035, Loss: 1.0962\n",
      "Epoch: 1036, Loss: 1.0960\n",
      "Epoch: 1037, Loss: 1.1099\n",
      "Epoch: 1038, Loss: 1.1202\n",
      "Epoch: 1039, Loss: 1.1009\n",
      "Epoch: 1040, Loss: 1.1018\n",
      "Epoch: 1041, Loss: 1.0961\n",
      "Epoch: 1042, Loss: 1.1221\n",
      "Epoch: 1043, Loss: 1.1175\n",
      "Epoch: 1044, Loss: 1.1116\n",
      "Epoch: 1045, Loss: 1.1231\n",
      "Epoch: 1046, Loss: 1.0989\n",
      "Epoch: 1047, Loss: 1.1007\n",
      "Epoch: 1048, Loss: 1.1057\n",
      "Epoch: 1049, Loss: 1.0899\n",
      "Epoch: 1050, Loss: 1.0990\n",
      "Epoch: 1051, Loss: 1.1013\n",
      "Epoch: 1052, Loss: 1.1057\n",
      "Epoch: 1053, Loss: 1.1217\n",
      "Epoch: 1054, Loss: 1.1014\n",
      "Epoch: 1055, Loss: 1.0986\n",
      "Epoch: 1056, Loss: 1.1008\n",
      "Epoch: 1057, Loss: 1.1133\n",
      "Epoch: 1058, Loss: 1.0887\n",
      "Epoch: 1059, Loss: 1.1091\n",
      "Epoch: 1060, Loss: 1.1190\n",
      "Epoch: 1061, Loss: 1.1112\n",
      "Epoch: 1062, Loss: 1.1084\n",
      "Epoch: 1063, Loss: 1.1220\n",
      "Epoch: 1064, Loss: 1.1119\n",
      "Epoch: 1065, Loss: 1.1223\n",
      "Epoch: 1066, Loss: 1.1113\n",
      "Epoch: 1067, Loss: 1.1069\n",
      "Epoch: 1068, Loss: 1.0987\n",
      "Epoch: 1069, Loss: 1.1064\n",
      "Epoch: 1070, Loss: 1.1042\n",
      "Epoch: 1071, Loss: 1.0828\n",
      "Epoch: 1072, Loss: 1.1092\n",
      "Epoch: 1073, Loss: 1.0923\n",
      "Epoch: 1074, Loss: 1.1125\n",
      "Epoch: 1075, Loss: 1.1279\n",
      "Epoch: 1076, Loss: 1.1016\n",
      "Epoch: 1077, Loss: 1.1050\n",
      "Epoch: 1078, Loss: 1.1141\n",
      "Epoch: 1079, Loss: 1.0890\n",
      "Epoch: 1080, Loss: 1.0998\n",
      "Epoch: 1081, Loss: 1.0978\n",
      "Epoch: 1082, Loss: 1.1061\n",
      "Epoch: 1083, Loss: 1.0961\n",
      "Epoch: 1084, Loss: 1.1096\n",
      "Epoch: 1085, Loss: 1.1123\n",
      "Epoch: 1086, Loss: 1.0991\n",
      "Epoch: 1087, Loss: 1.1164\n",
      "Epoch: 1088, Loss: 1.1059\n",
      "Epoch: 1089, Loss: 1.1080\n",
      "Epoch: 1090, Loss: 1.1014\n",
      "Epoch: 1091, Loss: 1.1072\n",
      "Epoch: 1092, Loss: 1.1020\n",
      "Epoch: 1093, Loss: 1.1036\n",
      "Epoch: 1094, Loss: 1.1006\n",
      "Epoch: 1095, Loss: 1.0876\n",
      "Epoch: 1096, Loss: 1.0998\n",
      "Epoch: 1097, Loss: 1.1035\n",
      "Epoch: 1098, Loss: 1.0961\n",
      "Epoch: 1099, Loss: 1.1020\n",
      "Epoch: 1100, Loss: 1.1066\n",
      "Epoch: 1101, Loss: 1.0976\n",
      "Epoch: 1102, Loss: 1.0886\n",
      "Epoch: 1103, Loss: 1.0979\n",
      "Epoch: 1104, Loss: 1.1135\n",
      "Epoch: 1105, Loss: 1.1115\n",
      "Epoch: 1106, Loss: 1.1006\n",
      "Epoch: 1107, Loss: 1.1037\n",
      "Epoch: 1108, Loss: 1.0895\n",
      "Epoch: 1109, Loss: 1.0948\n",
      "Epoch: 1110, Loss: 1.1160\n",
      "Epoch: 1111, Loss: 1.1003\n",
      "Epoch: 1112, Loss: 1.1134\n",
      "Epoch: 1113, Loss: 1.0945\n",
      "Epoch: 1114, Loss: 1.0822\n",
      "Epoch: 1115, Loss: 1.1094\n",
      "Epoch: 1116, Loss: 1.0929\n",
      "Epoch: 1117, Loss: 1.0949\n",
      "Epoch: 1118, Loss: 1.1088\n",
      "Epoch: 1119, Loss: 1.0962\n",
      "Epoch: 1120, Loss: 1.1004\n",
      "Epoch: 1121, Loss: 1.1163\n",
      "Epoch: 1122, Loss: 1.1081\n",
      "Epoch: 1123, Loss: 1.0924\n",
      "Epoch: 1124, Loss: 1.1039\n",
      "Epoch: 1125, Loss: 1.1074\n",
      "Epoch: 1126, Loss: 1.0937\n",
      "Epoch: 1127, Loss: 1.0986\n",
      "Epoch: 1128, Loss: 1.0917\n",
      "Epoch: 1129, Loss: 1.1011\n",
      "Epoch: 1130, Loss: 1.0973\n",
      "Epoch: 1131, Loss: 1.0926\n",
      "Epoch: 1132, Loss: 1.0916\n",
      "Epoch: 1133, Loss: 1.0874\n",
      "Epoch: 1134, Loss: 1.0897\n",
      "Epoch: 1135, Loss: 1.0962\n",
      "Epoch: 1136, Loss: 1.0985\n",
      "Epoch: 1137, Loss: 1.0948\n",
      "Epoch: 1138, Loss: 1.0912\n",
      "Epoch: 1139, Loss: 1.0909\n",
      "Epoch: 1140, Loss: 1.0967\n",
      "Epoch: 1141, Loss: 1.1036\n",
      "Epoch: 1142, Loss: 1.1003\n",
      "Epoch: 1143, Loss: 1.1102\n",
      "Epoch: 1144, Loss: 1.0904\n",
      "Epoch: 1145, Loss: 1.0994\n",
      "Epoch: 1146, Loss: 1.0987\n",
      "Epoch: 1147, Loss: 1.0950\n",
      "Epoch: 1148, Loss: 1.0972\n",
      "Epoch: 1149, Loss: 1.0847\n",
      "Epoch: 1150, Loss: 1.0815\n",
      "Epoch: 1151, Loss: 1.0928\n",
      "Epoch: 1152, Loss: 1.0835\n",
      "Epoch: 1153, Loss: 1.0978\n",
      "Epoch: 1154, Loss: 1.1132\n",
      "Epoch: 1155, Loss: 1.1139\n",
      "Epoch: 1156, Loss: 1.0985\n",
      "Epoch: 1157, Loss: 1.0891\n",
      "Epoch: 1158, Loss: 1.0997\n",
      "Epoch: 1159, Loss: 1.0839\n",
      "Epoch: 1160, Loss: 1.0937\n",
      "Epoch: 1161, Loss: 1.1022\n",
      "Epoch: 1162, Loss: 1.0981\n",
      "Epoch: 1163, Loss: 1.0809\n",
      "Epoch: 1164, Loss: 1.0946\n",
      "Epoch: 1165, Loss: 1.1037\n",
      "Epoch: 1166, Loss: 1.0944\n",
      "Epoch: 1167, Loss: 1.0914\n",
      "Epoch: 1168, Loss: 1.0880\n",
      "Epoch: 1169, Loss: 1.0887\n",
      "Epoch: 1170, Loss: 1.0977\n",
      "Epoch: 1171, Loss: 1.0914\n",
      "Epoch: 1172, Loss: 1.0934\n",
      "Epoch: 1173, Loss: 1.0897\n",
      "Epoch: 1174, Loss: 1.0938\n",
      "Epoch: 1175, Loss: 1.1027\n",
      "Epoch: 1176, Loss: 1.0732\n",
      "Epoch: 1177, Loss: 1.1048\n",
      "Epoch: 1178, Loss: 1.0872\n",
      "Epoch: 1179, Loss: 1.0893\n",
      "Epoch: 1180, Loss: 1.0800\n",
      "Epoch: 1181, Loss: 1.0940\n",
      "Epoch: 1182, Loss: 1.0975\n",
      "Epoch: 1183, Loss: 1.0933\n",
      "Epoch: 1184, Loss: 1.0913\n",
      "Epoch: 1185, Loss: 1.0842\n",
      "Epoch: 1186, Loss: 1.0921\n",
      "Epoch: 1187, Loss: 1.0844\n",
      "Epoch: 1188, Loss: 1.0865\n",
      "Epoch: 1189, Loss: 1.0849\n",
      "Epoch: 1190, Loss: 1.0879\n",
      "Epoch: 1191, Loss: 1.1024\n",
      "Epoch: 1192, Loss: 1.0813\n",
      "Epoch: 1193, Loss: 1.0850\n",
      "Epoch: 1194, Loss: 1.0885\n",
      "Epoch: 1195, Loss: 1.1053\n",
      "Epoch: 1196, Loss: 1.0936\n",
      "Epoch: 1197, Loss: 1.0909\n",
      "Epoch: 1198, Loss: 1.0978\n",
      "Epoch: 1199, Loss: 1.0971\n",
      "Epoch: 1200, Loss: 1.0957\n",
      "Epoch: 1201, Loss: 1.0889\n",
      "Epoch: 1202, Loss: 1.1059\n",
      "Epoch: 1203, Loss: 1.1095\n",
      "Epoch: 1204, Loss: 1.0873\n",
      "Epoch: 1205, Loss: 1.0878\n",
      "Epoch: 1206, Loss: 1.0846\n",
      "Epoch: 1207, Loss: 1.0896\n",
      "Epoch: 1208, Loss: 1.0931\n",
      "Epoch: 1209, Loss: 1.0866\n",
      "Epoch: 1210, Loss: 1.0893\n",
      "Epoch: 1211, Loss: 1.0800\n",
      "Epoch: 1212, Loss: 1.0891\n",
      "Epoch: 1213, Loss: 1.0961\n",
      "Epoch: 1214, Loss: 1.0974\n",
      "Epoch: 1215, Loss: 1.0912\n",
      "Epoch: 1216, Loss: 1.0963\n",
      "Epoch: 1217, Loss: 1.0860\n",
      "Epoch: 1218, Loss: 1.0928\n",
      "Epoch: 1219, Loss: 1.0779\n",
      "Epoch: 1220, Loss: 1.0827\n",
      "Epoch: 1221, Loss: 1.0867\n",
      "Epoch: 1222, Loss: 1.0841\n",
      "Epoch: 1223, Loss: 1.0739\n",
      "Epoch: 1224, Loss: 1.0787\n",
      "Epoch: 1225, Loss: 1.0704\n",
      "Epoch: 1226, Loss: 1.0691\n",
      "Epoch: 1227, Loss: 1.0836\n",
      "Epoch: 1228, Loss: 1.0705\n",
      "Epoch: 1229, Loss: 1.0853\n",
      "Epoch: 1230, Loss: 1.0847\n",
      "Epoch: 1231, Loss: 1.0947\n",
      "Epoch: 1232, Loss: 1.0984\n",
      "Epoch: 1233, Loss: 1.0730\n",
      "Epoch: 1234, Loss: 1.0906\n",
      "Epoch: 1235, Loss: 1.0831\n",
      "Epoch: 1236, Loss: 1.0884\n",
      "Epoch: 1237, Loss: 1.0746\n",
      "Epoch: 1238, Loss: 1.0890\n",
      "Epoch: 1239, Loss: 1.0816\n",
      "Epoch: 1240, Loss: 1.0788\n",
      "Epoch: 1241, Loss: 1.0905\n",
      "Epoch: 1242, Loss: 1.0916\n",
      "Epoch: 1243, Loss: 1.0760\n",
      "Epoch: 1244, Loss: 1.0893\n",
      "Epoch: 1245, Loss: 1.0860\n",
      "Epoch: 1246, Loss: 1.0730\n",
      "Epoch: 1247, Loss: 1.0831\n",
      "Epoch: 1248, Loss: 1.0730\n",
      "Epoch: 1249, Loss: 1.0812\n",
      "Epoch: 1250, Loss: 1.0724\n",
      "Epoch: 1251, Loss: 1.0796\n",
      "Epoch: 1252, Loss: 1.0855\n",
      "Epoch: 1253, Loss: 1.0970\n",
      "Epoch: 1254, Loss: 1.0813\n",
      "Epoch: 1255, Loss: 1.0818\n",
      "Epoch: 1256, Loss: 1.0848\n",
      "Epoch: 1257, Loss: 1.0894\n",
      "Epoch: 1258, Loss: 1.0940\n",
      "Epoch: 1259, Loss: 1.0895\n",
      "Epoch: 1260, Loss: 1.0750\n",
      "Epoch: 1261, Loss: 1.0791\n",
      "Epoch: 1262, Loss: 1.0862\n",
      "Epoch: 1263, Loss: 1.0734\n",
      "Epoch: 1264, Loss: 1.0696\n",
      "Epoch: 1265, Loss: 1.0850\n",
      "Epoch: 1266, Loss: 1.0863\n",
      "Epoch: 1267, Loss: 1.0753\n",
      "Epoch: 1268, Loss: 1.0896\n",
      "Epoch: 1269, Loss: 1.0806\n",
      "Epoch: 1270, Loss: 1.0882\n",
      "Epoch: 1271, Loss: 1.0796\n",
      "Epoch: 1272, Loss: 1.0719\n",
      "Epoch: 1273, Loss: 1.0729\n",
      "Epoch: 1274, Loss: 1.0991\n",
      "Epoch: 1275, Loss: 1.0841\n",
      "Epoch: 1276, Loss: 1.0728\n",
      "Epoch: 1277, Loss: 1.0961\n",
      "Epoch: 1278, Loss: 1.0872\n",
      "Epoch: 1279, Loss: 1.0781\n",
      "Epoch: 1280, Loss: 1.0699\n",
      "Epoch: 1281, Loss: 1.0950\n",
      "Epoch: 1282, Loss: 1.0915\n",
      "Epoch: 1283, Loss: 1.0846\n",
      "Epoch: 1284, Loss: 1.0724\n",
      "Epoch: 1285, Loss: 1.0697\n",
      "Epoch: 1286, Loss: 1.0893\n",
      "Epoch: 1287, Loss: 1.0820\n",
      "Epoch: 1288, Loss: 1.0689\n",
      "Epoch: 1289, Loss: 1.0873\n",
      "Epoch: 1290, Loss: 1.0920\n",
      "Epoch: 1291, Loss: 1.0915\n",
      "Epoch: 1292, Loss: 1.0782\n",
      "Epoch: 1293, Loss: 1.0744\n",
      "Epoch: 1294, Loss: 1.0637\n",
      "Epoch: 1295, Loss: 1.0895\n",
      "Epoch: 1296, Loss: 1.0861\n",
      "Epoch: 1297, Loss: 1.0789\n",
      "Epoch: 1298, Loss: 1.0733\n",
      "Epoch: 1299, Loss: 1.0734\n",
      "Epoch: 1300, Loss: 1.0663\n",
      "Epoch: 1301, Loss: 1.0740\n",
      "Epoch: 1302, Loss: 1.0832\n",
      "Epoch: 1303, Loss: 1.0716\n",
      "Epoch: 1304, Loss: 1.0918\n",
      "Epoch: 1305, Loss: 1.0709\n",
      "Epoch: 1306, Loss: 1.0954\n",
      "Epoch: 1307, Loss: 1.0748\n",
      "Epoch: 1308, Loss: 1.0895\n",
      "Epoch: 1309, Loss: 1.0666\n",
      "Epoch: 1310, Loss: 1.0785\n",
      "Epoch: 1311, Loss: 1.0669\n",
      "Epoch: 1312, Loss: 1.0874\n",
      "Epoch: 1313, Loss: 1.0855\n",
      "Epoch: 1314, Loss: 1.0749\n",
      "Epoch: 1315, Loss: 1.0792\n",
      "Epoch: 1316, Loss: 1.0787\n",
      "Epoch: 1317, Loss: 1.1041\n",
      "Epoch: 1318, Loss: 1.0752\n",
      "Epoch: 1319, Loss: 1.0646\n",
      "Epoch: 1320, Loss: 1.0663\n",
      "Epoch: 1321, Loss: 1.0810\n",
      "Epoch: 1322, Loss: 1.0720\n",
      "Epoch: 1323, Loss: 1.0823\n",
      "Epoch: 1324, Loss: 1.0798\n",
      "Epoch: 1325, Loss: 1.0811\n",
      "Epoch: 1326, Loss: 1.0850\n",
      "Epoch: 1327, Loss: 1.0792\n",
      "Epoch: 1328, Loss: 1.0893\n",
      "Epoch: 1329, Loss: 1.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1330, Loss: 1.0744\n",
      "Epoch: 1331, Loss: 1.0778\n",
      "Epoch: 1332, Loss: 1.0810\n",
      "Epoch: 1333, Loss: 1.0748\n",
      "Epoch: 1334, Loss: 1.0694\n",
      "Epoch: 1335, Loss: 1.0653\n",
      "Epoch: 1336, Loss: 1.0599\n",
      "Epoch: 1337, Loss: 1.0969\n",
      "Epoch: 1338, Loss: 1.0820\n",
      "Epoch: 1339, Loss: 1.0888\n",
      "Epoch: 1340, Loss: 1.0808\n",
      "Epoch: 1341, Loss: 1.0819\n",
      "Epoch: 1342, Loss: 1.0765\n",
      "Epoch: 1343, Loss: 1.0754\n",
      "Epoch: 1344, Loss: 1.0902\n",
      "Epoch: 1345, Loss: 1.0688\n",
      "Epoch: 1346, Loss: 1.0578\n",
      "Epoch: 1347, Loss: 1.0773\n",
      "Epoch: 1348, Loss: 1.0644\n",
      "Epoch: 1349, Loss: 1.0826\n",
      "Epoch: 1350, Loss: 1.0598\n",
      "Epoch: 1351, Loss: 1.0746\n",
      "Epoch: 1352, Loss: 1.0594\n",
      "Epoch: 1353, Loss: 1.0980\n",
      "Epoch: 1354, Loss: 1.0669\n",
      "Epoch: 1355, Loss: 1.0829\n",
      "Epoch: 1356, Loss: 1.0700\n",
      "Epoch: 1357, Loss: 1.0690\n",
      "Epoch: 1358, Loss: 1.0663\n",
      "Epoch: 1359, Loss: 1.0847\n",
      "Epoch: 1360, Loss: 1.0680\n",
      "Epoch: 1361, Loss: 1.0714\n",
      "Epoch: 1362, Loss: 1.0825\n",
      "Epoch: 1363, Loss: 1.0784\n",
      "Epoch: 1364, Loss: 1.0730\n",
      "Epoch: 1365, Loss: 1.0847\n",
      "Epoch: 1366, Loss: 1.0839\n",
      "Epoch: 1367, Loss: 1.0776\n",
      "Epoch: 1368, Loss: 1.0581\n",
      "Epoch: 1369, Loss: 1.0764\n",
      "Epoch: 1370, Loss: 1.0800\n",
      "Epoch: 1371, Loss: 1.0727\n",
      "Epoch: 1372, Loss: 1.0734\n",
      "Epoch: 1373, Loss: 1.0776\n",
      "Epoch: 1374, Loss: 1.0713\n",
      "Epoch: 1375, Loss: 1.0740\n",
      "Epoch: 1376, Loss: 1.0656\n",
      "Epoch: 1377, Loss: 1.0663\n",
      "Epoch: 1378, Loss: 1.0673\n",
      "Epoch: 1379, Loss: 1.0672\n",
      "Epoch: 1380, Loss: 1.0777\n",
      "Epoch: 1381, Loss: 1.0684\n",
      "Epoch: 1382, Loss: 1.0535\n",
      "Epoch: 1383, Loss: 1.0769\n",
      "Epoch: 1384, Loss: 1.0833\n",
      "Epoch: 1385, Loss: 1.0770\n",
      "Epoch: 1386, Loss: 1.0662\n",
      "Epoch: 1387, Loss: 1.0690\n",
      "Epoch: 1388, Loss: 1.0616\n",
      "Epoch: 1389, Loss: 1.0757\n",
      "Epoch: 1390, Loss: 1.0619\n",
      "Epoch: 1391, Loss: 1.0852\n",
      "Epoch: 1392, Loss: 1.0464\n",
      "Epoch: 1393, Loss: 1.0709\n",
      "Epoch: 1394, Loss: 1.0622\n",
      "Epoch: 1395, Loss: 1.0726\n",
      "Epoch: 1396, Loss: 1.0630\n",
      "Epoch: 1397, Loss: 1.0652\n",
      "Epoch: 1398, Loss: 1.0811\n",
      "Epoch: 1399, Loss: 1.0536\n",
      "Epoch: 1400, Loss: 1.0766\n",
      "Epoch: 1401, Loss: 1.0612\n",
      "Epoch: 1402, Loss: 1.0743\n",
      "Epoch: 1403, Loss: 1.0587\n",
      "Epoch: 1404, Loss: 1.0737\n",
      "Epoch: 1405, Loss: 1.0656\n",
      "Epoch: 1406, Loss: 1.0642\n",
      "Epoch: 1407, Loss: 1.0497\n",
      "Epoch: 1408, Loss: 1.0686\n",
      "Epoch: 1409, Loss: 1.0673\n",
      "Epoch: 1410, Loss: 1.0799\n",
      "Epoch: 1411, Loss: 1.0585\n",
      "Epoch: 1412, Loss: 1.0644\n",
      "Epoch: 1413, Loss: 1.0736\n",
      "Epoch: 1414, Loss: 1.0756\n",
      "Epoch: 1415, Loss: 1.0662\n",
      "Epoch: 1416, Loss: 1.0522\n",
      "Epoch: 1417, Loss: 1.0791\n",
      "Epoch: 1418, Loss: 1.0593\n",
      "Epoch: 1419, Loss: 1.0643\n",
      "Epoch: 1420, Loss: 1.0743\n",
      "Epoch: 1421, Loss: 1.0618\n",
      "Epoch: 1422, Loss: 1.0613\n",
      "Epoch: 1423, Loss: 1.0791\n",
      "Epoch: 1424, Loss: 1.0611\n",
      "Epoch: 1425, Loss: 1.0648\n",
      "Epoch: 1426, Loss: 1.0642\n",
      "Epoch: 1427, Loss: 1.0678\n",
      "Epoch: 1428, Loss: 1.0553\n",
      "Epoch: 1429, Loss: 1.0534\n",
      "Epoch: 1430, Loss: 1.0612\n",
      "Epoch: 1431, Loss: 1.0555\n",
      "Epoch: 1432, Loss: 1.0575\n",
      "Epoch: 1433, Loss: 1.0801\n",
      "Epoch: 1434, Loss: 1.0665\n",
      "Epoch: 1435, Loss: 1.0733\n",
      "Epoch: 1436, Loss: 1.0546\n",
      "Epoch: 1437, Loss: 1.0531\n",
      "Epoch: 1438, Loss: 1.0704\n",
      "Epoch: 1439, Loss: 1.0638\n",
      "Epoch: 1440, Loss: 1.0685\n",
      "Epoch: 1441, Loss: 1.0701\n",
      "Epoch: 1442, Loss: 1.0605\n",
      "Epoch: 1443, Loss: 1.0846\n",
      "Epoch: 1444, Loss: 1.0678\n",
      "Epoch: 1445, Loss: 1.0523\n",
      "Epoch: 1446, Loss: 1.0735\n",
      "Epoch: 1447, Loss: 1.0661\n",
      "Epoch: 1448, Loss: 1.0562\n",
      "Epoch: 1449, Loss: 1.0706\n",
      "Epoch: 1450, Loss: 1.0492\n",
      "Epoch: 1451, Loss: 1.0621\n",
      "Epoch: 1452, Loss: 1.0619\n",
      "Epoch: 1453, Loss: 1.0720\n",
      "Epoch: 1454, Loss: 1.0616\n",
      "Epoch: 1455, Loss: 1.0446\n",
      "Epoch: 1456, Loss: 1.0580\n",
      "Epoch: 1457, Loss: 1.0649\n",
      "Epoch: 1458, Loss: 1.0605\n",
      "Epoch: 1459, Loss: 1.0601\n",
      "Epoch: 1460, Loss: 1.0552\n",
      "Epoch: 1461, Loss: 1.0644\n",
      "Epoch: 1462, Loss: 1.0680\n",
      "Epoch: 1463, Loss: 1.0563\n",
      "Epoch: 1464, Loss: 1.0583\n",
      "Epoch: 1465, Loss: 1.0595\n",
      "Epoch: 1466, Loss: 1.0643\n",
      "Epoch: 1467, Loss: 1.0593\n",
      "Epoch: 1468, Loss: 1.0626\n",
      "Epoch: 1469, Loss: 1.0685\n",
      "Epoch: 1470, Loss: 1.0654\n",
      "Epoch: 1471, Loss: 1.0544\n",
      "Epoch: 1472, Loss: 1.0582\n",
      "Epoch: 1473, Loss: 1.0501\n",
      "Epoch: 1474, Loss: 1.0593\n",
      "Epoch: 1475, Loss: 1.0530\n",
      "Epoch: 1476, Loss: 1.0561\n",
      "Epoch: 1477, Loss: 1.0559\n",
      "Epoch: 1478, Loss: 1.0682\n",
      "Epoch: 1479, Loss: 1.0657\n",
      "Epoch: 1480, Loss: 1.0636\n",
      "Epoch: 1481, Loss: 1.0545\n",
      "Epoch: 1482, Loss: 1.0768\n",
      "Epoch: 1483, Loss: 1.0624\n",
      "Epoch: 1484, Loss: 1.0645\n",
      "Epoch: 1485, Loss: 1.0636\n",
      "Epoch: 1486, Loss: 1.0547\n",
      "Epoch: 1487, Loss: 1.0683\n",
      "Epoch: 1488, Loss: 1.0771\n",
      "Epoch: 1489, Loss: 1.0685\n",
      "Epoch: 1490, Loss: 1.0682\n",
      "Epoch: 1491, Loss: 1.0534\n",
      "Epoch: 1492, Loss: 1.0717\n",
      "Epoch: 1493, Loss: 1.0606\n",
      "Epoch: 1494, Loss: 1.0578\n",
      "Epoch: 1495, Loss: 1.0614\n",
      "Epoch: 1496, Loss: 1.0530\n",
      "Epoch: 1497, Loss: 1.0692\n",
      "Epoch: 1498, Loss: 1.0444\n",
      "Epoch: 1499, Loss: 1.0680\n",
      "Epoch: 1500, Loss: 1.0678\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "    \n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "    roc_auc = roc_auc_score(lb.transform(data.y[data.test_mask].cpu()),lb.transform(pred[data.test_mask].cpu()), multi_class='ovo')\n",
    "    return test_acc, roc_auc\n",
    "    \n",
    "# to calculate roc_auc, the data needs to be one hot encoded, which I am doing using LabelBinarizer()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(data.y[data.train_mask].cpu())\n",
    "\n",
    "epoch_list = list()\n",
    "loss_list = list()\n",
    "acc_list = list()\n",
    "roc_list = list()\n",
    "for epoch in range(1, 1501):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    # calculate test set accuracy\n",
    "    model.eval()\n",
    "    out = model(data.x)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "    acc_list.append(test_acc)\n",
    "    roc_auc = roc_auc_score(lb.transform(data.y[data.test_mask].cpu()),lb.transform(pred[data.test_mask].cpu()), multi_class='ovo')\n",
    "    roc_list.append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf98ec",
   "metadata": {},
   "source": [
    "After training the model, I call the `test` function to see how well the model performs. I also write the `test` function to output the ROC AUC since the classes are unbalanced. I can see the performance is pretty poor when using just the feature vectors. A big reason for this is that connected products are very likely related to the category of the product. This is where Graph Neural Networks can potentially boost the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b54f7",
   "metadata": {},
   "source": [
    "Below, I can see that within about 150 epochs, the ROC AUC levels off and the model begins overfitting. The model begins overfitting much faster here than with the GNN since there is less data to work from, since the model does not have access to the links between the nodes and is only making predictions based on the feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc0c55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, loss_list, label= \"Loss\")\n",
    "plt.plot(epoch_list, acc_list, label = \"Val Accuracy\")\n",
    "plt.plot(epoch_list, roc_list, label = \"Val ROC AUC\")\n",
    "plt.title(\"Loss, ROC AUC, and Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1100173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy last epoch: 0.5824\n",
      "Val ROC AUC last epoch: 0.5974\n",
      "\n",
      "Val Accuracy at epoch 150: 0.4736\n",
      "Val ROC AUC epoch 150: 0.5526\n"
     ]
    }
   ],
   "source": [
    "print(f'Val Accuracy last epoch: {acc_list[-1]:.4f}')\n",
    "print(f'Val ROC AUC last epoch: {roc_list[-1]:.4f}')\n",
    "print()\n",
    "print(f'Val Accuracy at epoch 150: {acc_list[150]:.4f}')\n",
    "print(f'Val ROC AUC epoch 150: {roc_list[150]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af26cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5525799365020401"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_list[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582aacf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(767, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (conv3): GCNConv(16, 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "605d641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 2.3026\n",
      "Epoch: 002, Loss: 2.2911\n",
      "Epoch: 003, Loss: 2.2761\n",
      "Epoch: 004, Loss: 2.2610\n",
      "Epoch: 005, Loss: 2.2442\n",
      "Epoch: 006, Loss: 2.2256\n",
      "Epoch: 007, Loss: 2.2049\n",
      "Epoch: 008, Loss: 2.1857\n",
      "Epoch: 009, Loss: 2.1606\n",
      "Epoch: 010, Loss: 2.1369\n",
      "Epoch: 011, Loss: 2.1187\n",
      "Epoch: 012, Loss: 2.0920\n",
      "Epoch: 013, Loss: 2.0697\n",
      "Epoch: 014, Loss: 2.0420\n",
      "Epoch: 015, Loss: 2.0180\n",
      "Epoch: 016, Loss: 1.9955\n",
      "Epoch: 017, Loss: 1.9796\n",
      "Epoch: 018, Loss: 1.9643\n",
      "Epoch: 019, Loss: 1.9521\n",
      "Epoch: 020, Loss: 1.9447\n",
      "Epoch: 021, Loss: 1.9460\n",
      "Epoch: 022, Loss: 1.9308\n",
      "Epoch: 023, Loss: 1.9420\n",
      "Epoch: 024, Loss: 1.9474\n",
      "Epoch: 025, Loss: 1.9462\n",
      "Epoch: 026, Loss: 1.9426\n",
      "Epoch: 027, Loss: 1.9488\n",
      "Epoch: 028, Loss: 1.9201\n",
      "Epoch: 029, Loss: 1.9286\n",
      "Epoch: 030, Loss: 1.9192\n",
      "Epoch: 031, Loss: 1.9182\n",
      "Epoch: 032, Loss: 1.9114\n",
      "Epoch: 033, Loss: 1.9202\n",
      "Epoch: 034, Loss: 1.9180\n",
      "Epoch: 035, Loss: 1.9143\n",
      "Epoch: 036, Loss: 1.9181\n",
      "Epoch: 037, Loss: 1.9094\n",
      "Epoch: 038, Loss: 1.9199\n",
      "Epoch: 039, Loss: 1.9166\n",
      "Epoch: 040, Loss: 1.9100\n",
      "Epoch: 041, Loss: 1.9055\n",
      "Epoch: 042, Loss: 1.9046\n",
      "Epoch: 043, Loss: 1.9128\n",
      "Epoch: 044, Loss: 1.9060\n",
      "Epoch: 045, Loss: 1.9045\n",
      "Epoch: 046, Loss: 1.9023\n",
      "Epoch: 047, Loss: 1.8986\n",
      "Epoch: 048, Loss: 1.9077\n",
      "Epoch: 049, Loss: 1.8950\n",
      "Epoch: 050, Loss: 1.8943\n",
      "Epoch: 051, Loss: 1.9076\n",
      "Epoch: 052, Loss: 1.9004\n",
      "Epoch: 053, Loss: 1.9022\n",
      "Epoch: 054, Loss: 1.9006\n",
      "Epoch: 055, Loss: 1.8973\n",
      "Epoch: 056, Loss: 1.8923\n",
      "Epoch: 057, Loss: 1.8894\n",
      "Epoch: 058, Loss: 1.8897\n",
      "Epoch: 059, Loss: 1.8955\n",
      "Epoch: 060, Loss: 1.8978\n",
      "Epoch: 061, Loss: 1.8938\n",
      "Epoch: 062, Loss: 1.8914\n",
      "Epoch: 063, Loss: 1.8909\n",
      "Epoch: 064, Loss: 1.8851\n",
      "Epoch: 065, Loss: 1.8867\n",
      "Epoch: 066, Loss: 1.8907\n",
      "Epoch: 067, Loss: 1.8819\n",
      "Epoch: 068, Loss: 1.8851\n",
      "Epoch: 069, Loss: 1.8765\n",
      "Epoch: 070, Loss: 1.8748\n",
      "Epoch: 071, Loss: 1.8811\n",
      "Epoch: 072, Loss: 1.8727\n",
      "Epoch: 073, Loss: 1.8747\n",
      "Epoch: 074, Loss: 1.8718\n",
      "Epoch: 075, Loss: 1.8625\n",
      "Epoch: 076, Loss: 1.8655\n",
      "Epoch: 077, Loss: 1.8577\n",
      "Epoch: 078, Loss: 1.8554\n",
      "Epoch: 079, Loss: 1.8518\n",
      "Epoch: 080, Loss: 1.8500\n",
      "Epoch: 081, Loss: 1.8429\n",
      "Epoch: 082, Loss: 1.8479\n",
      "Epoch: 083, Loss: 1.8369\n",
      "Epoch: 084, Loss: 1.8321\n",
      "Epoch: 085, Loss: 1.8332\n",
      "Epoch: 086, Loss: 1.8190\n",
      "Epoch: 087, Loss: 1.8183\n",
      "Epoch: 088, Loss: 1.8098\n",
      "Epoch: 089, Loss: 1.7984\n",
      "Epoch: 090, Loss: 1.7913\n",
      "Epoch: 091, Loss: 1.7897\n",
      "Epoch: 092, Loss: 1.7850\n",
      "Epoch: 093, Loss: 1.7724\n",
      "Epoch: 094, Loss: 1.7653\n",
      "Epoch: 095, Loss: 1.7555\n",
      "Epoch: 096, Loss: 1.7481\n",
      "Epoch: 097, Loss: 1.7360\n",
      "Epoch: 098, Loss: 1.7263\n",
      "Epoch: 099, Loss: 1.7169\n",
      "Epoch: 100, Loss: 1.7113\n",
      "Epoch: 101, Loss: 1.6996\n",
      "Epoch: 102, Loss: 1.6880\n",
      "Epoch: 103, Loss: 1.6835\n",
      "Epoch: 104, Loss: 1.6767\n",
      "Epoch: 105, Loss: 1.6695\n",
      "Epoch: 106, Loss: 1.6495\n",
      "Epoch: 107, Loss: 1.6529\n",
      "Epoch: 108, Loss: 1.6480\n",
      "Epoch: 109, Loss: 1.6334\n",
      "Epoch: 110, Loss: 1.6241\n",
      "Epoch: 111, Loss: 1.6222\n",
      "Epoch: 112, Loss: 1.6087\n",
      "Epoch: 113, Loss: 1.6111\n",
      "Epoch: 114, Loss: 1.5990\n",
      "Epoch: 115, Loss: 1.6103\n",
      "Epoch: 116, Loss: 1.5937\n",
      "Epoch: 117, Loss: 1.5903\n",
      "Epoch: 118, Loss: 1.5814\n",
      "Epoch: 119, Loss: 1.5762\n",
      "Epoch: 120, Loss: 1.5681\n",
      "Epoch: 121, Loss: 1.5664\n",
      "Epoch: 122, Loss: 1.5601\n",
      "Epoch: 123, Loss: 1.5609\n",
      "Epoch: 124, Loss: 1.5555\n",
      "Epoch: 125, Loss: 1.5473\n",
      "Epoch: 126, Loss: 1.5505\n",
      "Epoch: 127, Loss: 1.5392\n",
      "Epoch: 128, Loss: 1.5413\n",
      "Epoch: 129, Loss: 1.5368\n",
      "Epoch: 130, Loss: 1.5375\n",
      "Epoch: 131, Loss: 1.5268\n",
      "Epoch: 132, Loss: 1.5309\n",
      "Epoch: 133, Loss: 1.5124\n",
      "Epoch: 134, Loss: 1.5163\n",
      "Epoch: 135, Loss: 1.5195\n",
      "Epoch: 136, Loss: 1.5155\n",
      "Epoch: 137, Loss: 1.5044\n",
      "Epoch: 138, Loss: 1.5099\n",
      "Epoch: 139, Loss: 1.4900\n",
      "Epoch: 140, Loss: 1.5002\n",
      "Epoch: 141, Loss: 1.5053\n",
      "Epoch: 142, Loss: 1.4898\n",
      "Epoch: 143, Loss: 1.4955\n",
      "Epoch: 144, Loss: 1.4821\n",
      "Epoch: 145, Loss: 1.4786\n",
      "Epoch: 146, Loss: 1.4852\n",
      "Epoch: 147, Loss: 1.4819\n",
      "Epoch: 148, Loss: 1.4760\n",
      "Epoch: 149, Loss: 1.4745\n",
      "Epoch: 150, Loss: 1.4739\n",
      "Epoch: 151, Loss: 1.4620\n",
      "Epoch: 152, Loss: 1.4618\n",
      "Epoch: 153, Loss: 1.4599\n",
      "Epoch: 154, Loss: 1.4631\n",
      "Epoch: 155, Loss: 1.4589\n",
      "Epoch: 156, Loss: 1.4537\n",
      "Epoch: 157, Loss: 1.4555\n",
      "Epoch: 158, Loss: 1.4537\n",
      "Epoch: 159, Loss: 1.4373\n",
      "Epoch: 160, Loss: 1.4456\n",
      "Epoch: 161, Loss: 1.4437\n",
      "Epoch: 162, Loss: 1.4346\n",
      "Epoch: 163, Loss: 1.4420\n",
      "Epoch: 164, Loss: 1.4315\n",
      "Epoch: 165, Loss: 1.4348\n",
      "Epoch: 166, Loss: 1.4223\n",
      "Epoch: 167, Loss: 1.4294\n",
      "Epoch: 168, Loss: 1.4268\n",
      "Epoch: 169, Loss: 1.4239\n",
      "Epoch: 170, Loss: 1.4150\n",
      "Epoch: 171, Loss: 1.4221\n",
      "Epoch: 172, Loss: 1.4185\n",
      "Epoch: 173, Loss: 1.4066\n",
      "Epoch: 174, Loss: 1.4094\n",
      "Epoch: 175, Loss: 1.4062\n",
      "Epoch: 176, Loss: 1.4108\n",
      "Epoch: 177, Loss: 1.4014\n",
      "Epoch: 178, Loss: 1.4049\n",
      "Epoch: 179, Loss: 1.4086\n",
      "Epoch: 180, Loss: 1.4016\n",
      "Epoch: 181, Loss: 1.4042\n",
      "Epoch: 182, Loss: 1.4039\n",
      "Epoch: 183, Loss: 1.3972\n",
      "Epoch: 184, Loss: 1.3987\n",
      "Epoch: 185, Loss: 1.3821\n",
      "Epoch: 186, Loss: 1.3934\n",
      "Epoch: 187, Loss: 1.4012\n",
      "Epoch: 188, Loss: 1.3796\n",
      "Epoch: 189, Loss: 1.3872\n",
      "Epoch: 190, Loss: 1.3774\n",
      "Epoch: 191, Loss: 1.3833\n",
      "Epoch: 192, Loss: 1.3773\n",
      "Epoch: 193, Loss: 1.3784\n",
      "Epoch: 194, Loss: 1.3703\n",
      "Epoch: 195, Loss: 1.3778\n",
      "Epoch: 196, Loss: 1.3776\n",
      "Epoch: 197, Loss: 1.3648\n",
      "Epoch: 198, Loss: 1.3787\n",
      "Epoch: 199, Loss: 1.3646\n",
      "Epoch: 200, Loss: 1.3752\n",
      "Epoch: 201, Loss: 1.3603\n",
      "Epoch: 202, Loss: 1.3803\n",
      "Epoch: 203, Loss: 1.3619\n",
      "Epoch: 204, Loss: 1.3480\n",
      "Epoch: 205, Loss: 1.3632\n",
      "Epoch: 206, Loss: 1.3612\n",
      "Epoch: 207, Loss: 1.3595\n",
      "Epoch: 208, Loss: 1.3668\n",
      "Epoch: 209, Loss: 1.3559\n",
      "Epoch: 210, Loss: 1.3484\n",
      "Epoch: 211, Loss: 1.3551\n",
      "Epoch: 212, Loss: 1.3658\n",
      "Epoch: 213, Loss: 1.3515\n",
      "Epoch: 214, Loss: 1.3661\n",
      "Epoch: 215, Loss: 1.3471\n",
      "Epoch: 216, Loss: 1.3625\n",
      "Epoch: 217, Loss: 1.3530\n",
      "Epoch: 218, Loss: 1.3295\n",
      "Epoch: 219, Loss: 1.3279\n",
      "Epoch: 220, Loss: 1.3425\n",
      "Epoch: 221, Loss: 1.3350\n",
      "Epoch: 222, Loss: 1.3318\n",
      "Epoch: 223, Loss: 1.3363\n",
      "Epoch: 224, Loss: 1.3325\n",
      "Epoch: 225, Loss: 1.3511\n",
      "Epoch: 226, Loss: 1.3306\n",
      "Epoch: 227, Loss: 1.3352\n",
      "Epoch: 228, Loss: 1.3372\n",
      "Epoch: 229, Loss: 1.3327\n",
      "Epoch: 230, Loss: 1.3310\n",
      "Epoch: 231, Loss: 1.3343\n",
      "Epoch: 232, Loss: 1.3245\n",
      "Epoch: 233, Loss: 1.3305\n",
      "Epoch: 234, Loss: 1.3197\n",
      "Epoch: 235, Loss: 1.3276\n",
      "Epoch: 236, Loss: 1.3280\n",
      "Epoch: 237, Loss: 1.3218\n",
      "Epoch: 238, Loss: 1.3232\n",
      "Epoch: 239, Loss: 1.3100\n",
      "Epoch: 240, Loss: 1.3031\n",
      "Epoch: 241, Loss: 1.3202\n",
      "Epoch: 242, Loss: 1.3036\n",
      "Epoch: 243, Loss: 1.3224\n",
      "Epoch: 244, Loss: 1.3159\n",
      "Epoch: 245, Loss: 1.3009\n",
      "Epoch: 246, Loss: 1.3246\n",
      "Epoch: 247, Loss: 1.3127\n",
      "Epoch: 248, Loss: 1.3417\n",
      "Epoch: 249, Loss: 1.2981\n",
      "Epoch: 250, Loss: 1.3095\n",
      "Epoch: 251, Loss: 1.3005\n",
      "Epoch: 252, Loss: 1.3090\n",
      "Epoch: 253, Loss: 1.3098\n",
      "Epoch: 254, Loss: 1.2975\n",
      "Epoch: 255, Loss: 1.2964\n",
      "Epoch: 256, Loss: 1.2898\n",
      "Epoch: 257, Loss: 1.3117\n",
      "Epoch: 258, Loss: 1.3021\n",
      "Epoch: 259, Loss: 1.3066\n",
      "Epoch: 260, Loss: 1.2907\n",
      "Epoch: 261, Loss: 1.3116\n",
      "Epoch: 262, Loss: 1.2911\n",
      "Epoch: 263, Loss: 1.2944\n",
      "Epoch: 264, Loss: 1.2838\n",
      "Epoch: 265, Loss: 1.3025\n",
      "Epoch: 266, Loss: 1.2949\n",
      "Epoch: 267, Loss: 1.2894\n",
      "Epoch: 268, Loss: 1.2783\n",
      "Epoch: 269, Loss: 1.2853\n",
      "Epoch: 270, Loss: 1.2953\n",
      "Epoch: 271, Loss: 1.2941\n",
      "Epoch: 272, Loss: 1.2900\n",
      "Epoch: 273, Loss: 1.2827\n",
      "Epoch: 274, Loss: 1.2878\n",
      "Epoch: 275, Loss: 1.2705\n",
      "Epoch: 276, Loss: 1.2926\n",
      "Epoch: 277, Loss: 1.2767\n",
      "Epoch: 278, Loss: 1.2997\n",
      "Epoch: 279, Loss: 1.2834\n",
      "Epoch: 280, Loss: 1.2952\n",
      "Epoch: 281, Loss: 1.2687\n",
      "Epoch: 282, Loss: 1.2880\n",
      "Epoch: 283, Loss: 1.2673\n",
      "Epoch: 284, Loss: 1.2839\n",
      "Epoch: 285, Loss: 1.2552\n",
      "Epoch: 286, Loss: 1.2834\n",
      "Epoch: 287, Loss: 1.2805\n",
      "Epoch: 288, Loss: 1.2709\n",
      "Epoch: 289, Loss: 1.2972\n",
      "Epoch: 290, Loss: 1.2685\n",
      "Epoch: 291, Loss: 1.2650\n",
      "Epoch: 292, Loss: 1.2764\n",
      "Epoch: 293, Loss: 1.2799\n",
      "Epoch: 294, Loss: 1.2713\n",
      "Epoch: 295, Loss: 1.2715\n",
      "Epoch: 296, Loss: 1.2615\n",
      "Epoch: 297, Loss: 1.2876\n",
      "Epoch: 298, Loss: 1.2564\n",
      "Epoch: 299, Loss: 1.2707\n",
      "Epoch: 300, Loss: 1.2681\n",
      "Epoch: 301, Loss: 1.2608\n",
      "Epoch: 302, Loss: 1.2642\n",
      "Epoch: 303, Loss: 1.2732\n",
      "Epoch: 304, Loss: 1.2646\n",
      "Epoch: 305, Loss: 1.2715\n",
      "Epoch: 306, Loss: 1.2590\n",
      "Epoch: 307, Loss: 1.2697\n",
      "Epoch: 308, Loss: 1.2591\n",
      "Epoch: 309, Loss: 1.2685\n",
      "Epoch: 310, Loss: 1.2723\n",
      "Epoch: 311, Loss: 1.2584\n",
      "Epoch: 312, Loss: 1.2691\n",
      "Epoch: 313, Loss: 1.2627\n",
      "Epoch: 314, Loss: 1.2699\n",
      "Epoch: 315, Loss: 1.2669\n",
      "Epoch: 316, Loss: 1.2543\n",
      "Epoch: 317, Loss: 1.2581\n",
      "Epoch: 318, Loss: 1.2652\n",
      "Epoch: 319, Loss: 1.2559\n",
      "Epoch: 320, Loss: 1.2707\n",
      "Epoch: 321, Loss: 1.2545\n",
      "Epoch: 322, Loss: 1.2703\n",
      "Epoch: 323, Loss: 1.2659\n",
      "Epoch: 324, Loss: 1.2597\n",
      "Epoch: 325, Loss: 1.2736\n",
      "Epoch: 326, Loss: 1.2497\n",
      "Epoch: 327, Loss: 1.2456\n",
      "Epoch: 328, Loss: 1.2592\n",
      "Epoch: 329, Loss: 1.2581\n",
      "Epoch: 330, Loss: 1.2483\n",
      "Epoch: 331, Loss: 1.2728\n",
      "Epoch: 332, Loss: 1.2534\n",
      "Epoch: 333, Loss: 1.2605\n",
      "Epoch: 334, Loss: 1.2434\n",
      "Epoch: 335, Loss: 1.2459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 336, Loss: 1.2420\n",
      "Epoch: 337, Loss: 1.2576\n",
      "Epoch: 338, Loss: 1.2653\n",
      "Epoch: 339, Loss: 1.2682\n",
      "Epoch: 340, Loss: 1.2473\n",
      "Epoch: 341, Loss: 1.2768\n",
      "Epoch: 342, Loss: 1.2513\n",
      "Epoch: 343, Loss: 1.2568\n",
      "Epoch: 344, Loss: 1.2518\n",
      "Epoch: 345, Loss: 1.2688\n",
      "Epoch: 346, Loss: 1.2622\n",
      "Epoch: 347, Loss: 1.2590\n",
      "Epoch: 348, Loss: 1.2537\n",
      "Epoch: 349, Loss: 1.2624\n",
      "Epoch: 350, Loss: 1.2593\n",
      "Epoch: 351, Loss: 1.2522\n",
      "Epoch: 352, Loss: 1.2443\n",
      "Epoch: 353, Loss: 1.2527\n",
      "Epoch: 354, Loss: 1.2499\n",
      "Epoch: 355, Loss: 1.2524\n",
      "Epoch: 356, Loss: 1.2579\n",
      "Epoch: 357, Loss: 1.2353\n",
      "Epoch: 358, Loss: 1.2524\n",
      "Epoch: 359, Loss: 1.2393\n",
      "Epoch: 360, Loss: 1.2623\n",
      "Epoch: 361, Loss: 1.2522\n",
      "Epoch: 362, Loss: 1.2460\n",
      "Epoch: 363, Loss: 1.2466\n",
      "Epoch: 364, Loss: 1.2555\n",
      "Epoch: 365, Loss: 1.2686\n",
      "Epoch: 366, Loss: 1.2501\n",
      "Epoch: 367, Loss: 1.2346\n",
      "Epoch: 368, Loss: 1.2444\n",
      "Epoch: 369, Loss: 1.2433\n",
      "Epoch: 370, Loss: 1.2557\n",
      "Epoch: 371, Loss: 1.2380\n",
      "Epoch: 372, Loss: 1.2455\n",
      "Epoch: 373, Loss: 1.2420\n",
      "Epoch: 374, Loss: 1.2543\n",
      "Epoch: 375, Loss: 1.2389\n",
      "Epoch: 376, Loss: 1.2392\n",
      "Epoch: 377, Loss: 1.2382\n",
      "Epoch: 378, Loss: 1.2471\n",
      "Epoch: 379, Loss: 1.2451\n",
      "Epoch: 380, Loss: 1.2346\n",
      "Epoch: 381, Loss: 1.2319\n",
      "Epoch: 382, Loss: 1.2401\n",
      "Epoch: 383, Loss: 1.2285\n",
      "Epoch: 384, Loss: 1.2288\n",
      "Epoch: 385, Loss: 1.2351\n",
      "Epoch: 386, Loss: 1.2550\n",
      "Epoch: 387, Loss: 1.2206\n",
      "Epoch: 388, Loss: 1.2423\n",
      "Epoch: 389, Loss: 1.2388\n",
      "Epoch: 390, Loss: 1.2385\n",
      "Epoch: 391, Loss: 1.2142\n",
      "Epoch: 392, Loss: 1.2386\n",
      "Epoch: 393, Loss: 1.2448\n",
      "Epoch: 394, Loss: 1.2358\n",
      "Epoch: 395, Loss: 1.2301\n",
      "Epoch: 396, Loss: 1.2593\n",
      "Epoch: 397, Loss: 1.2461\n",
      "Epoch: 398, Loss: 1.2581\n",
      "Epoch: 399, Loss: 1.2416\n",
      "Epoch: 400, Loss: 1.2503\n",
      "Epoch: 401, Loss: 1.2411\n",
      "Epoch: 402, Loss: 1.2418\n",
      "Epoch: 403, Loss: 1.2457\n",
      "Epoch: 404, Loss: 1.2394\n",
      "Epoch: 405, Loss: 1.2375\n",
      "Epoch: 406, Loss: 1.2249\n",
      "Epoch: 407, Loss: 1.2355\n",
      "Epoch: 408, Loss: 1.2316\n",
      "Epoch: 409, Loss: 1.2272\n",
      "Epoch: 410, Loss: 1.2180\n",
      "Epoch: 411, Loss: 1.2422\n",
      "Epoch: 412, Loss: 1.2385\n",
      "Epoch: 413, Loss: 1.2224\n",
      "Epoch: 414, Loss: 1.2346\n",
      "Epoch: 415, Loss: 1.2347\n",
      "Epoch: 416, Loss: 1.2299\n",
      "Epoch: 417, Loss: 1.2282\n",
      "Epoch: 418, Loss: 1.2412\n",
      "Epoch: 419, Loss: 1.2218\n",
      "Epoch: 420, Loss: 1.2365\n",
      "Epoch: 421, Loss: 1.2269\n",
      "Epoch: 422, Loss: 1.2357\n",
      "Epoch: 423, Loss: 1.2250\n",
      "Epoch: 424, Loss: 1.2469\n",
      "Epoch: 425, Loss: 1.2377\n",
      "Epoch: 426, Loss: 1.2217\n",
      "Epoch: 427, Loss: 1.2333\n",
      "Epoch: 428, Loss: 1.2112\n",
      "Epoch: 429, Loss: 1.2316\n",
      "Epoch: 430, Loss: 1.2382\n",
      "Epoch: 431, Loss: 1.2277\n",
      "Epoch: 432, Loss: 1.2254\n",
      "Epoch: 433, Loss: 1.2208\n",
      "Epoch: 434, Loss: 1.2178\n",
      "Epoch: 435, Loss: 1.2271\n",
      "Epoch: 436, Loss: 1.2279\n",
      "Epoch: 437, Loss: 1.2281\n",
      "Epoch: 438, Loss: 1.2119\n",
      "Epoch: 439, Loss: 1.2223\n",
      "Epoch: 440, Loss: 1.2349\n",
      "Epoch: 441, Loss: 1.2285\n",
      "Epoch: 442, Loss: 1.2231\n",
      "Epoch: 443, Loss: 1.2316\n",
      "Epoch: 444, Loss: 1.2134\n",
      "Epoch: 445, Loss: 1.2339\n",
      "Epoch: 446, Loss: 1.2237\n",
      "Epoch: 447, Loss: 1.2163\n",
      "Epoch: 448, Loss: 1.2110\n",
      "Epoch: 449, Loss: 1.2165\n",
      "Epoch: 450, Loss: 1.2395\n",
      "Epoch: 451, Loss: 1.2189\n",
      "Epoch: 452, Loss: 1.2141\n",
      "Epoch: 453, Loss: 1.2180\n",
      "Epoch: 454, Loss: 1.2265\n",
      "Epoch: 455, Loss: 1.2177\n",
      "Epoch: 456, Loss: 1.2186\n",
      "Epoch: 457, Loss: 1.2285\n",
      "Epoch: 458, Loss: 1.2265\n",
      "Epoch: 459, Loss: 1.2270\n",
      "Epoch: 460, Loss: 1.2108\n",
      "Epoch: 461, Loss: 1.2169\n",
      "Epoch: 462, Loss: 1.2308\n",
      "Epoch: 463, Loss: 1.2234\n",
      "Epoch: 464, Loss: 1.2104\n",
      "Epoch: 465, Loss: 1.2166\n",
      "Epoch: 466, Loss: 1.2312\n",
      "Epoch: 467, Loss: 1.2047\n",
      "Epoch: 468, Loss: 1.2237\n",
      "Epoch: 469, Loss: 1.2218\n",
      "Epoch: 470, Loss: 1.2208\n",
      "Epoch: 471, Loss: 1.2214\n",
      "Epoch: 472, Loss: 1.2328\n",
      "Epoch: 473, Loss: 1.2125\n",
      "Epoch: 474, Loss: 1.2134\n",
      "Epoch: 475, Loss: 1.2074\n",
      "Epoch: 476, Loss: 1.2106\n",
      "Epoch: 477, Loss: 1.2018\n",
      "Epoch: 478, Loss: 1.2203\n",
      "Epoch: 479, Loss: 1.2193\n",
      "Epoch: 480, Loss: 1.2193\n",
      "Epoch: 481, Loss: 1.2138\n",
      "Epoch: 482, Loss: 1.2177\n",
      "Epoch: 483, Loss: 1.2298\n",
      "Epoch: 484, Loss: 1.2247\n",
      "Epoch: 485, Loss: 1.2071\n",
      "Epoch: 486, Loss: 1.2249\n",
      "Epoch: 487, Loss: 1.2194\n",
      "Epoch: 488, Loss: 1.2157\n",
      "Epoch: 489, Loss: 1.2158\n",
      "Epoch: 490, Loss: 1.2452\n",
      "Epoch: 491, Loss: 1.1976\n",
      "Epoch: 492, Loss: 1.2320\n",
      "Epoch: 493, Loss: 1.2069\n",
      "Epoch: 494, Loss: 1.2228\n",
      "Epoch: 495, Loss: 1.2176\n",
      "Epoch: 496, Loss: 1.2085\n",
      "Epoch: 497, Loss: 1.2184\n",
      "Epoch: 498, Loss: 1.2214\n",
      "Epoch: 499, Loss: 1.2153\n",
      "Epoch: 500, Loss: 1.2041\n",
      "Epoch: 501, Loss: 1.1969\n",
      "Epoch: 502, Loss: 1.2109\n",
      "Epoch: 503, Loss: 1.2288\n",
      "Epoch: 504, Loss: 1.2065\n",
      "Epoch: 505, Loss: 1.2192\n",
      "Epoch: 506, Loss: 1.2096\n",
      "Epoch: 507, Loss: 1.2166\n",
      "Epoch: 508, Loss: 1.1999\n",
      "Epoch: 509, Loss: 1.2100\n",
      "Epoch: 510, Loss: 1.2003\n",
      "Epoch: 511, Loss: 1.2008\n",
      "Epoch: 512, Loss: 1.2079\n",
      "Epoch: 513, Loss: 1.2167\n",
      "Epoch: 514, Loss: 1.2018\n",
      "Epoch: 515, Loss: 1.1994\n",
      "Epoch: 516, Loss: 1.1949\n",
      "Epoch: 517, Loss: 1.2148\n",
      "Epoch: 518, Loss: 1.2085\n",
      "Epoch: 519, Loss: 1.2017\n",
      "Epoch: 520, Loss: 1.2165\n",
      "Epoch: 521, Loss: 1.2188\n",
      "Epoch: 522, Loss: 1.2149\n",
      "Epoch: 523, Loss: 1.2173\n",
      "Epoch: 524, Loss: 1.2059\n",
      "Epoch: 525, Loss: 1.1994\n",
      "Epoch: 526, Loss: 1.2031\n",
      "Epoch: 527, Loss: 1.2231\n",
      "Epoch: 528, Loss: 1.2095\n",
      "Epoch: 529, Loss: 1.2211\n",
      "Epoch: 530, Loss: 1.1980\n",
      "Epoch: 531, Loss: 1.2287\n",
      "Epoch: 532, Loss: 1.2117\n",
      "Epoch: 533, Loss: 1.2124\n",
      "Epoch: 534, Loss: 1.2122\n",
      "Epoch: 535, Loss: 1.2000\n",
      "Epoch: 536, Loss: 1.2184\n",
      "Epoch: 537, Loss: 1.2085\n",
      "Epoch: 538, Loss: 1.1963\n",
      "Epoch: 539, Loss: 1.2089\n",
      "Epoch: 540, Loss: 1.2047\n",
      "Epoch: 541, Loss: 1.2125\n",
      "Epoch: 542, Loss: 1.2071\n",
      "Epoch: 543, Loss: 1.2057\n",
      "Epoch: 544, Loss: 1.2176\n",
      "Epoch: 545, Loss: 1.2013\n",
      "Epoch: 546, Loss: 1.2138\n",
      "Epoch: 547, Loss: 1.2208\n",
      "Epoch: 548, Loss: 1.2054\n",
      "Epoch: 549, Loss: 1.1982\n",
      "Epoch: 550, Loss: 1.2114\n",
      "Epoch: 551, Loss: 1.1854\n",
      "Epoch: 552, Loss: 1.2044\n",
      "Epoch: 553, Loss: 1.2011\n",
      "Epoch: 554, Loss: 1.2038\n",
      "Epoch: 555, Loss: 1.1985\n",
      "Epoch: 556, Loss: 1.1963\n",
      "Epoch: 557, Loss: 1.2120\n",
      "Epoch: 558, Loss: 1.2049\n",
      "Epoch: 559, Loss: 1.2134\n",
      "Epoch: 560, Loss: 1.1875\n",
      "Epoch: 561, Loss: 1.2032\n",
      "Epoch: 562, Loss: 1.1957\n",
      "Epoch: 563, Loss: 1.1886\n",
      "Epoch: 564, Loss: 1.2000\n",
      "Epoch: 565, Loss: 1.1979\n",
      "Epoch: 566, Loss: 1.1874\n",
      "Epoch: 567, Loss: 1.1969\n",
      "Epoch: 568, Loss: 1.2120\n",
      "Epoch: 569, Loss: 1.2041\n",
      "Epoch: 570, Loss: 1.1941\n",
      "Epoch: 571, Loss: 1.2152\n",
      "Epoch: 572, Loss: 1.1935\n",
      "Epoch: 573, Loss: 1.1862\n",
      "Epoch: 574, Loss: 1.1913\n",
      "Epoch: 575, Loss: 1.1913\n",
      "Epoch: 576, Loss: 1.2057\n",
      "Epoch: 577, Loss: 1.2009\n",
      "Epoch: 578, Loss: 1.2101\n",
      "Epoch: 579, Loss: 1.1933\n",
      "Epoch: 580, Loss: 1.1883\n",
      "Epoch: 581, Loss: 1.1868\n",
      "Epoch: 582, Loss: 1.2015\n",
      "Epoch: 583, Loss: 1.1835\n",
      "Epoch: 584, Loss: 1.2084\n",
      "Epoch: 585, Loss: 1.1876\n",
      "Epoch: 586, Loss: 1.1963\n",
      "Epoch: 587, Loss: 1.2034\n",
      "Epoch: 588, Loss: 1.2090\n",
      "Epoch: 589, Loss: 1.1875\n",
      "Epoch: 590, Loss: 1.2051\n",
      "Epoch: 591, Loss: 1.2014\n",
      "Epoch: 592, Loss: 1.2130\n",
      "Epoch: 593, Loss: 1.1859\n",
      "Epoch: 594, Loss: 1.2044\n",
      "Epoch: 595, Loss: 1.1830\n",
      "Epoch: 596, Loss: 1.1963\n",
      "Epoch: 597, Loss: 1.1930\n",
      "Epoch: 598, Loss: 1.1911\n",
      "Epoch: 599, Loss: 1.1994\n",
      "Epoch: 600, Loss: 1.1677\n",
      "Epoch: 601, Loss: 1.1826\n",
      "Epoch: 602, Loss: 1.1865\n",
      "Epoch: 603, Loss: 1.1875\n",
      "Epoch: 604, Loss: 1.1865\n",
      "Epoch: 605, Loss: 1.1791\n",
      "Epoch: 606, Loss: 1.1933\n",
      "Epoch: 607, Loss: 1.1910\n",
      "Epoch: 608, Loss: 1.1853\n",
      "Epoch: 609, Loss: 1.1805\n",
      "Epoch: 610, Loss: 1.1911\n",
      "Epoch: 611, Loss: 1.2038\n",
      "Epoch: 612, Loss: 1.1922\n",
      "Epoch: 613, Loss: 1.1920\n",
      "Epoch: 614, Loss: 1.1934\n",
      "Epoch: 615, Loss: 1.1888\n",
      "Epoch: 616, Loss: 1.1934\n",
      "Epoch: 617, Loss: 1.1869\n",
      "Epoch: 618, Loss: 1.1945\n",
      "Epoch: 619, Loss: 1.1811\n",
      "Epoch: 620, Loss: 1.2046\n",
      "Epoch: 621, Loss: 1.1986\n",
      "Epoch: 622, Loss: 1.1935\n",
      "Epoch: 623, Loss: 1.2095\n",
      "Epoch: 624, Loss: 1.1942\n",
      "Epoch: 625, Loss: 1.1977\n",
      "Epoch: 626, Loss: 1.1920\n",
      "Epoch: 627, Loss: 1.2032\n",
      "Epoch: 628, Loss: 1.1892\n",
      "Epoch: 629, Loss: 1.1913\n",
      "Epoch: 630, Loss: 1.1989\n",
      "Epoch: 631, Loss: 1.2071\n",
      "Epoch: 632, Loss: 1.1946\n",
      "Epoch: 633, Loss: 1.1848\n",
      "Epoch: 634, Loss: 1.1952\n",
      "Epoch: 635, Loss: 1.2006\n",
      "Epoch: 636, Loss: 1.1919\n",
      "Epoch: 637, Loss: 1.2064\n",
      "Epoch: 638, Loss: 1.1853\n",
      "Epoch: 639, Loss: 1.2065\n",
      "Epoch: 640, Loss: 1.1992\n",
      "Epoch: 641, Loss: 1.1976\n",
      "Epoch: 642, Loss: 1.1839\n",
      "Epoch: 643, Loss: 1.1872\n",
      "Epoch: 644, Loss: 1.1863\n",
      "Epoch: 645, Loss: 1.1938\n",
      "Epoch: 646, Loss: 1.1847\n",
      "Epoch: 647, Loss: 1.2091\n",
      "Epoch: 648, Loss: 1.1955\n",
      "Epoch: 649, Loss: 1.1966\n",
      "Epoch: 650, Loss: 1.1774\n",
      "Epoch: 651, Loss: 1.1969\n",
      "Epoch: 652, Loss: 1.1867\n",
      "Epoch: 653, Loss: 1.1809\n",
      "Epoch: 654, Loss: 1.1941\n",
      "Epoch: 655, Loss: 1.1868\n",
      "Epoch: 656, Loss: 1.1714\n",
      "Epoch: 657, Loss: 1.1816\n",
      "Epoch: 658, Loss: 1.1928\n",
      "Epoch: 659, Loss: 1.1698\n",
      "Epoch: 660, Loss: 1.1998\n",
      "Epoch: 661, Loss: 1.1782\n",
      "Epoch: 662, Loss: 1.1919\n",
      "Epoch: 663, Loss: 1.1991\n",
      "Epoch: 664, Loss: 1.1816\n",
      "Epoch: 665, Loss: 1.1815\n",
      "Epoch: 666, Loss: 1.1922\n",
      "Epoch: 667, Loss: 1.1691\n",
      "Epoch: 668, Loss: 1.1735\n",
      "Epoch: 669, Loss: 1.1775\n",
      "Epoch: 670, Loss: 1.1981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 671, Loss: 1.1857\n",
      "Epoch: 672, Loss: 1.1722\n",
      "Epoch: 673, Loss: 1.1828\n",
      "Epoch: 674, Loss: 1.1715\n",
      "Epoch: 675, Loss: 1.1752\n",
      "Epoch: 676, Loss: 1.1835\n",
      "Epoch: 677, Loss: 1.1865\n",
      "Epoch: 678, Loss: 1.1706\n",
      "Epoch: 679, Loss: 1.1749\n",
      "Epoch: 680, Loss: 1.1701\n",
      "Epoch: 681, Loss: 1.1661\n",
      "Epoch: 682, Loss: 1.1840\n",
      "Epoch: 683, Loss: 1.1665\n",
      "Epoch: 684, Loss: 1.1817\n",
      "Epoch: 685, Loss: 1.1719\n",
      "Epoch: 686, Loss: 1.1749\n",
      "Epoch: 687, Loss: 1.1803\n",
      "Epoch: 688, Loss: 1.1722\n",
      "Epoch: 689, Loss: 1.1701\n",
      "Epoch: 690, Loss: 1.1771\n",
      "Epoch: 691, Loss: 1.1697\n",
      "Epoch: 692, Loss: 1.1845\n",
      "Epoch: 693, Loss: 1.1702\n",
      "Epoch: 694, Loss: 1.1816\n",
      "Epoch: 695, Loss: 1.1829\n",
      "Epoch: 696, Loss: 1.1932\n",
      "Epoch: 697, Loss: 1.1807\n",
      "Epoch: 698, Loss: 1.1651\n",
      "Epoch: 699, Loss: 1.1805\n",
      "Epoch: 700, Loss: 1.1803\n",
      "Epoch: 701, Loss: 1.1615\n",
      "Epoch: 702, Loss: 1.1672\n",
      "Epoch: 703, Loss: 1.1733\n",
      "Epoch: 704, Loss: 1.1633\n",
      "Epoch: 705, Loss: 1.1569\n",
      "Epoch: 706, Loss: 1.1580\n",
      "Epoch: 707, Loss: 1.1641\n",
      "Epoch: 708, Loss: 1.1659\n",
      "Epoch: 709, Loss: 1.1706\n",
      "Epoch: 710, Loss: 1.1666\n",
      "Epoch: 711, Loss: 1.1702\n",
      "Epoch: 712, Loss: 1.1794\n",
      "Epoch: 713, Loss: 1.1695\n",
      "Epoch: 714, Loss: 1.1635\n",
      "Epoch: 715, Loss: 1.1549\n",
      "Epoch: 716, Loss: 1.1658\n",
      "Epoch: 717, Loss: 1.1484\n",
      "Epoch: 718, Loss: 1.1546\n",
      "Epoch: 719, Loss: 1.1718\n",
      "Epoch: 720, Loss: 1.1707\n",
      "Epoch: 721, Loss: 1.1677\n",
      "Epoch: 722, Loss: 1.1724\n",
      "Epoch: 723, Loss: 1.1668\n",
      "Epoch: 724, Loss: 1.1727\n",
      "Epoch: 725, Loss: 1.1861\n",
      "Epoch: 726, Loss: 1.1616\n",
      "Epoch: 727, Loss: 1.1730\n",
      "Epoch: 728, Loss: 1.1731\n",
      "Epoch: 729, Loss: 1.1625\n",
      "Epoch: 730, Loss: 1.1818\n",
      "Epoch: 731, Loss: 1.1798\n",
      "Epoch: 732, Loss: 1.1637\n",
      "Epoch: 733, Loss: 1.1621\n",
      "Epoch: 734, Loss: 1.1632\n",
      "Epoch: 735, Loss: 1.1485\n",
      "Epoch: 736, Loss: 1.1679\n",
      "Epoch: 737, Loss: 1.1478\n",
      "Epoch: 738, Loss: 1.1619\n",
      "Epoch: 739, Loss: 1.1554\n",
      "Epoch: 740, Loss: 1.1517\n",
      "Epoch: 741, Loss: 1.1748\n",
      "Epoch: 742, Loss: 1.1681\n",
      "Epoch: 743, Loss: 1.1505\n",
      "Epoch: 744, Loss: 1.1552\n",
      "Epoch: 745, Loss: 1.1484\n",
      "Epoch: 746, Loss: 1.1681\n",
      "Epoch: 747, Loss: 1.1439\n",
      "Epoch: 748, Loss: 1.1397\n",
      "Epoch: 749, Loss: 1.1574\n",
      "Epoch: 750, Loss: 1.1563\n",
      "Epoch: 751, Loss: 1.1634\n",
      "Epoch: 752, Loss: 1.1491\n",
      "Epoch: 753, Loss: 1.1413\n",
      "Epoch: 754, Loss: 1.1432\n",
      "Epoch: 755, Loss: 1.1543\n",
      "Epoch: 756, Loss: 1.1588\n",
      "Epoch: 757, Loss: 1.1611\n",
      "Epoch: 758, Loss: 1.1620\n",
      "Epoch: 759, Loss: 1.1384\n",
      "Epoch: 760, Loss: 1.1351\n",
      "Epoch: 761, Loss: 1.1493\n",
      "Epoch: 762, Loss: 1.1475\n",
      "Epoch: 763, Loss: 1.1535\n",
      "Epoch: 764, Loss: 1.1617\n",
      "Epoch: 765, Loss: 1.1449\n",
      "Epoch: 766, Loss: 1.1382\n",
      "Epoch: 767, Loss: 1.1418\n",
      "Epoch: 768, Loss: 1.1552\n",
      "Epoch: 769, Loss: 1.1362\n",
      "Epoch: 770, Loss: 1.1687\n",
      "Epoch: 771, Loss: 1.1357\n",
      "Epoch: 772, Loss: 1.1578\n",
      "Epoch: 773, Loss: 1.1367\n",
      "Epoch: 774, Loss: 1.1590\n",
      "Epoch: 775, Loss: 1.1283\n",
      "Epoch: 776, Loss: 1.1479\n",
      "Epoch: 777, Loss: 1.1325\n",
      "Epoch: 778, Loss: 1.1429\n",
      "Epoch: 779, Loss: 1.1302\n",
      "Epoch: 780, Loss: 1.1419\n",
      "Epoch: 781, Loss: 1.1421\n",
      "Epoch: 782, Loss: 1.1451\n",
      "Epoch: 783, Loss: 1.1472\n",
      "Epoch: 784, Loss: 1.1139\n",
      "Epoch: 785, Loss: 1.1296\n",
      "Epoch: 786, Loss: 1.1340\n",
      "Epoch: 787, Loss: 1.1286\n",
      "Epoch: 788, Loss: 1.1543\n",
      "Epoch: 789, Loss: 1.1179\n",
      "Epoch: 790, Loss: 1.1128\n",
      "Epoch: 791, Loss: 1.1245\n",
      "Epoch: 792, Loss: 1.1327\n",
      "Epoch: 793, Loss: 1.1298\n",
      "Epoch: 794, Loss: 1.1470\n",
      "Epoch: 795, Loss: 1.1227\n",
      "Epoch: 796, Loss: 1.1195\n",
      "Epoch: 797, Loss: 1.1331\n",
      "Epoch: 798, Loss: 1.1154\n",
      "Epoch: 799, Loss: 1.1230\n",
      "Epoch: 800, Loss: 1.1104\n",
      "Epoch: 801, Loss: 1.1189\n",
      "Epoch: 802, Loss: 1.1272\n",
      "Epoch: 803, Loss: 1.1097\n",
      "Epoch: 804, Loss: 1.1262\n",
      "Epoch: 805, Loss: 1.1003\n",
      "Epoch: 806, Loss: 1.1355\n",
      "Epoch: 807, Loss: 1.1252\n",
      "Epoch: 808, Loss: 1.1219\n",
      "Epoch: 809, Loss: 1.1076\n",
      "Epoch: 810, Loss: 1.1365\n",
      "Epoch: 811, Loss: 1.1225\n",
      "Epoch: 812, Loss: 1.1190\n",
      "Epoch: 813, Loss: 1.1112\n",
      "Epoch: 814, Loss: 1.1019\n",
      "Epoch: 815, Loss: 1.1055\n",
      "Epoch: 816, Loss: 1.1007\n",
      "Epoch: 817, Loss: 1.1139\n",
      "Epoch: 818, Loss: 1.1156\n",
      "Epoch: 819, Loss: 1.1270\n",
      "Epoch: 820, Loss: 1.1038\n",
      "Epoch: 821, Loss: 1.1106\n",
      "Epoch: 822, Loss: 1.1119\n",
      "Epoch: 823, Loss: 1.1001\n",
      "Epoch: 824, Loss: 1.1030\n",
      "Epoch: 825, Loss: 1.1073\n",
      "Epoch: 826, Loss: 1.0932\n",
      "Epoch: 827, Loss: 1.1169\n",
      "Epoch: 828, Loss: 1.1077\n",
      "Epoch: 829, Loss: 1.0974\n",
      "Epoch: 830, Loss: 1.1158\n",
      "Epoch: 831, Loss: 1.0924\n",
      "Epoch: 832, Loss: 1.0896\n",
      "Epoch: 833, Loss: 1.1086\n",
      "Epoch: 834, Loss: 1.0989\n",
      "Epoch: 835, Loss: 1.0958\n",
      "Epoch: 836, Loss: 1.0957\n",
      "Epoch: 837, Loss: 1.0811\n",
      "Epoch: 838, Loss: 1.0987\n",
      "Epoch: 839, Loss: 1.1073\n",
      "Epoch: 840, Loss: 1.0944\n",
      "Epoch: 841, Loss: 1.0985\n",
      "Epoch: 842, Loss: 1.0870\n",
      "Epoch: 843, Loss: 1.1045\n",
      "Epoch: 844, Loss: 1.0915\n",
      "Epoch: 845, Loss: 1.0773\n",
      "Epoch: 846, Loss: 1.0966\n",
      "Epoch: 847, Loss: 1.0822\n",
      "Epoch: 848, Loss: 1.0888\n",
      "Epoch: 849, Loss: 1.1014\n",
      "Epoch: 850, Loss: 1.0832\n",
      "Epoch: 851, Loss: 1.0863\n",
      "Epoch: 852, Loss: 1.0818\n",
      "Epoch: 853, Loss: 1.0686\n",
      "Epoch: 854, Loss: 1.0995\n",
      "Epoch: 855, Loss: 1.0793\n",
      "Epoch: 856, Loss: 1.0875\n",
      "Epoch: 857, Loss: 1.0893\n",
      "Epoch: 858, Loss: 1.0786\n",
      "Epoch: 859, Loss: 1.0694\n",
      "Epoch: 860, Loss: 1.0834\n",
      "Epoch: 861, Loss: 1.0856\n",
      "Epoch: 862, Loss: 1.0867\n",
      "Epoch: 863, Loss: 1.0660\n",
      "Epoch: 864, Loss: 1.0775\n",
      "Epoch: 865, Loss: 1.0775\n",
      "Epoch: 866, Loss: 1.0769\n",
      "Epoch: 867, Loss: 1.0762\n",
      "Epoch: 868, Loss: 1.0726\n",
      "Epoch: 869, Loss: 1.0839\n",
      "Epoch: 870, Loss: 1.0734\n",
      "Epoch: 871, Loss: 1.0430\n",
      "Epoch: 872, Loss: 1.0622\n",
      "Epoch: 873, Loss: 1.0658\n",
      "Epoch: 874, Loss: 1.0896\n",
      "Epoch: 875, Loss: 1.0586\n",
      "Epoch: 876, Loss: 1.0785\n",
      "Epoch: 877, Loss: 1.0586\n",
      "Epoch: 878, Loss: 1.0828\n",
      "Epoch: 879, Loss: 1.0635\n",
      "Epoch: 880, Loss: 1.0654\n",
      "Epoch: 881, Loss: 1.0527\n",
      "Epoch: 882, Loss: 1.0553\n",
      "Epoch: 883, Loss: 1.0503\n",
      "Epoch: 884, Loss: 1.0847\n",
      "Epoch: 885, Loss: 1.0635\n",
      "Epoch: 886, Loss: 1.0580\n",
      "Epoch: 887, Loss: 1.0566\n",
      "Epoch: 888, Loss: 1.0641\n",
      "Epoch: 889, Loss: 1.0410\n",
      "Epoch: 890, Loss: 1.0532\n",
      "Epoch: 891, Loss: 1.0527\n",
      "Epoch: 892, Loss: 1.0599\n",
      "Epoch: 893, Loss: 1.0576\n",
      "Epoch: 894, Loss: 1.0535\n",
      "Epoch: 895, Loss: 1.0380\n",
      "Epoch: 896, Loss: 1.0535\n",
      "Epoch: 897, Loss: 1.0465\n",
      "Epoch: 898, Loss: 1.0485\n",
      "Epoch: 899, Loss: 1.0590\n",
      "Epoch: 900, Loss: 1.0647\n",
      "Epoch: 901, Loss: 1.0447\n",
      "Epoch: 902, Loss: 1.0394\n",
      "Epoch: 903, Loss: 1.0485\n",
      "Epoch: 904, Loss: 1.0324\n",
      "Epoch: 905, Loss: 1.0583\n",
      "Epoch: 906, Loss: 1.0555\n",
      "Epoch: 907, Loss: 1.0230\n",
      "Epoch: 908, Loss: 1.0310\n",
      "Epoch: 909, Loss: 1.0205\n",
      "Epoch: 910, Loss: 1.0507\n",
      "Epoch: 911, Loss: 1.0288\n",
      "Epoch: 912, Loss: 1.0314\n",
      "Epoch: 913, Loss: 1.0474\n",
      "Epoch: 914, Loss: 1.0409\n",
      "Epoch: 915, Loss: 1.0286\n",
      "Epoch: 916, Loss: 1.0435\n",
      "Epoch: 917, Loss: 1.0158\n",
      "Epoch: 918, Loss: 1.0234\n",
      "Epoch: 919, Loss: 1.0352\n",
      "Epoch: 920, Loss: 1.0379\n",
      "Epoch: 921, Loss: 1.0342\n",
      "Epoch: 922, Loss: 1.0064\n",
      "Epoch: 923, Loss: 1.0219\n",
      "Epoch: 924, Loss: 1.0203\n",
      "Epoch: 925, Loss: 1.0192\n",
      "Epoch: 926, Loss: 1.0157\n",
      "Epoch: 927, Loss: 1.0145\n",
      "Epoch: 928, Loss: 0.9899\n",
      "Epoch: 929, Loss: 1.0274\n",
      "Epoch: 930, Loss: 1.0061\n",
      "Epoch: 931, Loss: 1.0158\n",
      "Epoch: 932, Loss: 0.9996\n",
      "Epoch: 933, Loss: 1.0238\n",
      "Epoch: 934, Loss: 1.0030\n",
      "Epoch: 935, Loss: 1.0015\n",
      "Epoch: 936, Loss: 1.0033\n",
      "Epoch: 937, Loss: 1.0070\n",
      "Epoch: 938, Loss: 1.0151\n",
      "Epoch: 939, Loss: 1.0062\n",
      "Epoch: 940, Loss: 1.0123\n",
      "Epoch: 941, Loss: 1.0033\n",
      "Epoch: 942, Loss: 1.0066\n",
      "Epoch: 943, Loss: 1.0064\n",
      "Epoch: 944, Loss: 1.0088\n",
      "Epoch: 945, Loss: 1.0131\n",
      "Epoch: 946, Loss: 1.0016\n",
      "Epoch: 947, Loss: 1.0081\n",
      "Epoch: 948, Loss: 0.9835\n",
      "Epoch: 949, Loss: 0.9878\n",
      "Epoch: 950, Loss: 0.9875\n",
      "Epoch: 951, Loss: 1.0004\n",
      "Epoch: 952, Loss: 0.9853\n",
      "Epoch: 953, Loss: 0.9813\n",
      "Epoch: 954, Loss: 0.9863\n",
      "Epoch: 955, Loss: 0.9776\n",
      "Epoch: 956, Loss: 1.0058\n",
      "Epoch: 957, Loss: 0.9835\n",
      "Epoch: 958, Loss: 0.9644\n",
      "Epoch: 959, Loss: 0.9751\n",
      "Epoch: 960, Loss: 0.9904\n",
      "Epoch: 961, Loss: 0.9722\n",
      "Epoch: 962, Loss: 0.9996\n",
      "Epoch: 963, Loss: 0.9748\n",
      "Epoch: 964, Loss: 0.9940\n",
      "Epoch: 965, Loss: 0.9710\n",
      "Epoch: 966, Loss: 0.9658\n",
      "Epoch: 967, Loss: 0.9754\n",
      "Epoch: 968, Loss: 0.9540\n",
      "Epoch: 969, Loss: 0.9593\n",
      "Epoch: 970, Loss: 0.9606\n",
      "Epoch: 971, Loss: 0.9700\n",
      "Epoch: 972, Loss: 0.9816\n",
      "Epoch: 973, Loss: 0.9791\n",
      "Epoch: 974, Loss: 0.9689\n",
      "Epoch: 975, Loss: 0.9655\n",
      "Epoch: 976, Loss: 0.9616\n",
      "Epoch: 977, Loss: 0.9632\n",
      "Epoch: 978, Loss: 0.9656\n",
      "Epoch: 979, Loss: 0.9674\n",
      "Epoch: 980, Loss: 0.9654\n",
      "Epoch: 981, Loss: 0.9550\n",
      "Epoch: 982, Loss: 0.9468\n",
      "Epoch: 983, Loss: 0.9491\n",
      "Epoch: 984, Loss: 0.9460\n",
      "Epoch: 985, Loss: 0.9778\n",
      "Epoch: 986, Loss: 0.9493\n",
      "Epoch: 987, Loss: 0.9603\n",
      "Epoch: 988, Loss: 0.9621\n",
      "Epoch: 989, Loss: 0.9592\n",
      "Epoch: 990, Loss: 0.9401\n",
      "Epoch: 991, Loss: 0.9769\n",
      "Epoch: 992, Loss: 0.9529\n",
      "Epoch: 993, Loss: 0.9482\n",
      "Epoch: 994, Loss: 0.9244\n",
      "Epoch: 995, Loss: 0.9501\n",
      "Epoch: 996, Loss: 0.9291\n",
      "Epoch: 997, Loss: 0.9398\n",
      "Epoch: 998, Loss: 0.9314\n",
      "Epoch: 999, Loss: 0.9453\n",
      "Epoch: 1000, Loss: 0.9382\n",
      "Epoch: 1001, Loss: 0.9461\n",
      "Epoch: 1002, Loss: 0.9484\n",
      "Epoch: 1003, Loss: 0.9361\n",
      "Epoch: 1004, Loss: 0.9218\n",
      "Epoch: 1005, Loss: 0.9576\n",
      "Epoch: 1006, Loss: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1007, Loss: 0.9303\n",
      "Epoch: 1008, Loss: 0.9430\n",
      "Epoch: 1009, Loss: 0.9313\n",
      "Epoch: 1010, Loss: 0.9515\n",
      "Epoch: 1011, Loss: 0.9421\n",
      "Epoch: 1012, Loss: 0.9387\n",
      "Epoch: 1013, Loss: 0.9305\n",
      "Epoch: 1014, Loss: 0.9337\n",
      "Epoch: 1015, Loss: 0.9163\n",
      "Epoch: 1016, Loss: 0.9355\n",
      "Epoch: 1017, Loss: 0.9391\n",
      "Epoch: 1018, Loss: 0.9288\n",
      "Epoch: 1019, Loss: 0.9261\n",
      "Epoch: 1020, Loss: 0.9369\n",
      "Epoch: 1021, Loss: 0.9211\n",
      "Epoch: 1022, Loss: 0.9152\n",
      "Epoch: 1023, Loss: 0.9192\n",
      "Epoch: 1024, Loss: 0.9220\n",
      "Epoch: 1025, Loss: 0.9313\n",
      "Epoch: 1026, Loss: 0.9035\n",
      "Epoch: 1027, Loss: 0.9144\n",
      "Epoch: 1028, Loss: 0.9169\n",
      "Epoch: 1029, Loss: 0.9171\n",
      "Epoch: 1030, Loss: 0.9257\n",
      "Epoch: 1031, Loss: 0.9243\n",
      "Epoch: 1032, Loss: 0.9181\n",
      "Epoch: 1033, Loss: 0.9135\n",
      "Epoch: 1034, Loss: 0.9119\n",
      "Epoch: 1035, Loss: 0.9187\n",
      "Epoch: 1036, Loss: 0.9361\n",
      "Epoch: 1037, Loss: 0.9124\n",
      "Epoch: 1038, Loss: 0.9268\n",
      "Epoch: 1039, Loss: 0.9206\n",
      "Epoch: 1040, Loss: 0.9242\n",
      "Epoch: 1041, Loss: 0.9110\n",
      "Epoch: 1042, Loss: 0.9150\n",
      "Epoch: 1043, Loss: 0.9084\n",
      "Epoch: 1044, Loss: 0.9134\n",
      "Epoch: 1045, Loss: 0.9028\n",
      "Epoch: 1046, Loss: 0.9067\n",
      "Epoch: 1047, Loss: 0.9203\n",
      "Epoch: 1048, Loss: 0.9077\n",
      "Epoch: 1049, Loss: 0.9079\n",
      "Epoch: 1050, Loss: 0.9029\n",
      "Epoch: 1051, Loss: 0.9048\n",
      "Epoch: 1052, Loss: 0.9225\n",
      "Epoch: 1053, Loss: 0.8887\n",
      "Epoch: 1054, Loss: 0.9266\n",
      "Epoch: 1055, Loss: 0.9085\n",
      "Epoch: 1056, Loss: 0.9159\n",
      "Epoch: 1057, Loss: 0.8884\n",
      "Epoch: 1058, Loss: 0.9114\n",
      "Epoch: 1059, Loss: 0.9113\n",
      "Epoch: 1060, Loss: 0.9155\n",
      "Epoch: 1061, Loss: 0.8955\n",
      "Epoch: 1062, Loss: 0.9202\n",
      "Epoch: 1063, Loss: 0.8978\n",
      "Epoch: 1064, Loss: 0.9135\n",
      "Epoch: 1065, Loss: 0.9037\n",
      "Epoch: 1066, Loss: 0.8955\n",
      "Epoch: 1067, Loss: 0.8888\n",
      "Epoch: 1068, Loss: 0.8875\n",
      "Epoch: 1069, Loss: 0.8916\n",
      "Epoch: 1070, Loss: 0.8968\n",
      "Epoch: 1071, Loss: 0.8946\n",
      "Epoch: 1072, Loss: 0.9213\n",
      "Epoch: 1073, Loss: 0.8892\n",
      "Epoch: 1074, Loss: 0.8818\n",
      "Epoch: 1075, Loss: 0.9019\n",
      "Epoch: 1076, Loss: 0.8859\n",
      "Epoch: 1077, Loss: 0.8927\n",
      "Epoch: 1078, Loss: 0.8894\n",
      "Epoch: 1079, Loss: 0.8909\n",
      "Epoch: 1080, Loss: 0.8979\n",
      "Epoch: 1081, Loss: 0.8947\n",
      "Epoch: 1082, Loss: 0.8896\n",
      "Epoch: 1083, Loss: 0.8904\n",
      "Epoch: 1084, Loss: 0.8719\n",
      "Epoch: 1085, Loss: 0.8773\n",
      "Epoch: 1086, Loss: 0.9000\n",
      "Epoch: 1087, Loss: 0.8835\n",
      "Epoch: 1088, Loss: 0.8666\n",
      "Epoch: 1089, Loss: 0.8845\n",
      "Epoch: 1090, Loss: 0.8902\n",
      "Epoch: 1091, Loss: 0.8828\n",
      "Epoch: 1092, Loss: 0.8711\n",
      "Epoch: 1093, Loss: 0.8871\n",
      "Epoch: 1094, Loss: 0.8884\n",
      "Epoch: 1095, Loss: 0.8849\n",
      "Epoch: 1096, Loss: 0.8668\n",
      "Epoch: 1097, Loss: 0.8941\n",
      "Epoch: 1098, Loss: 0.8858\n",
      "Epoch: 1099, Loss: 0.8734\n",
      "Epoch: 1100, Loss: 0.8892\n",
      "Epoch: 1101, Loss: 0.8824\n",
      "Epoch: 1102, Loss: 0.8819\n",
      "Epoch: 1103, Loss: 0.8741\n",
      "Epoch: 1104, Loss: 0.8674\n",
      "Epoch: 1105, Loss: 0.8578\n",
      "Epoch: 1106, Loss: 0.8671\n",
      "Epoch: 1107, Loss: 0.8684\n",
      "Epoch: 1108, Loss: 0.8793\n",
      "Epoch: 1109, Loss: 0.8615\n",
      "Epoch: 1110, Loss: 0.8632\n",
      "Epoch: 1111, Loss: 0.8772\n",
      "Epoch: 1112, Loss: 0.8622\n",
      "Epoch: 1113, Loss: 0.8633\n",
      "Epoch: 1114, Loss: 0.8718\n",
      "Epoch: 1115, Loss: 0.8739\n",
      "Epoch: 1116, Loss: 0.8836\n",
      "Epoch: 1117, Loss: 0.8745\n",
      "Epoch: 1118, Loss: 0.8890\n",
      "Epoch: 1119, Loss: 0.8625\n",
      "Epoch: 1120, Loss: 0.8623\n",
      "Epoch: 1121, Loss: 0.8622\n",
      "Epoch: 1122, Loss: 0.8759\n",
      "Epoch: 1123, Loss: 0.8638\n",
      "Epoch: 1124, Loss: 0.8658\n",
      "Epoch: 1125, Loss: 0.8647\n",
      "Epoch: 1126, Loss: 0.8612\n",
      "Epoch: 1127, Loss: 0.8665\n",
      "Epoch: 1128, Loss: 0.8692\n",
      "Epoch: 1129, Loss: 0.8559\n",
      "Epoch: 1130, Loss: 0.8523\n",
      "Epoch: 1131, Loss: 0.8619\n",
      "Epoch: 1132, Loss: 0.8521\n",
      "Epoch: 1133, Loss: 0.8526\n",
      "Epoch: 1134, Loss: 0.8535\n",
      "Epoch: 1135, Loss: 0.8549\n",
      "Epoch: 1136, Loss: 0.8730\n",
      "Epoch: 1137, Loss: 0.8634\n",
      "Epoch: 1138, Loss: 0.8549\n",
      "Epoch: 1139, Loss: 0.8537\n",
      "Epoch: 1140, Loss: 0.8658\n",
      "Epoch: 1141, Loss: 0.8741\n",
      "Epoch: 1142, Loss: 0.8475\n",
      "Epoch: 1143, Loss: 0.8525\n",
      "Epoch: 1144, Loss: 0.8560\n",
      "Epoch: 1145, Loss: 0.8679\n",
      "Epoch: 1146, Loss: 0.8677\n",
      "Epoch: 1147, Loss: 0.8435\n",
      "Epoch: 1148, Loss: 0.8700\n",
      "Epoch: 1149, Loss: 0.8596\n",
      "Epoch: 1150, Loss: 0.8554\n",
      "Epoch: 1151, Loss: 0.8615\n",
      "Epoch: 1152, Loss: 0.8520\n",
      "Epoch: 1153, Loss: 0.8532\n",
      "Epoch: 1154, Loss: 0.8455\n",
      "Epoch: 1155, Loss: 0.8627\n",
      "Epoch: 1156, Loss: 0.8566\n",
      "Epoch: 1157, Loss: 0.8544\n",
      "Epoch: 1158, Loss: 0.8526\n",
      "Epoch: 1159, Loss: 0.8547\n",
      "Epoch: 1160, Loss: 0.8480\n",
      "Epoch: 1161, Loss: 0.8400\n",
      "Epoch: 1162, Loss: 0.8594\n",
      "Epoch: 1163, Loss: 0.8586\n",
      "Epoch: 1164, Loss: 0.8406\n",
      "Epoch: 1165, Loss: 0.8531\n",
      "Epoch: 1166, Loss: 0.8497\n",
      "Epoch: 1167, Loss: 0.8567\n",
      "Epoch: 1168, Loss: 0.8276\n",
      "Epoch: 1169, Loss: 0.8613\n",
      "Epoch: 1170, Loss: 0.8517\n",
      "Epoch: 1171, Loss: 0.8421\n",
      "Epoch: 1172, Loss: 0.8532\n",
      "Epoch: 1173, Loss: 0.8459\n",
      "Epoch: 1174, Loss: 0.8572\n",
      "Epoch: 1175, Loss: 0.8338\n",
      "Epoch: 1176, Loss: 0.8442\n",
      "Epoch: 1177, Loss: 0.8536\n",
      "Epoch: 1178, Loss: 0.8305\n",
      "Epoch: 1179, Loss: 0.8535\n",
      "Epoch: 1180, Loss: 0.8374\n",
      "Epoch: 1181, Loss: 0.8306\n",
      "Epoch: 1182, Loss: 0.8468\n",
      "Epoch: 1183, Loss: 0.8274\n",
      "Epoch: 1184, Loss: 0.8509\n",
      "Epoch: 1185, Loss: 0.8383\n",
      "Epoch: 1186, Loss: 0.8360\n",
      "Epoch: 1187, Loss: 0.8441\n",
      "Epoch: 1188, Loss: 0.8383\n",
      "Epoch: 1189, Loss: 0.8484\n",
      "Epoch: 1190, Loss: 0.8395\n",
      "Epoch: 1191, Loss: 0.8400\n",
      "Epoch: 1192, Loss: 0.8371\n",
      "Epoch: 1193, Loss: 0.8325\n",
      "Epoch: 1194, Loss: 0.8369\n",
      "Epoch: 1195, Loss: 0.8260\n",
      "Epoch: 1196, Loss: 0.8285\n",
      "Epoch: 1197, Loss: 0.8394\n",
      "Epoch: 1198, Loss: 0.8388\n",
      "Epoch: 1199, Loss: 0.8286\n",
      "Epoch: 1200, Loss: 0.8181\n",
      "Epoch: 1201, Loss: 0.8388\n",
      "Epoch: 1202, Loss: 0.8321\n",
      "Epoch: 1203, Loss: 0.8389\n",
      "Epoch: 1204, Loss: 0.8245\n",
      "Epoch: 1205, Loss: 0.8508\n",
      "Epoch: 1206, Loss: 0.8382\n",
      "Epoch: 1207, Loss: 0.8229\n",
      "Epoch: 1208, Loss: 0.8382\n",
      "Epoch: 1209, Loss: 0.8441\n",
      "Epoch: 1210, Loss: 0.8199\n",
      "Epoch: 1211, Loss: 0.8398\n",
      "Epoch: 1212, Loss: 0.8243\n",
      "Epoch: 1213, Loss: 0.8296\n",
      "Epoch: 1214, Loss: 0.8304\n",
      "Epoch: 1215, Loss: 0.8320\n",
      "Epoch: 1216, Loss: 0.8350\n",
      "Epoch: 1217, Loss: 0.8347\n",
      "Epoch: 1218, Loss: 0.8398\n",
      "Epoch: 1219, Loss: 0.8147\n",
      "Epoch: 1220, Loss: 0.8227\n",
      "Epoch: 1221, Loss: 0.8277\n",
      "Epoch: 1222, Loss: 0.8173\n",
      "Epoch: 1223, Loss: 0.8280\n",
      "Epoch: 1224, Loss: 0.8066\n",
      "Epoch: 1225, Loss: 0.8256\n",
      "Epoch: 1226, Loss: 0.8205\n",
      "Epoch: 1227, Loss: 0.8304\n",
      "Epoch: 1228, Loss: 0.8235\n",
      "Epoch: 1229, Loss: 0.8179\n",
      "Epoch: 1230, Loss: 0.8296\n",
      "Epoch: 1231, Loss: 0.8053\n",
      "Epoch: 1232, Loss: 0.8298\n",
      "Epoch: 1233, Loss: 0.8336\n",
      "Epoch: 1234, Loss: 0.8146\n",
      "Epoch: 1235, Loss: 0.8165\n",
      "Epoch: 1236, Loss: 0.8044\n",
      "Epoch: 1237, Loss: 0.8036\n",
      "Epoch: 1238, Loss: 0.8155\n",
      "Epoch: 1239, Loss: 0.8209\n",
      "Epoch: 1240, Loss: 0.8235\n",
      "Epoch: 1241, Loss: 0.8094\n",
      "Epoch: 1242, Loss: 0.8046\n",
      "Epoch: 1243, Loss: 0.8171\n",
      "Epoch: 1244, Loss: 0.8156\n",
      "Epoch: 1245, Loss: 0.8221\n",
      "Epoch: 1246, Loss: 0.7959\n",
      "Epoch: 1247, Loss: 0.7974\n",
      "Epoch: 1248, Loss: 0.8119\n",
      "Epoch: 1249, Loss: 0.8047\n",
      "Epoch: 1250, Loss: 0.7808\n",
      "Epoch: 1251, Loss: 0.8036\n",
      "Epoch: 1252, Loss: 0.7982\n",
      "Epoch: 1253, Loss: 0.8255\n",
      "Epoch: 1254, Loss: 0.8075\n",
      "Epoch: 1255, Loss: 0.8095\n",
      "Epoch: 1256, Loss: 0.8118\n",
      "Epoch: 1257, Loss: 0.8082\n",
      "Epoch: 1258, Loss: 0.8129\n",
      "Epoch: 1259, Loss: 0.8286\n",
      "Epoch: 1260, Loss: 0.8142\n",
      "Epoch: 1261, Loss: 0.8032\n",
      "Epoch: 1262, Loss: 0.7982\n",
      "Epoch: 1263, Loss: 0.8100\n",
      "Epoch: 1264, Loss: 0.8094\n",
      "Epoch: 1265, Loss: 0.8020\n",
      "Epoch: 1266, Loss: 0.7910\n",
      "Epoch: 1267, Loss: 0.7980\n",
      "Epoch: 1268, Loss: 0.8024\n",
      "Epoch: 1269, Loss: 0.7917\n",
      "Epoch: 1270, Loss: 0.8034\n",
      "Epoch: 1271, Loss: 0.7854\n",
      "Epoch: 1272, Loss: 0.7996\n",
      "Epoch: 1273, Loss: 0.8009\n",
      "Epoch: 1274, Loss: 0.7959\n",
      "Epoch: 1275, Loss: 0.7925\n",
      "Epoch: 1276, Loss: 0.8021\n",
      "Epoch: 1277, Loss: 0.7918\n",
      "Epoch: 1278, Loss: 0.7833\n",
      "Epoch: 1279, Loss: 0.7995\n",
      "Epoch: 1280, Loss: 0.8013\n",
      "Epoch: 1281, Loss: 0.7839\n",
      "Epoch: 1282, Loss: 0.7803\n",
      "Epoch: 1283, Loss: 0.7777\n",
      "Epoch: 1284, Loss: 0.7883\n",
      "Epoch: 1285, Loss: 0.7942\n",
      "Epoch: 1286, Loss: 0.8032\n",
      "Epoch: 1287, Loss: 0.8047\n",
      "Epoch: 1288, Loss: 0.7667\n",
      "Epoch: 1289, Loss: 0.7882\n",
      "Epoch: 1290, Loss: 0.7957\n",
      "Epoch: 1291, Loss: 0.7954\n",
      "Epoch: 1292, Loss: 0.7999\n",
      "Epoch: 1293, Loss: 0.7833\n",
      "Epoch: 1294, Loss: 0.7972\n",
      "Epoch: 1295, Loss: 0.7820\n",
      "Epoch: 1296, Loss: 0.7813\n",
      "Epoch: 1297, Loss: 0.7927\n",
      "Epoch: 1298, Loss: 0.7764\n",
      "Epoch: 1299, Loss: 0.7924\n",
      "Epoch: 1300, Loss: 0.7838\n",
      "Epoch: 1301, Loss: 0.7824\n",
      "Epoch: 1302, Loss: 0.7750\n",
      "Epoch: 1303, Loss: 0.7819\n",
      "Epoch: 1304, Loss: 0.7899\n",
      "Epoch: 1305, Loss: 0.8037\n",
      "Epoch: 1306, Loss: 0.7849\n",
      "Epoch: 1307, Loss: 0.7886\n",
      "Epoch: 1308, Loss: 0.7812\n",
      "Epoch: 1309, Loss: 0.7731\n",
      "Epoch: 1310, Loss: 0.7737\n",
      "Epoch: 1311, Loss: 0.7786\n",
      "Epoch: 1312, Loss: 0.7853\n",
      "Epoch: 1313, Loss: 0.7737\n",
      "Epoch: 1314, Loss: 0.7993\n",
      "Epoch: 1315, Loss: 0.7687\n",
      "Epoch: 1316, Loss: 0.7790\n",
      "Epoch: 1317, Loss: 0.7645\n",
      "Epoch: 1318, Loss: 0.7797\n",
      "Epoch: 1319, Loss: 0.7753\n",
      "Epoch: 1320, Loss: 0.7707\n",
      "Epoch: 1321, Loss: 0.7777\n",
      "Epoch: 1322, Loss: 0.7800\n",
      "Epoch: 1323, Loss: 0.7786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1324, Loss: 0.7731\n",
      "Epoch: 1325, Loss: 0.7681\n",
      "Epoch: 1326, Loss: 0.7767\n",
      "Epoch: 1327, Loss: 0.7697\n",
      "Epoch: 1328, Loss: 0.7725\n",
      "Epoch: 1329, Loss: 0.7824\n",
      "Epoch: 1330, Loss: 0.7763\n",
      "Epoch: 1331, Loss: 0.7790\n",
      "Epoch: 1332, Loss: 0.7737\n",
      "Epoch: 1333, Loss: 0.7626\n",
      "Epoch: 1334, Loss: 0.7603\n",
      "Epoch: 1335, Loss: 0.7653\n",
      "Epoch: 1336, Loss: 0.7640\n",
      "Epoch: 1337, Loss: 0.7655\n",
      "Epoch: 1338, Loss: 0.7596\n",
      "Epoch: 1339, Loss: 0.7669\n",
      "Epoch: 1340, Loss: 0.7769\n",
      "Epoch: 1341, Loss: 0.7759\n",
      "Epoch: 1342, Loss: 0.7734\n",
      "Epoch: 1343, Loss: 0.7581\n",
      "Epoch: 1344, Loss: 0.7612\n",
      "Epoch: 1345, Loss: 0.7653\n",
      "Epoch: 1346, Loss: 0.7510\n",
      "Epoch: 1347, Loss: 0.7549\n",
      "Epoch: 1348, Loss: 0.7495\n",
      "Epoch: 1349, Loss: 0.7616\n",
      "Epoch: 1350, Loss: 0.7734\n",
      "Epoch: 1351, Loss: 0.7627\n",
      "Epoch: 1352, Loss: 0.7633\n",
      "Epoch: 1353, Loss: 0.7529\n",
      "Epoch: 1354, Loss: 0.7610\n",
      "Epoch: 1355, Loss: 0.7662\n",
      "Epoch: 1356, Loss: 0.7694\n",
      "Epoch: 1357, Loss: 0.7565\n",
      "Epoch: 1358, Loss: 0.7471\n",
      "Epoch: 1359, Loss: 0.7642\n",
      "Epoch: 1360, Loss: 0.7568\n",
      "Epoch: 1361, Loss: 0.7697\n",
      "Epoch: 1362, Loss: 0.7732\n",
      "Epoch: 1363, Loss: 0.7583\n",
      "Epoch: 1364, Loss: 0.7615\n",
      "Epoch: 1365, Loss: 0.7485\n",
      "Epoch: 1366, Loss: 0.7607\n",
      "Epoch: 1367, Loss: 0.7809\n",
      "Epoch: 1368, Loss: 0.7703\n",
      "Epoch: 1369, Loss: 0.7545\n",
      "Epoch: 1370, Loss: 0.7472\n",
      "Epoch: 1371, Loss: 0.7496\n",
      "Epoch: 1372, Loss: 0.7606\n",
      "Epoch: 1373, Loss: 0.7580\n",
      "Epoch: 1374, Loss: 0.7550\n",
      "Epoch: 1375, Loss: 0.7650\n",
      "Epoch: 1376, Loss: 0.7608\n",
      "Epoch: 1377, Loss: 0.7657\n",
      "Epoch: 1378, Loss: 0.7564\n",
      "Epoch: 1379, Loss: 0.7671\n",
      "Epoch: 1380, Loss: 0.7661\n",
      "Epoch: 1381, Loss: 0.7607\n",
      "Epoch: 1382, Loss: 0.7583\n",
      "Epoch: 1383, Loss: 0.7560\n",
      "Epoch: 1384, Loss: 0.7619\n",
      "Epoch: 1385, Loss: 0.7521\n",
      "Epoch: 1386, Loss: 0.7617\n",
      "Epoch: 1387, Loss: 0.7613\n",
      "Epoch: 1388, Loss: 0.7475\n",
      "Epoch: 1389, Loss: 0.7650\n",
      "Epoch: 1390, Loss: 0.7486\n",
      "Epoch: 1391, Loss: 0.7656\n",
      "Epoch: 1392, Loss: 0.7440\n",
      "Epoch: 1393, Loss: 0.7559\n",
      "Epoch: 1394, Loss: 0.7663\n",
      "Epoch: 1395, Loss: 0.7474\n",
      "Epoch: 1396, Loss: 0.7689\n",
      "Epoch: 1397, Loss: 0.7695\n",
      "Epoch: 1398, Loss: 0.7417\n",
      "Epoch: 1399, Loss: 0.7398\n",
      "Epoch: 1400, Loss: 0.7456\n",
      "Epoch: 1401, Loss: 0.7447\n",
      "Epoch: 1402, Loss: 0.7485\n",
      "Epoch: 1403, Loss: 0.7590\n",
      "Epoch: 1404, Loss: 0.7490\n",
      "Epoch: 1405, Loss: 0.7513\n",
      "Epoch: 1406, Loss: 0.7507\n",
      "Epoch: 1407, Loss: 0.7553\n",
      "Epoch: 1408, Loss: 0.7546\n",
      "Epoch: 1409, Loss: 0.7471\n",
      "Epoch: 1410, Loss: 0.7411\n",
      "Epoch: 1411, Loss: 0.7503\n",
      "Epoch: 1412, Loss: 0.7581\n",
      "Epoch: 1413, Loss: 0.7523\n",
      "Epoch: 1414, Loss: 0.7338\n",
      "Epoch: 1415, Loss: 0.7496\n",
      "Epoch: 1416, Loss: 0.7482\n",
      "Epoch: 1417, Loss: 0.7536\n",
      "Epoch: 1418, Loss: 0.7382\n",
      "Epoch: 1419, Loss: 0.7543\n",
      "Epoch: 1420, Loss: 0.7518\n",
      "Epoch: 1421, Loss: 0.7437\n",
      "Epoch: 1422, Loss: 0.7432\n",
      "Epoch: 1423, Loss: 0.7504\n",
      "Epoch: 1424, Loss: 0.7333\n",
      "Epoch: 1425, Loss: 0.7453\n",
      "Epoch: 1426, Loss: 0.7423\n",
      "Epoch: 1427, Loss: 0.7600\n",
      "Epoch: 1428, Loss: 0.7443\n",
      "Epoch: 1429, Loss: 0.7485\n",
      "Epoch: 1430, Loss: 0.7325\n",
      "Epoch: 1431, Loss: 0.7345\n",
      "Epoch: 1432, Loss: 0.7405\n",
      "Epoch: 1433, Loss: 0.7415\n",
      "Epoch: 1434, Loss: 0.7482\n",
      "Epoch: 1435, Loss: 0.7297\n",
      "Epoch: 1436, Loss: 0.7468\n",
      "Epoch: 1437, Loss: 0.7583\n",
      "Epoch: 1438, Loss: 0.7516\n",
      "Epoch: 1439, Loss: 0.7475\n",
      "Epoch: 1440, Loss: 0.7578\n",
      "Epoch: 1441, Loss: 0.7489\n",
      "Epoch: 1442, Loss: 0.7515\n",
      "Epoch: 1443, Loss: 0.7499\n",
      "Epoch: 1444, Loss: 0.7474\n",
      "Epoch: 1445, Loss: 0.7274\n",
      "Epoch: 1446, Loss: 0.7348\n",
      "Epoch: 1447, Loss: 0.7570\n",
      "Epoch: 1448, Loss: 0.7272\n",
      "Epoch: 1449, Loss: 0.7515\n",
      "Epoch: 1450, Loss: 0.7490\n",
      "Epoch: 1451, Loss: 0.7337\n",
      "Epoch: 1452, Loss: 0.7507\n",
      "Epoch: 1453, Loss: 0.7437\n",
      "Epoch: 1454, Loss: 0.7495\n",
      "Epoch: 1455, Loss: 0.7503\n",
      "Epoch: 1456, Loss: 0.7524\n",
      "Epoch: 1457, Loss: 0.7491\n",
      "Epoch: 1458, Loss: 0.7576\n",
      "Epoch: 1459, Loss: 0.7359\n",
      "Epoch: 1460, Loss: 0.7489\n",
      "Epoch: 1461, Loss: 0.7413\n",
      "Epoch: 1462, Loss: 0.7535\n",
      "Epoch: 1463, Loss: 0.7378\n",
      "Epoch: 1464, Loss: 0.7398\n",
      "Epoch: 1465, Loss: 0.7376\n",
      "Epoch: 1466, Loss: 0.7449\n",
      "Epoch: 1467, Loss: 0.7558\n",
      "Epoch: 1468, Loss: 0.7484\n",
      "Epoch: 1469, Loss: 0.7372\n",
      "Epoch: 1470, Loss: 0.7361\n",
      "Epoch: 1471, Loss: 0.7568\n",
      "Epoch: 1472, Loss: 0.7479\n",
      "Epoch: 1473, Loss: 0.7547\n",
      "Epoch: 1474, Loss: 0.7458\n",
      "Epoch: 1475, Loss: 0.7373\n",
      "Epoch: 1476, Loss: 0.7349\n",
      "Epoch: 1477, Loss: 0.7259\n",
      "Epoch: 1478, Loss: 0.7410\n",
      "Epoch: 1479, Loss: 0.7336\n",
      "Epoch: 1480, Loss: 0.7534\n",
      "Epoch: 1481, Loss: 0.7545\n",
      "Epoch: 1482, Loss: 0.7379\n",
      "Epoch: 1483, Loss: 0.7465\n",
      "Epoch: 1484, Loss: 0.7460\n",
      "Epoch: 1485, Loss: 0.7354\n",
      "Epoch: 1486, Loss: 0.7367\n",
      "Epoch: 1487, Loss: 0.7427\n",
      "Epoch: 1488, Loss: 0.7508\n",
      "Epoch: 1489, Loss: 0.7314\n",
      "Epoch: 1490, Loss: 0.7527\n",
      "Epoch: 1491, Loss: 0.7180\n",
      "Epoch: 1492, Loss: 0.7366\n",
      "Epoch: 1493, Loss: 0.7416\n",
      "Epoch: 1494, Loss: 0.7356\n",
      "Epoch: 1495, Loss: 0.7437\n",
      "Epoch: 1496, Loss: 0.7327\n",
      "Epoch: 1497, Loss: 0.7329\n",
      "Epoch: 1498, Loss: 0.7361\n",
      "Epoch: 1499, Loss: 0.7468\n",
      "Epoch: 1500, Loss: 0.7558\n",
      "Epoch: 1501, Loss: 0.7451\n",
      "Epoch: 1502, Loss: 0.7351\n",
      "Epoch: 1503, Loss: 0.7339\n",
      "Epoch: 1504, Loss: 0.7223\n",
      "Epoch: 1505, Loss: 0.7499\n",
      "Epoch: 1506, Loss: 0.7434\n",
      "Epoch: 1507, Loss: 0.7386\n",
      "Epoch: 1508, Loss: 0.7671\n",
      "Epoch: 1509, Loss: 0.7444\n",
      "Epoch: 1510, Loss: 0.7469\n",
      "Epoch: 1511, Loss: 0.7467\n",
      "Epoch: 1512, Loss: 0.7320\n",
      "Epoch: 1513, Loss: 0.7412\n",
      "Epoch: 1514, Loss: 0.7384\n",
      "Epoch: 1515, Loss: 0.7449\n",
      "Epoch: 1516, Loss: 0.7561\n",
      "Epoch: 1517, Loss: 0.7407\n",
      "Epoch: 1518, Loss: 0.7359\n",
      "Epoch: 1519, Loss: 0.7333\n",
      "Epoch: 1520, Loss: 0.7321\n",
      "Epoch: 1521, Loss: 0.7302\n",
      "Epoch: 1522, Loss: 0.7379\n",
      "Epoch: 1523, Loss: 0.7371\n",
      "Epoch: 1524, Loss: 0.7362\n",
      "Epoch: 1525, Loss: 0.7325\n",
      "Epoch: 1526, Loss: 0.7354\n",
      "Epoch: 1527, Loss: 0.7264\n",
      "Epoch: 1528, Loss: 0.7457\n",
      "Epoch: 1529, Loss: 0.7279\n",
      "Epoch: 1530, Loss: 0.7449\n",
      "Epoch: 1531, Loss: 0.7279\n",
      "Epoch: 1532, Loss: 0.7247\n",
      "Epoch: 1533, Loss: 0.7298\n",
      "Epoch: 1534, Loss: 0.7371\n",
      "Epoch: 1535, Loss: 0.7392\n",
      "Epoch: 1536, Loss: 0.7206\n",
      "Epoch: 1537, Loss: 0.7439\n",
      "Epoch: 1538, Loss: 0.7381\n",
      "Epoch: 1539, Loss: 0.7341\n",
      "Epoch: 1540, Loss: 0.7320\n",
      "Epoch: 1541, Loss: 0.7290\n",
      "Epoch: 1542, Loss: 0.7339\n",
      "Epoch: 1543, Loss: 0.7367\n",
      "Epoch: 1544, Loss: 0.7429\n",
      "Epoch: 1545, Loss: 0.7441\n",
      "Epoch: 1546, Loss: 0.7308\n",
      "Epoch: 1547, Loss: 0.7288\n",
      "Epoch: 1548, Loss: 0.7233\n",
      "Epoch: 1549, Loss: 0.7374\n",
      "Epoch: 1550, Loss: 0.7348\n",
      "Epoch: 1551, Loss: 0.7301\n",
      "Epoch: 1552, Loss: 0.7369\n",
      "Epoch: 1553, Loss: 0.7182\n",
      "Epoch: 1554, Loss: 0.7314\n",
      "Epoch: 1555, Loss: 0.7172\n",
      "Epoch: 1556, Loss: 0.7404\n",
      "Epoch: 1557, Loss: 0.7353\n",
      "Epoch: 1558, Loss: 0.7207\n",
      "Epoch: 1559, Loss: 0.7396\n",
      "Epoch: 1560, Loss: 0.7195\n",
      "Epoch: 1561, Loss: 0.7227\n",
      "Epoch: 1562, Loss: 0.7324\n",
      "Epoch: 1563, Loss: 0.7321\n",
      "Epoch: 1564, Loss: 0.7278\n",
      "Epoch: 1565, Loss: 0.7457\n",
      "Epoch: 1566, Loss: 0.7220\n",
      "Epoch: 1567, Loss: 0.7329\n",
      "Epoch: 1568, Loss: 0.7414\n",
      "Epoch: 1569, Loss: 0.7288\n",
      "Epoch: 1570, Loss: 0.7186\n",
      "Epoch: 1571, Loss: 0.7345\n",
      "Epoch: 1572, Loss: 0.7313\n",
      "Epoch: 1573, Loss: 0.7366\n",
      "Epoch: 1574, Loss: 0.7299\n",
      "Epoch: 1575, Loss: 0.7268\n",
      "Epoch: 1576, Loss: 0.7341\n",
      "Epoch: 1577, Loss: 0.7415\n",
      "Epoch: 1578, Loss: 0.7486\n",
      "Epoch: 1579, Loss: 0.7213\n",
      "Epoch: 1580, Loss: 0.7350\n",
      "Epoch: 1581, Loss: 0.7245\n",
      "Epoch: 1582, Loss: 0.7354\n",
      "Epoch: 1583, Loss: 0.7487\n",
      "Epoch: 1584, Loss: 0.7246\n",
      "Epoch: 1585, Loss: 0.7481\n",
      "Epoch: 1586, Loss: 0.7178\n",
      "Epoch: 1587, Loss: 0.7122\n",
      "Epoch: 1588, Loss: 0.7325\n",
      "Epoch: 1589, Loss: 0.7244\n",
      "Epoch: 1590, Loss: 0.7399\n",
      "Epoch: 1591, Loss: 0.7180\n",
      "Epoch: 1592, Loss: 0.7297\n",
      "Epoch: 1593, Loss: 0.7313\n",
      "Epoch: 1594, Loss: 0.7288\n",
      "Epoch: 1595, Loss: 0.7437\n",
      "Epoch: 1596, Loss: 0.7149\n",
      "Epoch: 1597, Loss: 0.7260\n",
      "Epoch: 1598, Loss: 0.7312\n",
      "Epoch: 1599, Loss: 0.7344\n",
      "Epoch: 1600, Loss: 0.7414\n",
      "Epoch: 1601, Loss: 0.7331\n",
      "Epoch: 1602, Loss: 0.7369\n",
      "Epoch: 1603, Loss: 0.7285\n",
      "Epoch: 1604, Loss: 0.7193\n",
      "Epoch: 1605, Loss: 0.7343\n",
      "Epoch: 1606, Loss: 0.7341\n",
      "Epoch: 1607, Loss: 0.7328\n",
      "Epoch: 1608, Loss: 0.7197\n",
      "Epoch: 1609, Loss: 0.7243\n",
      "Epoch: 1610, Loss: 0.7187\n",
      "Epoch: 1611, Loss: 0.7171\n",
      "Epoch: 1612, Loss: 0.7279\n",
      "Epoch: 1613, Loss: 0.7147\n",
      "Epoch: 1614, Loss: 0.7228\n",
      "Epoch: 1615, Loss: 0.7238\n",
      "Epoch: 1616, Loss: 0.7187\n",
      "Epoch: 1617, Loss: 0.7310\n",
      "Epoch: 1618, Loss: 0.7240\n",
      "Epoch: 1619, Loss: 0.7198\n",
      "Epoch: 1620, Loss: 0.7214\n",
      "Epoch: 1621, Loss: 0.7315\n",
      "Epoch: 1622, Loss: 0.7271\n",
      "Epoch: 1623, Loss: 0.7087\n",
      "Epoch: 1624, Loss: 0.7103\n",
      "Epoch: 1625, Loss: 0.7295\n",
      "Epoch: 1626, Loss: 0.7145\n",
      "Epoch: 1627, Loss: 0.7021\n",
      "Epoch: 1628, Loss: 0.7166\n",
      "Epoch: 1629, Loss: 0.7119\n",
      "Epoch: 1630, Loss: 0.7234\n",
      "Epoch: 1631, Loss: 0.7265\n",
      "Epoch: 1632, Loss: 0.7227\n",
      "Epoch: 1633, Loss: 0.7228\n",
      "Epoch: 1634, Loss: 0.7264\n",
      "Epoch: 1635, Loss: 0.7365\n",
      "Epoch: 1636, Loss: 0.7191\n",
      "Epoch: 1637, Loss: 0.7334\n",
      "Epoch: 1638, Loss: 0.7134\n",
      "Epoch: 1639, Loss: 0.6965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1640, Loss: 0.7210\n",
      "Epoch: 1641, Loss: 0.7190\n",
      "Epoch: 1642, Loss: 0.7044\n",
      "Epoch: 1643, Loss: 0.7195\n",
      "Epoch: 1644, Loss: 0.7264\n",
      "Epoch: 1645, Loss: 0.7353\n",
      "Epoch: 1646, Loss: 0.7143\n",
      "Epoch: 1647, Loss: 0.7308\n",
      "Epoch: 1648, Loss: 0.7240\n",
      "Epoch: 1649, Loss: 0.7320\n",
      "Epoch: 1650, Loss: 0.7256\n",
      "Epoch: 1651, Loss: 0.7225\n",
      "Epoch: 1652, Loss: 0.7293\n",
      "Epoch: 1653, Loss: 0.7271\n",
      "Epoch: 1654, Loss: 0.7192\n",
      "Epoch: 1655, Loss: 0.7112\n",
      "Epoch: 1656, Loss: 0.7104\n",
      "Epoch: 1657, Loss: 0.7140\n",
      "Epoch: 1658, Loss: 0.7255\n",
      "Epoch: 1659, Loss: 0.7176\n",
      "Epoch: 1660, Loss: 0.7240\n",
      "Epoch: 1661, Loss: 0.7125\n",
      "Epoch: 1662, Loss: 0.7200\n",
      "Epoch: 1663, Loss: 0.7077\n",
      "Epoch: 1664, Loss: 0.7196\n",
      "Epoch: 1665, Loss: 0.7143\n",
      "Epoch: 1666, Loss: 0.7124\n",
      "Epoch: 1667, Loss: 0.7047\n",
      "Epoch: 1668, Loss: 0.7173\n",
      "Epoch: 1669, Loss: 0.7134\n",
      "Epoch: 1670, Loss: 0.7116\n",
      "Epoch: 1671, Loss: 0.7139\n",
      "Epoch: 1672, Loss: 0.7243\n",
      "Epoch: 1673, Loss: 0.7214\n",
      "Epoch: 1674, Loss: 0.7151\n",
      "Epoch: 1675, Loss: 0.7261\n",
      "Epoch: 1676, Loss: 0.7225\n",
      "Epoch: 1677, Loss: 0.7294\n",
      "Epoch: 1678, Loss: 0.7126\n",
      "Epoch: 1679, Loss: 0.7162\n",
      "Epoch: 1680, Loss: 0.7248\n",
      "Epoch: 1681, Loss: 0.7227\n",
      "Epoch: 1682, Loss: 0.7164\n",
      "Epoch: 1683, Loss: 0.7422\n",
      "Epoch: 1684, Loss: 0.7252\n",
      "Epoch: 1685, Loss: 0.7194\n",
      "Epoch: 1686, Loss: 0.7176\n",
      "Epoch: 1687, Loss: 0.7255\n",
      "Epoch: 1688, Loss: 0.7192\n",
      "Epoch: 1689, Loss: 0.7115\n",
      "Epoch: 1690, Loss: 0.7149\n",
      "Epoch: 1691, Loss: 0.7175\n",
      "Epoch: 1692, Loss: 0.7236\n",
      "Epoch: 1693, Loss: 0.7254\n",
      "Epoch: 1694, Loss: 0.7256\n",
      "Epoch: 1695, Loss: 0.7202\n",
      "Epoch: 1696, Loss: 0.7066\n",
      "Epoch: 1697, Loss: 0.7065\n",
      "Epoch: 1698, Loss: 0.7111\n",
      "Epoch: 1699, Loss: 0.7192\n",
      "Epoch: 1700, Loss: 0.7092\n",
      "Epoch: 1701, Loss: 0.7210\n",
      "Epoch: 1702, Loss: 0.7006\n",
      "Epoch: 1703, Loss: 0.7205\n",
      "Epoch: 1704, Loss: 0.7080\n",
      "Epoch: 1705, Loss: 0.7131\n",
      "Epoch: 1706, Loss: 0.7134\n",
      "Epoch: 1707, Loss: 0.7163\n",
      "Epoch: 1708, Loss: 0.7132\n",
      "Epoch: 1709, Loss: 0.7061\n",
      "Epoch: 1710, Loss: 0.7211\n",
      "Epoch: 1711, Loss: 0.7042\n",
      "Epoch: 1712, Loss: 0.7122\n",
      "Epoch: 1713, Loss: 0.6826\n",
      "Epoch: 1714, Loss: 0.7256\n",
      "Epoch: 1715, Loss: 0.7100\n",
      "Epoch: 1716, Loss: 0.7060\n",
      "Epoch: 1717, Loss: 0.7183\n",
      "Epoch: 1718, Loss: 0.7166\n",
      "Epoch: 1719, Loss: 0.7130\n",
      "Epoch: 1720, Loss: 0.7074\n",
      "Epoch: 1721, Loss: 0.7230\n",
      "Epoch: 1722, Loss: 0.7077\n",
      "Epoch: 1723, Loss: 0.7129\n",
      "Epoch: 1724, Loss: 0.7199\n",
      "Epoch: 1725, Loss: 0.7165\n",
      "Epoch: 1726, Loss: 0.7194\n",
      "Epoch: 1727, Loss: 0.7032\n",
      "Epoch: 1728, Loss: 0.7192\n",
      "Epoch: 1729, Loss: 0.7154\n",
      "Epoch: 1730, Loss: 0.7251\n",
      "Epoch: 1731, Loss: 0.7194\n",
      "Epoch: 1732, Loss: 0.7112\n",
      "Epoch: 1733, Loss: 0.7316\n",
      "Epoch: 1734, Loss: 0.7046\n",
      "Epoch: 1735, Loss: 0.7239\n",
      "Epoch: 1736, Loss: 0.7357\n",
      "Epoch: 1737, Loss: 0.7109\n",
      "Epoch: 1738, Loss: 0.7157\n",
      "Epoch: 1739, Loss: 0.7104\n",
      "Epoch: 1740, Loss: 0.7175\n",
      "Epoch: 1741, Loss: 0.7164\n",
      "Epoch: 1742, Loss: 0.6958\n",
      "Epoch: 1743, Loss: 0.7163\n",
      "Epoch: 1744, Loss: 0.7190\n",
      "Epoch: 1745, Loss: 0.7124\n",
      "Epoch: 1746, Loss: 0.7102\n",
      "Epoch: 1747, Loss: 0.7130\n",
      "Epoch: 1748, Loss: 0.7116\n",
      "Epoch: 1749, Loss: 0.7140\n",
      "Epoch: 1750, Loss: 0.7121\n",
      "Epoch: 1751, Loss: 0.7314\n",
      "Epoch: 1752, Loss: 0.6955\n",
      "Epoch: 1753, Loss: 0.7135\n",
      "Epoch: 1754, Loss: 0.7086\n",
      "Epoch: 1755, Loss: 0.7162\n",
      "Epoch: 1756, Loss: 0.7180\n",
      "Epoch: 1757, Loss: 0.7077\n",
      "Epoch: 1758, Loss: 0.7202\n",
      "Epoch: 1759, Loss: 0.7233\n",
      "Epoch: 1760, Loss: 0.7080\n",
      "Epoch: 1761, Loss: 0.7125\n",
      "Epoch: 1762, Loss: 0.7036\n",
      "Epoch: 1763, Loss: 0.7095\n",
      "Epoch: 1764, Loss: 0.7140\n",
      "Epoch: 1765, Loss: 0.7040\n",
      "Epoch: 1766, Loss: 0.7298\n",
      "Epoch: 1767, Loss: 0.7272\n",
      "Epoch: 1768, Loss: 0.7069\n",
      "Epoch: 1769, Loss: 0.7126\n",
      "Epoch: 1770, Loss: 0.6947\n",
      "Epoch: 1771, Loss: 0.7079\n",
      "Epoch: 1772, Loss: 0.7112\n",
      "Epoch: 1773, Loss: 0.6919\n",
      "Epoch: 1774, Loss: 0.7109\n",
      "Epoch: 1775, Loss: 0.7026\n",
      "Epoch: 1776, Loss: 0.7143\n",
      "Epoch: 1777, Loss: 0.6947\n",
      "Epoch: 1778, Loss: 0.6966\n",
      "Epoch: 1779, Loss: 0.7081\n",
      "Epoch: 1780, Loss: 0.6920\n",
      "Epoch: 1781, Loss: 0.6949\n",
      "Epoch: 1782, Loss: 0.7111\n",
      "Epoch: 1783, Loss: 0.7054\n",
      "Epoch: 1784, Loss: 0.7068\n",
      "Epoch: 1785, Loss: 0.7001\n",
      "Epoch: 1786, Loss: 0.6827\n",
      "Epoch: 1787, Loss: 0.7000\n",
      "Epoch: 1788, Loss: 0.7101\n",
      "Epoch: 1789, Loss: 0.6987\n",
      "Epoch: 1790, Loss: 0.7167\n",
      "Epoch: 1791, Loss: 0.7044\n",
      "Epoch: 1792, Loss: 0.7021\n",
      "Epoch: 1793, Loss: 0.7043\n",
      "Epoch: 1794, Loss: 0.7097\n",
      "Epoch: 1795, Loss: 0.6907\n",
      "Epoch: 1796, Loss: 0.7067\n",
      "Epoch: 1797, Loss: 0.6957\n",
      "Epoch: 1798, Loss: 0.7038\n",
      "Epoch: 1799, Loss: 0.7035\n",
      "Epoch: 1800, Loss: 0.7256\n",
      "Epoch: 1801, Loss: 0.7035\n",
      "Epoch: 1802, Loss: 0.7008\n",
      "Epoch: 1803, Loss: 0.7074\n",
      "Epoch: 1804, Loss: 0.7165\n",
      "Epoch: 1805, Loss: 0.6900\n",
      "Epoch: 1806, Loss: 0.6925\n",
      "Epoch: 1807, Loss: 0.7142\n",
      "Epoch: 1808, Loss: 0.6912\n",
      "Epoch: 1809, Loss: 0.7007\n",
      "Epoch: 1810, Loss: 0.6995\n",
      "Epoch: 1811, Loss: 0.7102\n",
      "Epoch: 1812, Loss: 0.7090\n",
      "Epoch: 1813, Loss: 0.7129\n",
      "Epoch: 1814, Loss: 0.7010\n",
      "Epoch: 1815, Loss: 0.6971\n",
      "Epoch: 1816, Loss: 0.7004\n",
      "Epoch: 1817, Loss: 0.7040\n",
      "Epoch: 1818, Loss: 0.7027\n",
      "Epoch: 1819, Loss: 0.6831\n",
      "Epoch: 1820, Loss: 0.7224\n",
      "Epoch: 1821, Loss: 0.6986\n",
      "Epoch: 1822, Loss: 0.6980\n",
      "Epoch: 1823, Loss: 0.6962\n",
      "Epoch: 1824, Loss: 0.7062\n",
      "Epoch: 1825, Loss: 0.6927\n",
      "Epoch: 1826, Loss: 0.7073\n",
      "Epoch: 1827, Loss: 0.6899\n",
      "Epoch: 1828, Loss: 0.6934\n",
      "Epoch: 1829, Loss: 0.6802\n",
      "Epoch: 1830, Loss: 0.6984\n",
      "Epoch: 1831, Loss: 0.6931\n",
      "Epoch: 1832, Loss: 0.7110\n",
      "Epoch: 1833, Loss: 0.6937\n",
      "Epoch: 1834, Loss: 0.7020\n",
      "Epoch: 1835, Loss: 0.7009\n",
      "Epoch: 1836, Loss: 0.7144\n",
      "Epoch: 1837, Loss: 0.7160\n",
      "Epoch: 1838, Loss: 0.6941\n",
      "Epoch: 1839, Loss: 0.7033\n",
      "Epoch: 1840, Loss: 0.7019\n",
      "Epoch: 1841, Loss: 0.7054\n",
      "Epoch: 1842, Loss: 0.7166\n",
      "Epoch: 1843, Loss: 0.6858\n",
      "Epoch: 1844, Loss: 0.7120\n",
      "Epoch: 1845, Loss: 0.6930\n",
      "Epoch: 1846, Loss: 0.6974\n",
      "Epoch: 1847, Loss: 0.7144\n",
      "Epoch: 1848, Loss: 0.7001\n",
      "Epoch: 1849, Loss: 0.6978\n",
      "Epoch: 1850, Loss: 0.6956\n",
      "Epoch: 1851, Loss: 0.7212\n",
      "Epoch: 1852, Loss: 0.7170\n",
      "Epoch: 1853, Loss: 0.6961\n",
      "Epoch: 1854, Loss: 0.7018\n",
      "Epoch: 1855, Loss: 0.7048\n",
      "Epoch: 1856, Loss: 0.7165\n",
      "Epoch: 1857, Loss: 0.7073\n",
      "Epoch: 1858, Loss: 0.6863\n",
      "Epoch: 1859, Loss: 0.7116\n",
      "Epoch: 1860, Loss: 0.6896\n",
      "Epoch: 1861, Loss: 0.7108\n",
      "Epoch: 1862, Loss: 0.6925\n",
      "Epoch: 1863, Loss: 0.6946\n",
      "Epoch: 1864, Loss: 0.6956\n",
      "Epoch: 1865, Loss: 0.6898\n",
      "Epoch: 1866, Loss: 0.7015\n",
      "Epoch: 1867, Loss: 0.6968\n",
      "Epoch: 1868, Loss: 0.6983\n",
      "Epoch: 1869, Loss: 0.6912\n",
      "Epoch: 1870, Loss: 0.6951\n",
      "Epoch: 1871, Loss: 0.6980\n",
      "Epoch: 1872, Loss: 0.6693\n",
      "Epoch: 1873, Loss: 0.6938\n",
      "Epoch: 1874, Loss: 0.6809\n",
      "Epoch: 1875, Loss: 0.7048\n",
      "Epoch: 1876, Loss: 0.7106\n",
      "Epoch: 1877, Loss: 0.6894\n",
      "Epoch: 1878, Loss: 0.6980\n",
      "Epoch: 1879, Loss: 0.6865\n",
      "Epoch: 1880, Loss: 0.7012\n",
      "Epoch: 1881, Loss: 0.6894\n",
      "Epoch: 1882, Loss: 0.6813\n",
      "Epoch: 1883, Loss: 0.7038\n",
      "Epoch: 1884, Loss: 0.6747\n",
      "Epoch: 1885, Loss: 0.6911\n",
      "Epoch: 1886, Loss: 0.6891\n",
      "Epoch: 1887, Loss: 0.6931\n",
      "Epoch: 1888, Loss: 0.6800\n",
      "Epoch: 1889, Loss: 0.6869\n",
      "Epoch: 1890, Loss: 0.6986\n",
      "Epoch: 1891, Loss: 0.6830\n",
      "Epoch: 1892, Loss: 0.6870\n",
      "Epoch: 1893, Loss: 0.6876\n",
      "Epoch: 1894, Loss: 0.6728\n",
      "Epoch: 1895, Loss: 0.6912\n",
      "Epoch: 1896, Loss: 0.6916\n",
      "Epoch: 1897, Loss: 0.6874\n",
      "Epoch: 1898, Loss: 0.6878\n",
      "Epoch: 1899, Loss: 0.6871\n",
      "Epoch: 1900, Loss: 0.6904\n",
      "Epoch: 1901, Loss: 0.6872\n",
      "Epoch: 1902, Loss: 0.6946\n",
      "Epoch: 1903, Loss: 0.6690\n",
      "Epoch: 1904, Loss: 0.6794\n",
      "Epoch: 1905, Loss: 0.6834\n",
      "Epoch: 1906, Loss: 0.6724\n",
      "Epoch: 1907, Loss: 0.6910\n",
      "Epoch: 1908, Loss: 0.6874\n",
      "Epoch: 1909, Loss: 0.6835\n",
      "Epoch: 1910, Loss: 0.6820\n",
      "Epoch: 1911, Loss: 0.6757\n",
      "Epoch: 1912, Loss: 0.6675\n",
      "Epoch: 1913, Loss: 0.6825\n",
      "Epoch: 1914, Loss: 0.6713\n",
      "Epoch: 1915, Loss: 0.6771\n",
      "Epoch: 1916, Loss: 0.6790\n",
      "Epoch: 1917, Loss: 0.6651\n",
      "Epoch: 1918, Loss: 0.6895\n",
      "Epoch: 1919, Loss: 0.6756\n",
      "Epoch: 1920, Loss: 0.6785\n",
      "Epoch: 1921, Loss: 0.6734\n",
      "Epoch: 1922, Loss: 0.6774\n",
      "Epoch: 1923, Loss: 0.6807\n",
      "Epoch: 1924, Loss: 0.6672\n",
      "Epoch: 1925, Loss: 0.6729\n",
      "Epoch: 1926, Loss: 0.6848\n",
      "Epoch: 1927, Loss: 0.6711\n",
      "Epoch: 1928, Loss: 0.6821\n",
      "Epoch: 1929, Loss: 0.6777\n",
      "Epoch: 1930, Loss: 0.6675\n",
      "Epoch: 1931, Loss: 0.6717\n",
      "Epoch: 1932, Loss: 0.6709\n",
      "Epoch: 1933, Loss: 0.6754\n",
      "Epoch: 1934, Loss: 0.6714\n",
      "Epoch: 1935, Loss: 0.6717\n",
      "Epoch: 1936, Loss: 0.6683\n",
      "Epoch: 1937, Loss: 0.6749\n",
      "Epoch: 1938, Loss: 0.6654\n",
      "Epoch: 1939, Loss: 0.6711\n",
      "Epoch: 1940, Loss: 0.6632\n",
      "Epoch: 1941, Loss: 0.6666\n",
      "Epoch: 1942, Loss: 0.6565\n",
      "Epoch: 1943, Loss: 0.6704\n",
      "Epoch: 1944, Loss: 0.6702\n",
      "Epoch: 1945, Loss: 0.6792\n",
      "Epoch: 1946, Loss: 0.6677\n",
      "Epoch: 1947, Loss: 0.6513\n",
      "Epoch: 1948, Loss: 0.6790\n",
      "Epoch: 1949, Loss: 0.6679\n",
      "Epoch: 1950, Loss: 0.6578\n",
      "Epoch: 1951, Loss: 0.6768\n",
      "Epoch: 1952, Loss: 0.6814\n",
      "Epoch: 1953, Loss: 0.6676\n",
      "Epoch: 1954, Loss: 0.6704\n",
      "Epoch: 1955, Loss: 0.6645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1956, Loss: 0.6766\n",
      "Epoch: 1957, Loss: 0.6689\n",
      "Epoch: 1958, Loss: 0.6745\n",
      "Epoch: 1959, Loss: 0.6693\n",
      "Epoch: 1960, Loss: 0.6818\n",
      "Epoch: 1961, Loss: 0.6737\n",
      "Epoch: 1962, Loss: 0.6610\n",
      "Epoch: 1963, Loss: 0.6664\n",
      "Epoch: 1964, Loss: 0.6634\n",
      "Epoch: 1965, Loss: 0.6642\n",
      "Epoch: 1966, Loss: 0.6700\n",
      "Epoch: 1967, Loss: 0.6618\n",
      "Epoch: 1968, Loss: 0.6682\n",
      "Epoch: 1969, Loss: 0.6544\n",
      "Epoch: 1970, Loss: 0.6646\n",
      "Epoch: 1971, Loss: 0.6690\n",
      "Epoch: 1972, Loss: 0.6504\n",
      "Epoch: 1973, Loss: 0.6668\n",
      "Epoch: 1974, Loss: 0.6586\n",
      "Epoch: 1975, Loss: 0.6681\n",
      "Epoch: 1976, Loss: 0.6662\n",
      "Epoch: 1977, Loss: 0.6721\n",
      "Epoch: 1978, Loss: 0.6727\n",
      "Epoch: 1979, Loss: 0.6674\n",
      "Epoch: 1980, Loss: 0.6644\n",
      "Epoch: 1981, Loss: 0.6601\n",
      "Epoch: 1982, Loss: 0.6567\n",
      "Epoch: 1983, Loss: 0.6623\n",
      "Epoch: 1984, Loss: 0.6541\n",
      "Epoch: 1985, Loss: 0.6609\n",
      "Epoch: 1986, Loss: 0.6689\n",
      "Epoch: 1987, Loss: 0.6691\n",
      "Epoch: 1988, Loss: 0.6795\n",
      "Epoch: 1989, Loss: 0.6648\n",
      "Epoch: 1990, Loss: 0.6602\n",
      "Epoch: 1991, Loss: 0.6610\n",
      "Epoch: 1992, Loss: 0.6499\n",
      "Epoch: 1993, Loss: 0.6651\n",
      "Epoch: 1994, Loss: 0.6478\n",
      "Epoch: 1995, Loss: 0.6745\n",
      "Epoch: 1996, Loss: 0.6504\n",
      "Epoch: 1997, Loss: 0.6665\n",
      "Epoch: 1998, Loss: 0.6694\n",
      "Epoch: 1999, Loss: 0.6601\n",
      "Epoch: 2000, Loss: 0.6655\n",
      "Epoch: 2001, Loss: 0.6670\n",
      "Epoch: 2002, Loss: 0.6648\n",
      "Epoch: 2003, Loss: 0.6698\n",
      "Epoch: 2004, Loss: 0.6611\n",
      "Epoch: 2005, Loss: 0.6542\n",
      "Epoch: 2006, Loss: 0.6548\n",
      "Epoch: 2007, Loss: 0.6818\n",
      "Epoch: 2008, Loss: 0.6614\n",
      "Epoch: 2009, Loss: 0.6664\n",
      "Epoch: 2010, Loss: 0.6467\n",
      "Epoch: 2011, Loss: 0.6467\n",
      "Epoch: 2012, Loss: 0.6603\n",
      "Epoch: 2013, Loss: 0.6667\n",
      "Epoch: 2014, Loss: 0.6408\n",
      "Epoch: 2015, Loss: 0.6551\n",
      "Epoch: 2016, Loss: 0.6610\n",
      "Epoch: 2017, Loss: 0.6381\n",
      "Epoch: 2018, Loss: 0.6540\n",
      "Epoch: 2019, Loss: 0.6596\n",
      "Epoch: 2020, Loss: 0.6386\n",
      "Epoch: 2021, Loss: 0.6554\n",
      "Epoch: 2022, Loss: 0.6356\n",
      "Epoch: 2023, Loss: 0.6525\n",
      "Epoch: 2024, Loss: 0.6523\n",
      "Epoch: 2025, Loss: 0.6657\n",
      "Epoch: 2026, Loss: 0.6567\n",
      "Epoch: 2027, Loss: 0.6547\n",
      "Epoch: 2028, Loss: 0.6564\n",
      "Epoch: 2029, Loss: 0.6615\n",
      "Epoch: 2030, Loss: 0.6478\n",
      "Epoch: 2031, Loss: 0.6661\n",
      "Epoch: 2032, Loss: 0.6630\n",
      "Epoch: 2033, Loss: 0.6652\n",
      "Epoch: 2034, Loss: 0.6582\n",
      "Epoch: 2035, Loss: 0.6571\n",
      "Epoch: 2036, Loss: 0.6573\n",
      "Epoch: 2037, Loss: 0.6635\n",
      "Epoch: 2038, Loss: 0.6627\n",
      "Epoch: 2039, Loss: 0.6620\n",
      "Epoch: 2040, Loss: 0.6457\n",
      "Epoch: 2041, Loss: 0.6538\n",
      "Epoch: 2042, Loss: 0.6408\n",
      "Epoch: 2043, Loss: 0.6596\n",
      "Epoch: 2044, Loss: 0.6418\n",
      "Epoch: 2045, Loss: 0.6675\n",
      "Epoch: 2046, Loss: 0.6544\n",
      "Epoch: 2047, Loss: 0.6426\n",
      "Epoch: 2048, Loss: 0.6640\n",
      "Epoch: 2049, Loss: 0.6555\n",
      "Epoch: 2050, Loss: 0.6523\n",
      "Epoch: 2051, Loss: 0.6487\n",
      "Epoch: 2052, Loss: 0.6483\n",
      "Epoch: 2053, Loss: 0.6541\n",
      "Epoch: 2054, Loss: 0.6606\n",
      "Epoch: 2055, Loss: 0.6646\n",
      "Epoch: 2056, Loss: 0.6651\n",
      "Epoch: 2057, Loss: 0.6469\n",
      "Epoch: 2058, Loss: 0.6367\n",
      "Epoch: 2059, Loss: 0.6428\n",
      "Epoch: 2060, Loss: 0.6536\n",
      "Epoch: 2061, Loss: 0.6512\n",
      "Epoch: 2062, Loss: 0.6461\n",
      "Epoch: 2063, Loss: 0.6563\n",
      "Epoch: 2064, Loss: 0.6596\n",
      "Epoch: 2065, Loss: 0.6461\n",
      "Epoch: 2066, Loss: 0.6405\n",
      "Epoch: 2067, Loss: 0.6494\n",
      "Epoch: 2068, Loss: 0.6513\n",
      "Epoch: 2069, Loss: 0.6462\n",
      "Epoch: 2070, Loss: 0.6606\n",
      "Epoch: 2071, Loss: 0.6420\n",
      "Epoch: 2072, Loss: 0.6354\n",
      "Epoch: 2073, Loss: 0.6404\n",
      "Epoch: 2074, Loss: 0.6421\n",
      "Epoch: 2075, Loss: 0.6410\n",
      "Epoch: 2076, Loss: 0.6605\n",
      "Epoch: 2077, Loss: 0.6426\n",
      "Epoch: 2078, Loss: 0.6451\n",
      "Epoch: 2079, Loss: 0.6320\n",
      "Epoch: 2080, Loss: 0.6467\n",
      "Epoch: 2081, Loss: 0.6481\n",
      "Epoch: 2082, Loss: 0.6303\n",
      "Epoch: 2083, Loss: 0.6335\n",
      "Epoch: 2084, Loss: 0.6579\n",
      "Epoch: 2085, Loss: 0.6493\n",
      "Epoch: 2086, Loss: 0.6545\n",
      "Epoch: 2087, Loss: 0.6491\n",
      "Epoch: 2088, Loss: 0.6409\n",
      "Epoch: 2089, Loss: 0.6439\n",
      "Epoch: 2090, Loss: 0.6408\n",
      "Epoch: 2091, Loss: 0.6483\n",
      "Epoch: 2092, Loss: 0.6408\n",
      "Epoch: 2093, Loss: 0.6349\n",
      "Epoch: 2094, Loss: 0.6402\n",
      "Epoch: 2095, Loss: 0.6393\n",
      "Epoch: 2096, Loss: 0.6436\n",
      "Epoch: 2097, Loss: 0.6335\n",
      "Epoch: 2098, Loss: 0.6416\n",
      "Epoch: 2099, Loss: 0.6456\n",
      "Epoch: 2100, Loss: 0.6286\n",
      "Epoch: 2101, Loss: 0.6539\n",
      "Epoch: 2102, Loss: 0.6492\n",
      "Epoch: 2103, Loss: 0.6472\n",
      "Epoch: 2104, Loss: 0.6442\n",
      "Epoch: 2105, Loss: 0.6588\n",
      "Epoch: 2106, Loss: 0.6543\n",
      "Epoch: 2107, Loss: 0.6557\n",
      "Epoch: 2108, Loss: 0.6603\n",
      "Epoch: 2109, Loss: 0.6400\n",
      "Epoch: 2110, Loss: 0.6446\n",
      "Epoch: 2111, Loss: 0.6435\n",
      "Epoch: 2112, Loss: 0.6480\n",
      "Epoch: 2113, Loss: 0.6471\n",
      "Epoch: 2114, Loss: 0.6280\n",
      "Epoch: 2115, Loss: 0.6475\n",
      "Epoch: 2116, Loss: 0.6337\n",
      "Epoch: 2117, Loss: 0.6462\n",
      "Epoch: 2118, Loss: 0.6468\n",
      "Epoch: 2119, Loss: 0.6302\n",
      "Epoch: 2120, Loss: 0.6375\n",
      "Epoch: 2121, Loss: 0.6323\n",
      "Epoch: 2122, Loss: 0.6282\n",
      "Epoch: 2123, Loss: 0.6455\n",
      "Epoch: 2124, Loss: 0.6402\n",
      "Epoch: 2125, Loss: 0.6541\n",
      "Epoch: 2126, Loss: 0.6273\n",
      "Epoch: 2127, Loss: 0.6434\n",
      "Epoch: 2128, Loss: 0.6457\n",
      "Epoch: 2129, Loss: 0.6431\n",
      "Epoch: 2130, Loss: 0.6355\n",
      "Epoch: 2131, Loss: 0.6380\n",
      "Epoch: 2132, Loss: 0.6480\n",
      "Epoch: 2133, Loss: 0.6505\n",
      "Epoch: 2134, Loss: 0.6310\n",
      "Epoch: 2135, Loss: 0.6346\n",
      "Epoch: 2136, Loss: 0.6437\n",
      "Epoch: 2137, Loss: 0.6274\n",
      "Epoch: 2138, Loss: 0.6360\n",
      "Epoch: 2139, Loss: 0.6582\n",
      "Epoch: 2140, Loss: 0.6341\n",
      "Epoch: 2141, Loss: 0.6412\n",
      "Epoch: 2142, Loss: 0.6451\n",
      "Epoch: 2143, Loss: 0.6403\n",
      "Epoch: 2144, Loss: 0.6324\n",
      "Epoch: 2145, Loss: 0.6351\n",
      "Epoch: 2146, Loss: 0.6504\n",
      "Epoch: 2147, Loss: 0.6325\n",
      "Epoch: 2148, Loss: 0.6364\n",
      "Epoch: 2149, Loss: 0.6351\n",
      "Epoch: 2150, Loss: 0.6286\n",
      "Epoch: 2151, Loss: 0.6437\n",
      "Epoch: 2152, Loss: 0.6400\n",
      "Epoch: 2153, Loss: 0.6351\n",
      "Epoch: 2154, Loss: 0.6191\n",
      "Epoch: 2155, Loss: 0.6344\n",
      "Epoch: 2156, Loss: 0.6273\n",
      "Epoch: 2157, Loss: 0.6326\n",
      "Epoch: 2158, Loss: 0.6481\n",
      "Epoch: 2159, Loss: 0.6172\n",
      "Epoch: 2160, Loss: 0.6264\n",
      "Epoch: 2161, Loss: 0.6273\n",
      "Epoch: 2162, Loss: 0.6344\n",
      "Epoch: 2163, Loss: 0.6317\n",
      "Epoch: 2164, Loss: 0.6351\n",
      "Epoch: 2165, Loss: 0.6542\n",
      "Epoch: 2166, Loss: 0.6337\n",
      "Epoch: 2167, Loss: 0.6384\n",
      "Epoch: 2168, Loss: 0.6232\n",
      "Epoch: 2169, Loss: 0.6461\n",
      "Epoch: 2170, Loss: 0.6257\n",
      "Epoch: 2171, Loss: 0.6253\n",
      "Epoch: 2172, Loss: 0.6444\n",
      "Epoch: 2173, Loss: 0.6368\n",
      "Epoch: 2174, Loss: 0.6244\n",
      "Epoch: 2175, Loss: 0.6331\n",
      "Epoch: 2176, Loss: 0.6264\n",
      "Epoch: 2177, Loss: 0.6279\n",
      "Epoch: 2178, Loss: 0.6258\n",
      "Epoch: 2179, Loss: 0.6377\n",
      "Epoch: 2180, Loss: 0.6249\n",
      "Epoch: 2181, Loss: 0.6323\n",
      "Epoch: 2182, Loss: 0.6232\n",
      "Epoch: 2183, Loss: 0.6324\n",
      "Epoch: 2184, Loss: 0.6264\n",
      "Epoch: 2185, Loss: 0.6258\n",
      "Epoch: 2186, Loss: 0.6302\n",
      "Epoch: 2187, Loss: 0.6367\n",
      "Epoch: 2188, Loss: 0.6295\n",
      "Epoch: 2189, Loss: 0.6328\n",
      "Epoch: 2190, Loss: 0.6382\n",
      "Epoch: 2191, Loss: 0.6258\n",
      "Epoch: 2192, Loss: 0.6214\n",
      "Epoch: 2193, Loss: 0.6399\n",
      "Epoch: 2194, Loss: 0.6357\n",
      "Epoch: 2195, Loss: 0.6226\n",
      "Epoch: 2196, Loss: 0.6329\n",
      "Epoch: 2197, Loss: 0.6314\n",
      "Epoch: 2198, Loss: 0.6301\n",
      "Epoch: 2199, Loss: 0.6245\n",
      "Epoch: 2200, Loss: 0.6262\n",
      "Epoch: 2201, Loss: 0.6280\n",
      "Epoch: 2202, Loss: 0.6196\n",
      "Epoch: 2203, Loss: 0.6323\n",
      "Epoch: 2204, Loss: 0.6388\n",
      "Epoch: 2205, Loss: 0.6349\n",
      "Epoch: 2206, Loss: 0.6338\n",
      "Epoch: 2207, Loss: 0.6415\n",
      "Epoch: 2208, Loss: 0.6341\n",
      "Epoch: 2209, Loss: 0.6473\n",
      "Epoch: 2210, Loss: 0.6344\n",
      "Epoch: 2211, Loss: 0.6322\n",
      "Epoch: 2212, Loss: 0.6227\n",
      "Epoch: 2213, Loss: 0.6237\n",
      "Epoch: 2214, Loss: 0.6256\n",
      "Epoch: 2215, Loss: 0.6147\n",
      "Epoch: 2216, Loss: 0.6295\n",
      "Epoch: 2217, Loss: 0.6196\n",
      "Epoch: 2218, Loss: 0.6332\n",
      "Epoch: 2219, Loss: 0.6279\n",
      "Epoch: 2220, Loss: 0.6249\n",
      "Epoch: 2221, Loss: 0.6307\n",
      "Epoch: 2222, Loss: 0.6205\n",
      "Epoch: 2223, Loss: 0.6141\n",
      "Epoch: 2224, Loss: 0.6399\n",
      "Epoch: 2225, Loss: 0.6250\n",
      "Epoch: 2226, Loss: 0.6318\n",
      "Epoch: 2227, Loss: 0.6196\n",
      "Epoch: 2228, Loss: 0.6239\n",
      "Epoch: 2229, Loss: 0.6258\n",
      "Epoch: 2230, Loss: 0.6314\n",
      "Epoch: 2231, Loss: 0.6111\n",
      "Epoch: 2232, Loss: 0.6306\n",
      "Epoch: 2233, Loss: 0.6350\n",
      "Epoch: 2234, Loss: 0.6296\n",
      "Epoch: 2235, Loss: 0.6200\n",
      "Epoch: 2236, Loss: 0.6135\n",
      "Epoch: 2237, Loss: 0.6221\n",
      "Epoch: 2238, Loss: 0.6240\n",
      "Epoch: 2239, Loss: 0.6225\n",
      "Epoch: 2240, Loss: 0.6264\n",
      "Epoch: 2241, Loss: 0.6266\n",
      "Epoch: 2242, Loss: 0.6161\n",
      "Epoch: 2243, Loss: 0.6122\n",
      "Epoch: 2244, Loss: 0.6185\n",
      "Epoch: 2245, Loss: 0.6268\n",
      "Epoch: 2246, Loss: 0.6116\n",
      "Epoch: 2247, Loss: 0.6344\n",
      "Epoch: 2248, Loss: 0.6265\n",
      "Epoch: 2249, Loss: 0.6255\n",
      "Epoch: 2250, Loss: 0.6181\n",
      "Epoch: 2251, Loss: 0.6260\n",
      "Epoch: 2252, Loss: 0.6199\n",
      "Epoch: 2253, Loss: 0.6253\n",
      "Epoch: 2254, Loss: 0.6234\n",
      "Epoch: 2255, Loss: 0.6375\n",
      "Epoch: 2256, Loss: 0.6201\n",
      "Epoch: 2257, Loss: 0.6082\n",
      "Epoch: 2258, Loss: 0.6187\n",
      "Epoch: 2259, Loss: 0.6156\n",
      "Epoch: 2260, Loss: 0.6121\n",
      "Epoch: 2261, Loss: 0.6257\n",
      "Epoch: 2262, Loss: 0.6120\n",
      "Epoch: 2263, Loss: 0.6228\n",
      "Epoch: 2264, Loss: 0.6273\n",
      "Epoch: 2265, Loss: 0.6148\n",
      "Epoch: 2266, Loss: 0.6167\n",
      "Epoch: 2267, Loss: 0.6244\n",
      "Epoch: 2268, Loss: 0.6291\n",
      "Epoch: 2269, Loss: 0.6107\n",
      "Epoch: 2270, Loss: 0.6194\n",
      "Epoch: 2271, Loss: 0.6226\n",
      "Epoch: 2272, Loss: 0.6221\n",
      "Epoch: 2273, Loss: 0.6184\n",
      "Epoch: 2274, Loss: 0.6209\n",
      "Epoch: 2275, Loss: 0.6343\n",
      "Epoch: 2276, Loss: 0.6128\n",
      "Epoch: 2277, Loss: 0.6335\n",
      "Epoch: 2278, Loss: 0.6140\n",
      "Epoch: 2279, Loss: 0.6169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2280, Loss: 0.6267\n",
      "Epoch: 2281, Loss: 0.6173\n",
      "Epoch: 2282, Loss: 0.6248\n",
      "Epoch: 2283, Loss: 0.6152\n",
      "Epoch: 2284, Loss: 0.6255\n",
      "Epoch: 2285, Loss: 0.6212\n",
      "Epoch: 2286, Loss: 0.6147\n",
      "Epoch: 2287, Loss: 0.6110\n",
      "Epoch: 2288, Loss: 0.6185\n",
      "Epoch: 2289, Loss: 0.6176\n",
      "Epoch: 2290, Loss: 0.6163\n",
      "Epoch: 2291, Loss: 0.6139\n",
      "Epoch: 2292, Loss: 0.6204\n",
      "Epoch: 2293, Loss: 0.6189\n",
      "Epoch: 2294, Loss: 0.6209\n",
      "Epoch: 2295, Loss: 0.6314\n",
      "Epoch: 2296, Loss: 0.6082\n",
      "Epoch: 2297, Loss: 0.6330\n",
      "Epoch: 2298, Loss: 0.6163\n",
      "Epoch: 2299, Loss: 0.6135\n",
      "Epoch: 2300, Loss: 0.6236\n",
      "Epoch: 2301, Loss: 0.6215\n",
      "Epoch: 2302, Loss: 0.6183\n",
      "Epoch: 2303, Loss: 0.6163\n",
      "Epoch: 2304, Loss: 0.6175\n",
      "Epoch: 2305, Loss: 0.6220\n",
      "Epoch: 2306, Loss: 0.6037\n",
      "Epoch: 2307, Loss: 0.6102\n",
      "Epoch: 2308, Loss: 0.6130\n",
      "Epoch: 2309, Loss: 0.6093\n",
      "Epoch: 2310, Loss: 0.6209\n",
      "Epoch: 2311, Loss: 0.6109\n",
      "Epoch: 2312, Loss: 0.6139\n",
      "Epoch: 2313, Loss: 0.6283\n",
      "Epoch: 2314, Loss: 0.6167\n",
      "Epoch: 2315, Loss: 0.6112\n",
      "Epoch: 2316, Loss: 0.5949\n",
      "Epoch: 2317, Loss: 0.6043\n",
      "Epoch: 2318, Loss: 0.6132\n",
      "Epoch: 2319, Loss: 0.6271\n",
      "Epoch: 2320, Loss: 0.6020\n",
      "Epoch: 2321, Loss: 0.6110\n",
      "Epoch: 2322, Loss: 0.5970\n",
      "Epoch: 2323, Loss: 0.6091\n",
      "Epoch: 2324, Loss: 0.6139\n",
      "Epoch: 2325, Loss: 0.5968\n",
      "Epoch: 2326, Loss: 0.6099\n",
      "Epoch: 2327, Loss: 0.6298\n",
      "Epoch: 2328, Loss: 0.6207\n",
      "Epoch: 2329, Loss: 0.6103\n",
      "Epoch: 2330, Loss: 0.6223\n",
      "Epoch: 2331, Loss: 0.6122\n",
      "Epoch: 2332, Loss: 0.6043\n",
      "Epoch: 2333, Loss: 0.6053\n",
      "Epoch: 2334, Loss: 0.6083\n",
      "Epoch: 2335, Loss: 0.6024\n",
      "Epoch: 2336, Loss: 0.6034\n",
      "Epoch: 2337, Loss: 0.6016\n",
      "Epoch: 2338, Loss: 0.6093\n",
      "Epoch: 2339, Loss: 0.5988\n",
      "Epoch: 2340, Loss: 0.6160\n",
      "Epoch: 2341, Loss: 0.5952\n",
      "Epoch: 2342, Loss: 0.6266\n",
      "Epoch: 2343, Loss: 0.6162\n",
      "Epoch: 2344, Loss: 0.6026\n",
      "Epoch: 2345, Loss: 0.6027\n",
      "Epoch: 2346, Loss: 0.5855\n",
      "Epoch: 2347, Loss: 0.6088\n",
      "Epoch: 2348, Loss: 0.5966\n",
      "Epoch: 2349, Loss: 0.6137\n",
      "Epoch: 2350, Loss: 0.6061\n",
      "Epoch: 2351, Loss: 0.6213\n",
      "Epoch: 2352, Loss: 0.6157\n",
      "Epoch: 2353, Loss: 0.6093\n",
      "Epoch: 2354, Loss: 0.6057\n",
      "Epoch: 2355, Loss: 0.6041\n",
      "Epoch: 2356, Loss: 0.6182\n",
      "Epoch: 2357, Loss: 0.6173\n",
      "Epoch: 2358, Loss: 0.6024\n",
      "Epoch: 2359, Loss: 0.5989\n",
      "Epoch: 2360, Loss: 0.5988\n",
      "Epoch: 2361, Loss: 0.5969\n",
      "Epoch: 2362, Loss: 0.6096\n",
      "Epoch: 2363, Loss: 0.6177\n",
      "Epoch: 2364, Loss: 0.6075\n",
      "Epoch: 2365, Loss: 0.6026\n",
      "Epoch: 2366, Loss: 0.6069\n",
      "Epoch: 2367, Loss: 0.6172\n",
      "Epoch: 2368, Loss: 0.6149\n",
      "Epoch: 2369, Loss: 0.6171\n",
      "Epoch: 2370, Loss: 0.6060\n",
      "Epoch: 2371, Loss: 0.6095\n",
      "Epoch: 2372, Loss: 0.6202\n",
      "Epoch: 2373, Loss: 0.6131\n",
      "Epoch: 2374, Loss: 0.6211\n",
      "Epoch: 2375, Loss: 0.6224\n",
      "Epoch: 2376, Loss: 0.6159\n",
      "Epoch: 2377, Loss: 0.6079\n",
      "Epoch: 2378, Loss: 0.6055\n",
      "Epoch: 2379, Loss: 0.6138\n",
      "Epoch: 2380, Loss: 0.6084\n",
      "Epoch: 2381, Loss: 0.6069\n",
      "Epoch: 2382, Loss: 0.6059\n",
      "Epoch: 2383, Loss: 0.5934\n",
      "Epoch: 2384, Loss: 0.6062\n",
      "Epoch: 2385, Loss: 0.5978\n",
      "Epoch: 2386, Loss: 0.6030\n",
      "Epoch: 2387, Loss: 0.6092\n",
      "Epoch: 2388, Loss: 0.5947\n",
      "Epoch: 2389, Loss: 0.6095\n",
      "Epoch: 2390, Loss: 0.6077\n",
      "Epoch: 2391, Loss: 0.6016\n",
      "Epoch: 2392, Loss: 0.5929\n",
      "Epoch: 2393, Loss: 0.6109\n",
      "Epoch: 2394, Loss: 0.6021\n",
      "Epoch: 2395, Loss: 0.6060\n",
      "Epoch: 2396, Loss: 0.6030\n",
      "Epoch: 2397, Loss: 0.6038\n",
      "Epoch: 2398, Loss: 0.6079\n",
      "Epoch: 2399, Loss: 0.6032\n",
      "Epoch: 2400, Loss: 0.6050\n",
      "Epoch: 2401, Loss: 0.6067\n",
      "Epoch: 2402, Loss: 0.6082\n",
      "Epoch: 2403, Loss: 0.6232\n",
      "Epoch: 2404, Loss: 0.6087\n",
      "Epoch: 2405, Loss: 0.6080\n",
      "Epoch: 2406, Loss: 0.6128\n",
      "Epoch: 2407, Loss: 0.6185\n",
      "Epoch: 2408, Loss: 0.5939\n",
      "Epoch: 2409, Loss: 0.5937\n",
      "Epoch: 2410, Loss: 0.6143\n",
      "Epoch: 2411, Loss: 0.6053\n",
      "Epoch: 2412, Loss: 0.5978\n",
      "Epoch: 2413, Loss: 0.6197\n",
      "Epoch: 2414, Loss: 0.6014\n",
      "Epoch: 2415, Loss: 0.5895\n",
      "Epoch: 2416, Loss: 0.6091\n",
      "Epoch: 2417, Loss: 0.6058\n",
      "Epoch: 2418, Loss: 0.5918\n",
      "Epoch: 2419, Loss: 0.5990\n",
      "Epoch: 2420, Loss: 0.5898\n",
      "Epoch: 2421, Loss: 0.6061\n",
      "Epoch: 2422, Loss: 0.6128\n",
      "Epoch: 2423, Loss: 0.6107\n",
      "Epoch: 2424, Loss: 0.5958\n",
      "Epoch: 2425, Loss: 0.6042\n",
      "Epoch: 2426, Loss: 0.6024\n",
      "Epoch: 2427, Loss: 0.6143\n",
      "Epoch: 2428, Loss: 0.6009\n",
      "Epoch: 2429, Loss: 0.5932\n",
      "Epoch: 2430, Loss: 0.5943\n",
      "Epoch: 2431, Loss: 0.5933\n",
      "Epoch: 2432, Loss: 0.6026\n",
      "Epoch: 2433, Loss: 0.5988\n",
      "Epoch: 2434, Loss: 0.6031\n",
      "Epoch: 2435, Loss: 0.6084\n",
      "Epoch: 2436, Loss: 0.6073\n",
      "Epoch: 2437, Loss: 0.5958\n",
      "Epoch: 2438, Loss: 0.6022\n",
      "Epoch: 2439, Loss: 0.6027\n",
      "Epoch: 2440, Loss: 0.5914\n",
      "Epoch: 2441, Loss: 0.6049\n",
      "Epoch: 2442, Loss: 0.5889\n",
      "Epoch: 2443, Loss: 0.6021\n",
      "Epoch: 2444, Loss: 0.6132\n",
      "Epoch: 2445, Loss: 0.6011\n",
      "Epoch: 2446, Loss: 0.6043\n",
      "Epoch: 2447, Loss: 0.6105\n",
      "Epoch: 2448, Loss: 0.5981\n",
      "Epoch: 2449, Loss: 0.5995\n",
      "Epoch: 2450, Loss: 0.6071\n",
      "Epoch: 2451, Loss: 0.5985\n",
      "Epoch: 2452, Loss: 0.6072\n",
      "Epoch: 2453, Loss: 0.5874\n",
      "Epoch: 2454, Loss: 0.5975\n",
      "Epoch: 2455, Loss: 0.6104\n",
      "Epoch: 2456, Loss: 0.6113\n",
      "Epoch: 2457, Loss: 0.6037\n",
      "Epoch: 2458, Loss: 0.6048\n",
      "Epoch: 2459, Loss: 0.6051\n",
      "Epoch: 2460, Loss: 0.6058\n",
      "Epoch: 2461, Loss: 0.5932\n",
      "Epoch: 2462, Loss: 0.5889\n",
      "Epoch: 2463, Loss: 0.6110\n",
      "Epoch: 2464, Loss: 0.6029\n",
      "Epoch: 2465, Loss: 0.6027\n",
      "Epoch: 2466, Loss: 0.5930\n",
      "Epoch: 2467, Loss: 0.6069\n",
      "Epoch: 2468, Loss: 0.5964\n",
      "Epoch: 2469, Loss: 0.5964\n",
      "Epoch: 2470, Loss: 0.6161\n",
      "Epoch: 2471, Loss: 0.5993\n",
      "Epoch: 2472, Loss: 0.6061\n",
      "Epoch: 2473, Loss: 0.5932\n",
      "Epoch: 2474, Loss: 0.5903\n",
      "Epoch: 2475, Loss: 0.5782\n",
      "Epoch: 2476, Loss: 0.5975\n",
      "Epoch: 2477, Loss: 0.6094\n",
      "Epoch: 2478, Loss: 0.6166\n",
      "Epoch: 2479, Loss: 0.5965\n",
      "Epoch: 2480, Loss: 0.5948\n",
      "Epoch: 2481, Loss: 0.6043\n",
      "Epoch: 2482, Loss: 0.5957\n",
      "Epoch: 2483, Loss: 0.5829\n",
      "Epoch: 2484, Loss: 0.5938\n",
      "Epoch: 2485, Loss: 0.6012\n",
      "Epoch: 2486, Loss: 0.6181\n",
      "Epoch: 2487, Loss: 0.6098\n",
      "Epoch: 2488, Loss: 0.5961\n",
      "Epoch: 2489, Loss: 0.6222\n",
      "Epoch: 2490, Loss: 0.6008\n",
      "Epoch: 2491, Loss: 0.6035\n",
      "Epoch: 2492, Loss: 0.6127\n",
      "Epoch: 2493, Loss: 0.5881\n",
      "Epoch: 2494, Loss: 0.5942\n",
      "Epoch: 2495, Loss: 0.5974\n",
      "Epoch: 2496, Loss: 0.5892\n",
      "Epoch: 2497, Loss: 0.5925\n",
      "Epoch: 2498, Loss: 0.5973\n",
      "Epoch: 2499, Loss: 0.6026\n",
      "Epoch: 2500, Loss: 0.6109\n",
      "Epoch: 2501, Loss: 0.5894\n",
      "Epoch: 2502, Loss: 0.6022\n",
      "Epoch: 2503, Loss: 0.6004\n",
      "Epoch: 2504, Loss: 0.6009\n",
      "Epoch: 2505, Loss: 0.5941\n",
      "Epoch: 2506, Loss: 0.5942\n",
      "Epoch: 2507, Loss: 0.5938\n",
      "Epoch: 2508, Loss: 0.5891\n",
      "Epoch: 2509, Loss: 0.5991\n",
      "Epoch: 2510, Loss: 0.5923\n",
      "Epoch: 2511, Loss: 0.6036\n",
      "Epoch: 2512, Loss: 0.6131\n",
      "Epoch: 2513, Loss: 0.5938\n",
      "Epoch: 2514, Loss: 0.5931\n",
      "Epoch: 2515, Loss: 0.5982\n",
      "Epoch: 2516, Loss: 0.5970\n",
      "Epoch: 2517, Loss: 0.5956\n",
      "Epoch: 2518, Loss: 0.6022\n",
      "Epoch: 2519, Loss: 0.5927\n",
      "Epoch: 2520, Loss: 0.6049\n",
      "Epoch: 2521, Loss: 0.5976\n",
      "Epoch: 2522, Loss: 0.6039\n",
      "Epoch: 2523, Loss: 0.6001\n",
      "Epoch: 2524, Loss: 0.6009\n",
      "Epoch: 2525, Loss: 0.5859\n",
      "Epoch: 2526, Loss: 0.5928\n",
      "Epoch: 2527, Loss: 0.5972\n",
      "Epoch: 2528, Loss: 0.6030\n",
      "Epoch: 2529, Loss: 0.6064\n",
      "Epoch: 2530, Loss: 0.6104\n",
      "Epoch: 2531, Loss: 0.5989\n",
      "Epoch: 2532, Loss: 0.6017\n",
      "Epoch: 2533, Loss: 0.5947\n",
      "Epoch: 2534, Loss: 0.5929\n",
      "Epoch: 2535, Loss: 0.5975\n",
      "Epoch: 2536, Loss: 0.6100\n",
      "Epoch: 2537, Loss: 0.5963\n",
      "Epoch: 2538, Loss: 0.6019\n",
      "Epoch: 2539, Loss: 0.6042\n",
      "Epoch: 2540, Loss: 0.5972\n",
      "Epoch: 2541, Loss: 0.5874\n",
      "Epoch: 2542, Loss: 0.5935\n",
      "Epoch: 2543, Loss: 0.5942\n",
      "Epoch: 2544, Loss: 0.6120\n",
      "Epoch: 2545, Loss: 0.6032\n",
      "Epoch: 2546, Loss: 0.5949\n",
      "Epoch: 2547, Loss: 0.6046\n",
      "Epoch: 2548, Loss: 0.5982\n",
      "Epoch: 2549, Loss: 0.5863\n",
      "Epoch: 2550, Loss: 0.5999\n",
      "Epoch: 2551, Loss: 0.6051\n",
      "Epoch: 2552, Loss: 0.5964\n",
      "Epoch: 2553, Loss: 0.5872\n",
      "Epoch: 2554, Loss: 0.6079\n",
      "Epoch: 2555, Loss: 0.5926\n",
      "Epoch: 2556, Loss: 0.6001\n",
      "Epoch: 2557, Loss: 0.5891\n",
      "Epoch: 2558, Loss: 0.6213\n",
      "Epoch: 2559, Loss: 0.6054\n",
      "Epoch: 2560, Loss: 0.5771\n",
      "Epoch: 2561, Loss: 0.5935\n",
      "Epoch: 2562, Loss: 0.6023\n",
      "Epoch: 2563, Loss: 0.5905\n",
      "Epoch: 2564, Loss: 0.5924\n",
      "Epoch: 2565, Loss: 0.5868\n",
      "Epoch: 2566, Loss: 0.6082\n",
      "Epoch: 2567, Loss: 0.5974\n",
      "Epoch: 2568, Loss: 0.5916\n",
      "Epoch: 2569, Loss: 0.5970\n",
      "Epoch: 2570, Loss: 0.5970\n",
      "Epoch: 2571, Loss: 0.5974\n",
      "Epoch: 2572, Loss: 0.5946\n",
      "Epoch: 2573, Loss: 0.6075\n",
      "Epoch: 2574, Loss: 0.5851\n",
      "Epoch: 2575, Loss: 0.5956\n",
      "Epoch: 2576, Loss: 0.5959\n",
      "Epoch: 2577, Loss: 0.5972\n",
      "Epoch: 2578, Loss: 0.6017\n",
      "Epoch: 2579, Loss: 0.6042\n",
      "Epoch: 2580, Loss: 0.6016\n",
      "Epoch: 2581, Loss: 0.5947\n",
      "Epoch: 2582, Loss: 0.6022\n",
      "Epoch: 2583, Loss: 0.5924\n",
      "Epoch: 2584, Loss: 0.6138\n",
      "Epoch: 2585, Loss: 0.5852\n",
      "Epoch: 2586, Loss: 0.5965\n",
      "Epoch: 2587, Loss: 0.5988\n",
      "Epoch: 2588, Loss: 0.5894\n",
      "Epoch: 2589, Loss: 0.5933\n",
      "Epoch: 2590, Loss: 0.5894\n",
      "Epoch: 2591, Loss: 0.6007\n",
      "Epoch: 2592, Loss: 0.5894\n",
      "Epoch: 2593, Loss: 0.5973\n",
      "Epoch: 2594, Loss: 0.5855\n",
      "Epoch: 2595, Loss: 0.5770\n",
      "Epoch: 2596, Loss: 0.6035\n",
      "Epoch: 2597, Loss: 0.6015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2598, Loss: 0.5920\n",
      "Epoch: 2599, Loss: 0.6008\n",
      "Epoch: 2600, Loss: 0.6002\n",
      "Epoch: 2601, Loss: 0.5839\n",
      "Epoch: 2602, Loss: 0.6135\n",
      "Epoch: 2603, Loss: 0.5862\n",
      "Epoch: 2604, Loss: 0.5912\n",
      "Epoch: 2605, Loss: 0.6013\n",
      "Epoch: 2606, Loss: 0.6018\n",
      "Epoch: 2607, Loss: 0.6008\n",
      "Epoch: 2608, Loss: 0.5885\n",
      "Epoch: 2609, Loss: 0.6000\n",
      "Epoch: 2610, Loss: 0.5881\n",
      "Epoch: 2611, Loss: 0.6028\n",
      "Epoch: 2612, Loss: 0.5919\n",
      "Epoch: 2613, Loss: 0.5810\n",
      "Epoch: 2614, Loss: 0.5843\n",
      "Epoch: 2615, Loss: 0.5860\n",
      "Epoch: 2616, Loss: 0.5895\n",
      "Epoch: 2617, Loss: 0.6005\n",
      "Epoch: 2618, Loss: 0.5923\n",
      "Epoch: 2619, Loss: 0.6118\n",
      "Epoch: 2620, Loss: 0.5920\n",
      "Epoch: 2621, Loss: 0.6100\n",
      "Epoch: 2622, Loss: 0.5934\n",
      "Epoch: 2623, Loss: 0.6023\n",
      "Epoch: 2624, Loss: 0.5939\n",
      "Epoch: 2625, Loss: 0.6079\n",
      "Epoch: 2626, Loss: 0.5916\n",
      "Epoch: 2627, Loss: 0.6004\n",
      "Epoch: 2628, Loss: 0.6016\n",
      "Epoch: 2629, Loss: 0.5913\n",
      "Epoch: 2630, Loss: 0.5792\n",
      "Epoch: 2631, Loss: 0.5945\n",
      "Epoch: 2632, Loss: 0.5959\n",
      "Epoch: 2633, Loss: 0.6067\n",
      "Epoch: 2634, Loss: 0.5930\n",
      "Epoch: 2635, Loss: 0.6090\n",
      "Epoch: 2636, Loss: 0.6037\n",
      "Epoch: 2637, Loss: 0.5872\n",
      "Epoch: 2638, Loss: 0.6046\n",
      "Epoch: 2639, Loss: 0.5915\n",
      "Epoch: 2640, Loss: 0.5868\n",
      "Epoch: 2641, Loss: 0.5972\n",
      "Epoch: 2642, Loss: 0.5883\n",
      "Epoch: 2643, Loss: 0.5853\n",
      "Epoch: 2644, Loss: 0.5910\n",
      "Epoch: 2645, Loss: 0.5965\n",
      "Epoch: 2646, Loss: 0.5915\n",
      "Epoch: 2647, Loss: 0.6022\n",
      "Epoch: 2648, Loss: 0.5847\n",
      "Epoch: 2649, Loss: 0.5994\n",
      "Epoch: 2650, Loss: 0.6046\n",
      "Epoch: 2651, Loss: 0.5850\n",
      "Epoch: 2652, Loss: 0.5969\n",
      "Epoch: 2653, Loss: 0.5929\n",
      "Epoch: 2654, Loss: 0.5836\n",
      "Epoch: 2655, Loss: 0.5980\n",
      "Epoch: 2656, Loss: 0.5967\n",
      "Epoch: 2657, Loss: 0.6115\n",
      "Epoch: 2658, Loss: 0.5926\n",
      "Epoch: 2659, Loss: 0.5967\n",
      "Epoch: 2660, Loss: 0.5890\n",
      "Epoch: 2661, Loss: 0.5995\n",
      "Epoch: 2662, Loss: 0.5925\n",
      "Epoch: 2663, Loss: 0.5893\n",
      "Epoch: 2664, Loss: 0.5890\n",
      "Epoch: 2665, Loss: 0.5880\n",
      "Epoch: 2666, Loss: 0.5944\n",
      "Epoch: 2667, Loss: 0.5894\n",
      "Epoch: 2668, Loss: 0.5946\n",
      "Epoch: 2669, Loss: 0.5897\n",
      "Epoch: 2670, Loss: 0.5922\n",
      "Epoch: 2671, Loss: 0.5937\n",
      "Epoch: 2672, Loss: 0.5816\n",
      "Epoch: 2673, Loss: 0.5867\n",
      "Epoch: 2674, Loss: 0.5857\n",
      "Epoch: 2675, Loss: 0.5955\n",
      "Epoch: 2676, Loss: 0.5676\n",
      "Epoch: 2677, Loss: 0.5904\n",
      "Epoch: 2678, Loss: 0.5901\n",
      "Epoch: 2679, Loss: 0.5786\n",
      "Epoch: 2680, Loss: 0.5804\n",
      "Epoch: 2681, Loss: 0.5946\n",
      "Epoch: 2682, Loss: 0.5854\n",
      "Epoch: 2683, Loss: 0.5931\n",
      "Epoch: 2684, Loss: 0.5797\n",
      "Epoch: 2685, Loss: 0.5860\n",
      "Epoch: 2686, Loss: 0.5936\n",
      "Epoch: 2687, Loss: 0.5911\n",
      "Epoch: 2688, Loss: 0.5945\n",
      "Epoch: 2689, Loss: 0.5929\n",
      "Epoch: 2690, Loss: 0.5888\n",
      "Epoch: 2691, Loss: 0.5886\n",
      "Epoch: 2692, Loss: 0.5977\n",
      "Epoch: 2693, Loss: 0.5806\n",
      "Epoch: 2694, Loss: 0.5879\n",
      "Epoch: 2695, Loss: 0.5893\n",
      "Epoch: 2696, Loss: 0.5853\n",
      "Epoch: 2697, Loss: 0.5771\n",
      "Epoch: 2698, Loss: 0.5893\n",
      "Epoch: 2699, Loss: 0.5800\n",
      "Epoch: 2700, Loss: 0.5827\n",
      "Epoch: 2701, Loss: 0.5893\n",
      "Epoch: 2702, Loss: 0.5967\n",
      "Epoch: 2703, Loss: 0.5904\n",
      "Epoch: 2704, Loss: 0.5859\n",
      "Epoch: 2705, Loss: 0.5934\n",
      "Epoch: 2706, Loss: 0.5936\n",
      "Epoch: 2707, Loss: 0.5796\n",
      "Epoch: 2708, Loss: 0.5797\n",
      "Epoch: 2709, Loss: 0.5948\n",
      "Epoch: 2710, Loss: 0.5809\n",
      "Epoch: 2711, Loss: 0.5894\n",
      "Epoch: 2712, Loss: 0.5798\n",
      "Epoch: 2713, Loss: 0.5864\n",
      "Epoch: 2714, Loss: 0.5872\n",
      "Epoch: 2715, Loss: 0.5748\n",
      "Epoch: 2716, Loss: 0.5927\n",
      "Epoch: 2717, Loss: 0.5892\n",
      "Epoch: 2718, Loss: 0.5781\n",
      "Epoch: 2719, Loss: 0.5925\n",
      "Epoch: 2720, Loss: 0.5776\n",
      "Epoch: 2721, Loss: 0.5783\n",
      "Epoch: 2722, Loss: 0.5754\n",
      "Epoch: 2723, Loss: 0.5761\n",
      "Epoch: 2724, Loss: 0.5835\n",
      "Epoch: 2725, Loss: 0.5926\n",
      "Epoch: 2726, Loss: 0.5835\n",
      "Epoch: 2727, Loss: 0.5979\n",
      "Epoch: 2728, Loss: 0.5798\n",
      "Epoch: 2729, Loss: 0.5975\n",
      "Epoch: 2730, Loss: 0.5943\n",
      "Epoch: 2731, Loss: 0.5855\n",
      "Epoch: 2732, Loss: 0.5895\n",
      "Epoch: 2733, Loss: 0.5836\n",
      "Epoch: 2734, Loss: 0.5932\n",
      "Epoch: 2735, Loss: 0.5745\n",
      "Epoch: 2736, Loss: 0.5873\n",
      "Epoch: 2737, Loss: 0.5981\n",
      "Epoch: 2738, Loss: 0.5811\n",
      "Epoch: 2739, Loss: 0.5839\n",
      "Epoch: 2740, Loss: 0.5843\n",
      "Epoch: 2741, Loss: 0.5950\n",
      "Epoch: 2742, Loss: 0.5871\n",
      "Epoch: 2743, Loss: 0.5928\n",
      "Epoch: 2744, Loss: 0.5767\n",
      "Epoch: 2745, Loss: 0.5828\n",
      "Epoch: 2746, Loss: 0.5933\n",
      "Epoch: 2747, Loss: 0.5880\n",
      "Epoch: 2748, Loss: 0.5964\n",
      "Epoch: 2749, Loss: 0.5789\n",
      "Epoch: 2750, Loss: 0.5893\n",
      "Epoch: 2751, Loss: 0.5832\n",
      "Epoch: 2752, Loss: 0.5980\n",
      "Epoch: 2753, Loss: 0.5902\n",
      "Epoch: 2754, Loss: 0.5726\n",
      "Epoch: 2755, Loss: 0.5766\n",
      "Epoch: 2756, Loss: 0.5830\n",
      "Epoch: 2757, Loss: 0.5806\n",
      "Epoch: 2758, Loss: 0.5856\n",
      "Epoch: 2759, Loss: 0.5932\n",
      "Epoch: 2760, Loss: 0.6082\n",
      "Epoch: 2761, Loss: 0.5788\n",
      "Epoch: 2762, Loss: 0.5936\n",
      "Epoch: 2763, Loss: 0.5894\n",
      "Epoch: 2764, Loss: 0.5941\n",
      "Epoch: 2765, Loss: 0.5841\n",
      "Epoch: 2766, Loss: 0.5840\n",
      "Epoch: 2767, Loss: 0.5846\n",
      "Epoch: 2768, Loss: 0.5860\n",
      "Epoch: 2769, Loss: 0.5860\n",
      "Epoch: 2770, Loss: 0.5880\n",
      "Epoch: 2771, Loss: 0.5838\n",
      "Epoch: 2772, Loss: 0.5966\n",
      "Epoch: 2773, Loss: 0.5813\n",
      "Epoch: 2774, Loss: 0.5830\n",
      "Epoch: 2775, Loss: 0.5855\n",
      "Epoch: 2776, Loss: 0.5956\n",
      "Epoch: 2777, Loss: 0.6006\n",
      "Epoch: 2778, Loss: 0.5813\n",
      "Epoch: 2779, Loss: 0.5897\n",
      "Epoch: 2780, Loss: 0.5840\n",
      "Epoch: 2781, Loss: 0.5886\n",
      "Epoch: 2782, Loss: 0.5710\n",
      "Epoch: 2783, Loss: 0.5916\n",
      "Epoch: 2784, Loss: 0.5814\n",
      "Epoch: 2785, Loss: 0.5865\n",
      "Epoch: 2786, Loss: 0.5937\n",
      "Epoch: 2787, Loss: 0.5845\n",
      "Epoch: 2788, Loss: 0.5932\n",
      "Epoch: 2789, Loss: 0.5828\n",
      "Epoch: 2790, Loss: 0.5897\n",
      "Epoch: 2791, Loss: 0.5810\n",
      "Epoch: 2792, Loss: 0.5873\n",
      "Epoch: 2793, Loss: 0.5857\n",
      "Epoch: 2794, Loss: 0.5952\n",
      "Epoch: 2795, Loss: 0.5807\n",
      "Epoch: 2796, Loss: 0.5882\n",
      "Epoch: 2797, Loss: 0.5719\n",
      "Epoch: 2798, Loss: 0.5851\n",
      "Epoch: 2799, Loss: 0.5996\n",
      "Epoch: 2800, Loss: 0.5856\n",
      "Epoch: 2801, Loss: 0.5844\n",
      "Epoch: 2802, Loss: 0.5886\n",
      "Epoch: 2803, Loss: 0.5974\n",
      "Epoch: 2804, Loss: 0.5887\n",
      "Epoch: 2805, Loss: 0.5672\n",
      "Epoch: 2806, Loss: 0.5803\n",
      "Epoch: 2807, Loss: 0.5795\n",
      "Epoch: 2808, Loss: 0.5746\n",
      "Epoch: 2809, Loss: 0.5874\n",
      "Epoch: 2810, Loss: 0.5788\n",
      "Epoch: 2811, Loss: 0.5857\n",
      "Epoch: 2812, Loss: 0.5811\n",
      "Epoch: 2813, Loss: 0.5867\n",
      "Epoch: 2814, Loss: 0.5902\n",
      "Epoch: 2815, Loss: 0.5917\n",
      "Epoch: 2816, Loss: 0.5925\n",
      "Epoch: 2817, Loss: 0.5741\n",
      "Epoch: 2818, Loss: 0.5841\n",
      "Epoch: 2819, Loss: 0.5798\n",
      "Epoch: 2820, Loss: 0.5806\n",
      "Epoch: 2821, Loss: 0.5715\n",
      "Epoch: 2822, Loss: 0.5770\n",
      "Epoch: 2823, Loss: 0.5929\n",
      "Epoch: 2824, Loss: 0.5913\n",
      "Epoch: 2825, Loss: 0.5872\n",
      "Epoch: 2826, Loss: 0.5849\n",
      "Epoch: 2827, Loss: 0.5870\n",
      "Epoch: 2828, Loss: 0.5768\n",
      "Epoch: 2829, Loss: 0.5818\n",
      "Epoch: 2830, Loss: 0.5679\n",
      "Epoch: 2831, Loss: 0.5799\n",
      "Epoch: 2832, Loss: 0.5939\n",
      "Epoch: 2833, Loss: 0.5871\n",
      "Epoch: 2834, Loss: 0.5979\n",
      "Epoch: 2835, Loss: 0.5650\n",
      "Epoch: 2836, Loss: 0.5806\n",
      "Epoch: 2837, Loss: 0.5832\n",
      "Epoch: 2838, Loss: 0.5808\n",
      "Epoch: 2839, Loss: 0.5828\n",
      "Epoch: 2840, Loss: 0.5799\n",
      "Epoch: 2841, Loss: 0.5831\n",
      "Epoch: 2842, Loss: 0.5769\n",
      "Epoch: 2843, Loss: 0.5701\n",
      "Epoch: 2844, Loss: 0.5841\n",
      "Epoch: 2845, Loss: 0.5949\n",
      "Epoch: 2846, Loss: 0.5679\n",
      "Epoch: 2847, Loss: 0.5804\n",
      "Epoch: 2848, Loss: 0.5808\n",
      "Epoch: 2849, Loss: 0.5898\n",
      "Epoch: 2850, Loss: 0.6064\n",
      "Epoch: 2851, Loss: 0.5841\n",
      "Epoch: 2852, Loss: 0.5829\n",
      "Epoch: 2853, Loss: 0.5822\n",
      "Epoch: 2854, Loss: 0.5997\n",
      "Epoch: 2855, Loss: 0.5812\n",
      "Epoch: 2856, Loss: 0.5957\n",
      "Epoch: 2857, Loss: 0.5764\n",
      "Epoch: 2858, Loss: 0.5886\n",
      "Epoch: 2859, Loss: 0.5942\n",
      "Epoch: 2860, Loss: 0.5768\n",
      "Epoch: 2861, Loss: 0.5903\n",
      "Epoch: 2862, Loss: 0.5893\n",
      "Epoch: 2863, Loss: 0.6043\n",
      "Epoch: 2864, Loss: 0.5726\n",
      "Epoch: 2865, Loss: 0.5841\n",
      "Epoch: 2866, Loss: 0.5876\n",
      "Epoch: 2867, Loss: 0.5822\n",
      "Epoch: 2868, Loss: 0.5861\n",
      "Epoch: 2869, Loss: 0.5862\n",
      "Epoch: 2870, Loss: 0.5837\n",
      "Epoch: 2871, Loss: 0.5852\n",
      "Epoch: 2872, Loss: 0.5785\n",
      "Epoch: 2873, Loss: 0.5802\n",
      "Epoch: 2874, Loss: 0.5893\n",
      "Epoch: 2875, Loss: 0.5711\n",
      "Epoch: 2876, Loss: 0.6000\n",
      "Epoch: 2877, Loss: 0.5830\n",
      "Epoch: 2878, Loss: 0.5831\n",
      "Epoch: 2879, Loss: 0.5966\n",
      "Epoch: 2880, Loss: 0.5774\n",
      "Epoch: 2881, Loss: 0.5850\n",
      "Epoch: 2882, Loss: 0.5837\n",
      "Epoch: 2883, Loss: 0.5730\n",
      "Epoch: 2884, Loss: 0.5856\n",
      "Epoch: 2885, Loss: 0.5952\n",
      "Epoch: 2886, Loss: 0.5721\n",
      "Epoch: 2887, Loss: 0.5879\n",
      "Epoch: 2888, Loss: 0.5816\n",
      "Epoch: 2889, Loss: 0.5818\n",
      "Epoch: 2890, Loss: 0.5864\n",
      "Epoch: 2891, Loss: 0.5795\n",
      "Epoch: 2892, Loss: 0.5784\n",
      "Epoch: 2893, Loss: 0.5941\n",
      "Epoch: 2894, Loss: 0.5937\n",
      "Epoch: 2895, Loss: 0.5958\n",
      "Epoch: 2896, Loss: 0.5856\n",
      "Epoch: 2897, Loss: 0.5822\n",
      "Epoch: 2898, Loss: 0.5876\n",
      "Epoch: 2899, Loss: 0.5748\n",
      "Epoch: 2900, Loss: 0.5991\n",
      "Epoch: 2901, Loss: 0.5901\n",
      "Epoch: 2902, Loss: 0.5845\n",
      "Epoch: 2903, Loss: 0.5796\n",
      "Epoch: 2904, Loss: 0.5901\n",
      "Epoch: 2905, Loss: 0.5847\n",
      "Epoch: 2906, Loss: 0.5884\n",
      "Epoch: 2907, Loss: 0.5894\n",
      "Epoch: 2908, Loss: 0.5877\n",
      "Epoch: 2909, Loss: 0.5785\n",
      "Epoch: 2910, Loss: 0.5817\n",
      "Epoch: 2911, Loss: 0.5693\n",
      "Epoch: 2912, Loss: 0.5837\n",
      "Epoch: 2913, Loss: 0.5849\n",
      "Epoch: 2914, Loss: 0.5890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2915, Loss: 0.5771\n",
      "Epoch: 2916, Loss: 0.5779\n",
      "Epoch: 2917, Loss: 0.5714\n",
      "Epoch: 2918, Loss: 0.5891\n",
      "Epoch: 2919, Loss: 0.5813\n",
      "Epoch: 2920, Loss: 0.5894\n",
      "Epoch: 2921, Loss: 0.5798\n",
      "Epoch: 2922, Loss: 0.5853\n",
      "Epoch: 2923, Loss: 0.5795\n",
      "Epoch: 2924, Loss: 0.5807\n",
      "Epoch: 2925, Loss: 0.5869\n",
      "Epoch: 2926, Loss: 0.5751\n",
      "Epoch: 2927, Loss: 0.5672\n",
      "Epoch: 2928, Loss: 0.5642\n",
      "Epoch: 2929, Loss: 0.5775\n",
      "Epoch: 2930, Loss: 0.5730\n",
      "Epoch: 2931, Loss: 0.5828\n",
      "Epoch: 2932, Loss: 0.5967\n",
      "Epoch: 2933, Loss: 0.5802\n",
      "Epoch: 2934, Loss: 0.5781\n",
      "Epoch: 2935, Loss: 0.5775\n",
      "Epoch: 2936, Loss: 0.5787\n",
      "Epoch: 2937, Loss: 0.5966\n",
      "Epoch: 2938, Loss: 0.5667\n",
      "Epoch: 2939, Loss: 0.5682\n",
      "Epoch: 2940, Loss: 0.5695\n",
      "Epoch: 2941, Loss: 0.5777\n",
      "Epoch: 2942, Loss: 0.5835\n",
      "Epoch: 2943, Loss: 0.5752\n",
      "Epoch: 2944, Loss: 0.5787\n",
      "Epoch: 2945, Loss: 0.5864\n",
      "Epoch: 2946, Loss: 0.5664\n",
      "Epoch: 2947, Loss: 0.5843\n",
      "Epoch: 2948, Loss: 0.5852\n",
      "Epoch: 2949, Loss: 0.5975\n",
      "Epoch: 2950, Loss: 0.5673\n",
      "Epoch: 2951, Loss: 0.5861\n",
      "Epoch: 2952, Loss: 0.5843\n",
      "Epoch: 2953, Loss: 0.5865\n",
      "Epoch: 2954, Loss: 0.5892\n",
      "Epoch: 2955, Loss: 0.5748\n",
      "Epoch: 2956, Loss: 0.5913\n",
      "Epoch: 2957, Loss: 0.5808\n",
      "Epoch: 2958, Loss: 0.5706\n",
      "Epoch: 2959, Loss: 0.6004\n",
      "Epoch: 2960, Loss: 0.5991\n",
      "Epoch: 2961, Loss: 0.5834\n",
      "Epoch: 2962, Loss: 0.5881\n",
      "Epoch: 2963, Loss: 0.5745\n",
      "Epoch: 2964, Loss: 0.5769\n",
      "Epoch: 2965, Loss: 0.5868\n",
      "Epoch: 2966, Loss: 0.5972\n",
      "Epoch: 2967, Loss: 0.5801\n",
      "Epoch: 2968, Loss: 0.5802\n",
      "Epoch: 2969, Loss: 0.5800\n",
      "Epoch: 2970, Loss: 0.5847\n",
      "Epoch: 2971, Loss: 0.5780\n",
      "Epoch: 2972, Loss: 0.5919\n",
      "Epoch: 2973, Loss: 0.5631\n",
      "Epoch: 2974, Loss: 0.5745\n",
      "Epoch: 2975, Loss: 0.5797\n",
      "Epoch: 2976, Loss: 0.5802\n",
      "Epoch: 2977, Loss: 0.5788\n",
      "Epoch: 2978, Loss: 0.5731\n",
      "Epoch: 2979, Loss: 0.5680\n",
      "Epoch: 2980, Loss: 0.5850\n",
      "Epoch: 2981, Loss: 0.5865\n",
      "Epoch: 2982, Loss: 0.5961\n",
      "Epoch: 2983, Loss: 0.6003\n",
      "Epoch: 2984, Loss: 0.6061\n",
      "Epoch: 2985, Loss: 0.5654\n",
      "Epoch: 2986, Loss: 0.5790\n",
      "Epoch: 2987, Loss: 0.5936\n",
      "Epoch: 2988, Loss: 0.5880\n",
      "Epoch: 2989, Loss: 0.5809\n",
      "Epoch: 2990, Loss: 0.5744\n",
      "Epoch: 2991, Loss: 0.5883\n",
      "Epoch: 2992, Loss: 0.5903\n",
      "Epoch: 2993, Loss: 0.5866\n",
      "Epoch: 2994, Loss: 0.5957\n",
      "Epoch: 2995, Loss: 0.5922\n",
      "Epoch: 2996, Loss: 0.5904\n",
      "Epoch: 2997, Loss: 0.6003\n",
      "Epoch: 2998, Loss: 0.5974\n",
      "Epoch: 2999, Loss: 0.5864\n",
      "Epoch: 3000, Loss: 0.5871\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "# move model to gpu\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "    roc_auc = roc_auc_score(lb.transform(data.y[data.test_mask].cpu()),lb.transform(pred[data.test_mask].cpu()), multi_class='ovo')\n",
    "    return test_acc, roc_auc\n",
    "\n",
    "\n",
    "# to calculate roc_auc, the data needs to be one hot encoded, which I am doing using LabelBinarizer()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(data.y[data.train_mask].cpu())\n",
    "    \n",
    "epoch_list = list()\n",
    "loss_list = list()\n",
    "acc_list = list()\n",
    "roc_list = list()\n",
    "for epoch in range(1, 3001):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    # calculate test set accuracy\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "    acc_list.append(test_acc)\n",
    "    roc_auc = roc_auc_score(lb.transform(data.y[data.test_mask].cpu()),lb.transform(pred[data.test_mask].cpu()), multi_class='ovo')\n",
    "    roc_list.append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f72d59",
   "metadata": {},
   "source": [
    "Below I can see that with the GNN, the model ROC AUC continues to increase for far longer than with the MLP model. It is able to utilize much more data since it has access to the edges and it is able to use that information to achieve a much higher accuracy score. The performance of the GNN doesn't level off until around epoch 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4621e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, loss_list, label= \"Loss\")\n",
    "plt.plot(epoch_list, acc_list, label = \"Val Accuracy\")\n",
    "plt.plot(epoch_list, roc_list, label = \"Val ROC AUC\")\n",
    "plt.title(\"Loss, ROC AUC, and Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e7115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy last epoch: 0.8240\n",
      "Val ROC AUC last epoch: 0.8342\n",
      "\n",
      "Val Accuracy at epoch 1500: 0.7764\n",
      "Val ROC AUC epoch 1500: 0.7597\n"
     ]
    }
   ],
   "source": [
    "print(f'Val Accuracy last epoch: {acc_list[-1]:.4f}')\n",
    "print(f'Val ROC AUC last epoch: {roc_list[-1]:.4f}')\n",
    "print()\n",
    "print(f'Val Accuracy at epoch 1500: {acc_list[1500]:.4f}')\n",
    "print(f'Val ROC AUC epoch 1500: {roc_list[1500]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd72809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
